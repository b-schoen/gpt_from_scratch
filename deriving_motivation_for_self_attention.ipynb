{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5674fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload when imports change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d131b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import Unpack\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4978c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch import (\n",
    "    file_utils,\n",
    "    vocab_utils,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155f247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# imported for typechecking\n",
    "#\n",
    "# note: can't easily alias via jaxtyping annotations, as it's a string literal and\n",
    "#       likely plays weirdly with typing.Annotation to forward a payload\n",
    "# note: torchtyping is deprecated in favor of jaxtyping, as torchtyping doesn't have mypy integration\n",
    "#\n",
    "# note: jaxtyping does support prepending\n",
    "#\n",
    "#   Image = Float[Array, \"channels height width\"]\n",
    "#   BatchImage = Float[Image, \"batch\"]\n",
    "#\n",
    "#    -->\n",
    "#\n",
    "#   BatchImage = Float[Array, \"batch channels height width\"]\n",
    "#\n",
    "# so we can compose aliases\n",
    "#\n",
    "from torch import Tensor\n",
    "import jaxtyping\n",
    "from jaxtyping import jaxtyped, Float32, Int64\n",
    "from typeguard import typechecked as typechecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2076e5",
   "metadata": {},
   "source": [
    "# The mathematical trick of self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e34a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important enough for Karpathy to call out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc46612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem:\n",
    "# - we want it to be able to communicate previous token up to current token\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e6d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - the simplest possible way, if I'm the 5th token, I just want\n",
    "# -   [\n",
    "#       <avg-0th-position>\n",
    "#       <avg-1st-position>\n",
    "#       <avg-2nd-position>\n",
    "#       ...\n",
    "#     ]\n",
    "#   along the vocab dimension\n",
    "#\n",
    "# - this is \"bag of words\"\n",
    "#\n",
    "# this is our \"version 1\"\n",
    "\n",
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "x_bow = torch.zeros((B,T,C))\n",
    "\n",
    "# for each batch\n",
    "for b in range(B):\n",
    "    \n",
    "    # for each token in the sequence\n",
    "    for t in range(T):\n",
    "        \n",
    "        # slice up to (and including) the current token\n",
    "        x_prev = x[b, :t+1] # (t,C)\n",
    "        \n",
    "        # average them (along the vocab dimension)\n",
    "        x_bow[b, t] = torch.mean(x_prev, 0)\n",
    "\n",
    "# now `x_bow` is average \"up to \"\n",
    "x_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c3bbf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element:\n",
      " - tensor([ 0.1808, -0.0700])\n",
      " -> tensor([ 0.1808, -0.0700])\n"
     ]
    }
   ],
   "source": [
    "print(f'First element:')\n",
    "print(f' - {x[0][0]}')\n",
    "print(f' -> {x_bow[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f1428ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second element: (average of first two)\n",
      " - tensor([ 0.1808, -0.0700])\n",
      " - tensor([-0.3596, -0.9152])\n",
      " -> tensor([-0.0894, -0.4926])\n"
     ]
    }
   ],
   "source": [
    "print(f'Second element: (average of first two)')\n",
    "print(f' - {x[0][0]}')\n",
    "print(f' - {x[0][1]}')\n",
    "print(f' -> {x_bow[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74a6360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# this is good, but very inefficient\n",
    "# the trick is that we can be very very good about doing this with matrix multiplication\n",
    "\n",
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# a = torch.ones(3, 3)\n",
    "\n",
    "# OHHHH the triangular starts to look like the running total used in bag of words\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "\n",
    "# we can normalize them so they sum to 1 (now rows sum to 1)\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "\n",
    "c = a @ b\n",
    "\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)\n",
    "\n",
    "# that was literally it lmao?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "253df363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"version 2\": using matrix multiply for a weighted aggregation\n",
    "#\n",
    "# - this essentially lets:\n",
    "#   - `a = weights`\n",
    "#   - `b = x`\n",
    "#\n",
    "# - the weights are an intermediate computation tool\n",
    "#\n",
    "# - is self attention about letting them go in different directions?\n",
    "#\n",
    "weights = torch.tril(torch.ones(T, T))\n",
    "weights = weights / weights.sum(1, keepdim=True)\n",
    "\n",
    "x_bow2 = weights @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "\n",
    "# can see that same normalized running average pattern\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "053acc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can show that this gives us the same thing our for loop was doing\n",
    "torch.allclose(x_bow, x_bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68cd6cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Softmax:\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "After Softmax:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "# version 3: use softmax\n",
    "#\n",
    "# - so why do we care? this is the same thing\n",
    "# - this allows the weights to start at 0\n",
    "# - and we can essentially treat them as \"interaction strength\"\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "# affinities aren't going to be constant at 0, we want to let them vary depending on the data\n",
    "weights = torch.zeros((T,T))\n",
    "\n",
    "# for all the weights that are 0, make them -inf\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "print('Before Softmax:')\n",
    "print(weights)\n",
    "\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "print('After Softmax:')\n",
    "print(weights)\n",
    "\n",
    "x_bow3 = weights @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(x_bow, x_bow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tldr: this is:\n",
    "#  - weighted aggregation of information from previous tokens\n",
    "#  - allows it to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72cf9ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: Batch 0 (before normalization by head size)\n",
      "\n",
      "tensor([[-1.7629, -1.3011,  0.5652,  2.1616, -1.0674,  1.9632,  1.0765, -0.4530],\n",
      "        [-3.3334, -1.6556,  0.1040,  3.3782, -2.1825,  1.0415, -0.0557,  0.2927],\n",
      "        [-1.0226, -1.2606,  0.0762, -0.3813, -0.9843, -1.4303,  0.0749, -0.9547],\n",
      "        [ 0.7836, -0.8014, -0.3368, -0.8496, -0.5602, -1.1701, -1.2927, -1.0260],\n",
      "        [-1.2566,  0.0187, -0.7880, -1.3204,  2.0363,  0.8638,  0.3719,  0.9258],\n",
      "        [-0.3126,  2.4152, -0.1106, -0.9931,  3.3449, -2.5229,  1.4187,  1.2196],\n",
      "        [ 1.0876,  1.9652, -0.2621, -0.3158,  0.6091,  1.2616, -0.5484,  0.8048],\n",
      "        [-1.8044, -0.4126, -0.8306,  0.5898, -0.7987, -0.5856,  0.6433,  0.6303]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Example: Batch 0 (before masking)\n",
      "\n",
      "tensor([[-0.4407, -0.3253,  0.1413,  0.5404, -0.2668,  0.4908,  0.2691, -0.1132],\n",
      "        [-0.8334, -0.4139,  0.0260,  0.8446, -0.5456,  0.2604, -0.0139,  0.0732],\n",
      "        [-0.2557, -0.3152,  0.0191, -0.0953, -0.2461, -0.3576,  0.0187, -0.2387],\n",
      "        [ 0.1959, -0.2004, -0.0842, -0.2124, -0.1401, -0.2925, -0.3232, -0.2565],\n",
      "        [-0.3142,  0.0047, -0.1970, -0.3301,  0.5091,  0.2160,  0.0930,  0.2314],\n",
      "        [-0.0782,  0.6038, -0.0276, -0.2483,  0.8362, -0.6307,  0.3547,  0.3049],\n",
      "        [ 0.2719,  0.4913, -0.0655, -0.0789,  0.1523,  0.3154, -0.1371,  0.2012],\n",
      "        [-0.4511, -0.1031, -0.2077,  0.1475, -0.1997, -0.1464,  0.1608,  0.1576]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Example: Batch 0 (before softmax)\n",
      "\n",
      "tensor([[-0.4407,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.8334, -0.4139,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.2557, -0.3152,  0.0191,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.1959, -0.2004, -0.0842, -0.2124,    -inf,    -inf,    -inf,    -inf],\n",
      "        [-0.3142,  0.0047, -0.1970, -0.3301,  0.5091,    -inf,    -inf,    -inf],\n",
      "        [-0.0782,  0.6038, -0.0276, -0.2483,  0.8362, -0.6307,    -inf,    -inf],\n",
      "        [ 0.2719,  0.4913, -0.0655, -0.0789,  0.1523,  0.3154, -0.1371,    -inf],\n",
      "        [-0.4511, -0.1031, -0.2077,  0.1475, -0.1997, -0.1464,  0.1608,  0.1576]],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "\n",
      "Example: Batch 0 (after softmax)\n",
      "\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3966, 0.6034, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3069, 0.2892, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3233, 0.2175, 0.2443, 0.2149, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1479, 0.2034, 0.1663, 0.1455, 0.3369, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1259, 0.2490, 0.1324, 0.1062, 0.3141, 0.0724, 0.0000, 0.0000],\n",
      "        [0.1598, 0.1990, 0.1140, 0.1125, 0.1418, 0.1669, 0.1061, 0.0000],\n",
      "        [0.0845, 0.1197, 0.1078, 0.1537, 0.1086, 0.1146, 0.1558, 0.1553]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# version 4: self-attention!\n",
    "#\n",
    "# - attention for a single individual head\n",
    "#\n",
    "# note: Karpathy uses tokens <-> nodes interchangeably?\n",
    "#\n",
    "# - oh so Karpathy *literally* thinks of this as a graph\n",
    "#\n",
    "# - nodes with no notion of space\n",
    "#\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B,T,C = 4, 8, 32 # batch, time, channels\n",
    "\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# let's see a single Head perform self-attention\n",
    "head_size = 16\n",
    "\n",
    "# we'll have every token \"emit\" a:\n",
    "# - key:   \"what do I contain\"\n",
    "# - query: \"what am I looking for\"\n",
    "# - value: \"if you find anything interesting to me, here's what I'll give you\"\n",
    "#\n",
    "# - are these in terms of the updated weighted running average of previous tokens?\n",
    "#\n",
    "# - key * query = affinity (essentially acts like the weighted average matrix)\n",
    "#\n",
    "key   = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "# all tokens individually produce a key and a query vector\n",
    "# - no communication has happened yet\n",
    "k = key(x)   # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "\n",
    "# - don't want these to actually be completely 0 and data independent\n",
    "# weights = torch.zeros((T,T))\n",
    "#\n",
    "# note: batch dimension is only reason we can't just do `q @ k.T`\n",
    "#\n",
    "# (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
    "weights: Float32[Tensor, 'batch_size block_size block_size'] =  q @ k.transpose(-2, -1) \n",
    "\n",
    "print('\\nExample: Batch 0 (before normalization by head size)\\n')\n",
    "print(weights[0])\n",
    "\n",
    "# now `weights` has variance on the order of `n_heads`\n",
    "# - (since both `q` and `k` have `unit_variance`)\n",
    "# - want it to have `unit_variance` too since otherwise\n",
    "# - `softmax`` will saturate really quickly\n",
    "# - want these to be very diffuse at initialization, otherwise softmax will \n",
    "#   overly sharpen towards the max (from a single node)\n",
    "# - that's fine if happens later but at initialization don't want that\n",
    "weights = weights / math.sqrt(head_size)\n",
    "\n",
    "# so now we have a `block_size x block_size` matrix for each batch\n",
    "# essentially representing what was previously a weighted\n",
    "# sum of previous tokens, but is now a learnable linear layer\n",
    "#\n",
    "# - so we've essentially created:\n",
    "#  - a weighted average of previous tokens' contribution for each logit\n",
    "#  - a pair of linear layers that let's us actually learn this via backprop\n",
    "#  - they learn it in a data dependent way\n",
    "\n",
    "# want to mask before aggregating, since we actually don't want to allow future tokens to propagate\n",
    "print('\\nExample: Batch 0 (before masking)\\n')\n",
    "print(weights[0])\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "print('\\nExample: Batch 0 (before softmax)\\n')\n",
    "print(weights[0])\n",
    "\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "print('\\nExample: Batch 0 (after softmax)\\n')\n",
    "print(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e99eea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# we let the actual aggregation itself be learned too because why not\n",
    "#\n",
    "# essentially when QK *does* match, here's how much I'll give you\n",
    "#\n",
    "# essentially how to interpret the affinities, since they don't have any intrinsic meaning as far as units\n",
    "#\n",
    "v = value(x) # (B, T, 16)\n",
    "\n",
    "out = weights @ v # (B, T, T) @ (B, T, 16) ---> (B, T, 16)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4170e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1571,  0.8801,  0.1615, -0.7824, -0.1429,  0.7468,  0.1007, -0.5239,\n",
       "         -0.8873,  0.1907,  0.1762, -0.5943, -0.4812, -0.4860,  0.2862,  0.5710],\n",
       "        [ 0.6764, -0.5477, -0.2478,  0.3143, -0.1280, -0.2952, -0.4296, -0.1089,\n",
       "         -0.0493,  0.7268,  0.7130, -0.1164,  0.3266,  0.3431, -0.0710,  1.2716],\n",
       "        [ 0.4823, -0.1069, -0.4055,  0.1770,  0.1581, -0.1697,  0.0162,  0.0215,\n",
       "         -0.2490, -0.3773,  0.2787,  0.1629, -0.2895, -0.0676, -0.1416,  1.2194],\n",
       "        [ 0.1971,  0.2856, -0.1303, -0.2655,  0.0668,  0.1954,  0.0281, -0.2451,\n",
       "         -0.4647,  0.0693,  0.1528, -0.2032, -0.2479, -0.1621,  0.1947,  0.7678],\n",
       "        [ 0.2510,  0.7346,  0.5939,  0.2516,  0.2606,  0.7582,  0.5595,  0.3539,\n",
       "         -0.5934, -1.0807, -0.3111, -0.2781, -0.9054,  0.1318, -0.1382,  0.6371],\n",
       "        [ 0.3428,  0.4960,  0.4725,  0.3028,  0.1844,  0.5814,  0.3824,  0.2952,\n",
       "         -0.4897, -0.7705, -0.1172, -0.2541, -0.6892,  0.1979, -0.1513,  0.7666],\n",
       "        [ 0.1866, -0.0964, -0.1430,  0.3059,  0.0834, -0.0069, -0.2047, -0.1535,\n",
       "         -0.0762,  0.3269,  0.3090,  0.0766,  0.0992,  0.1656,  0.1975,  0.7625],\n",
       "        [ 0.1301, -0.0328, -0.4965,  0.2865,  0.2704, -0.2636, -0.0738,  0.3786,\n",
       "          0.0746,  0.0338,  0.0147,  0.3194,  0.2993, -0.1653, -0.0386,  0.3375]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d78fcb",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- Attention is a **communication mechanism**. Can be seen as nodes in a directed graph looking at each other and aggregating information with a weighted sum from all nodes that point to them, with data-dependent weights.\n",
    "\n",
    "- There is no notion of space. Attention simply acts over a set of vectors. This is why we need to positionally encode tokens.\n",
    "\n",
    "- Each example across batch dimension is of course processed completely independently and never \"talk\" to each other\n",
    "\n",
    "- In an $encoder$ attention block just delete the single line that does masking with `tril`, allowing all tokens to communicate. \n",
    "- This block here is called a $decoder$ attention block because it has triangular masking, and is usually used in autoregressive settings, like language modeling.\n",
    "\n",
    "- $self\\_attention$ just means that the keys and values are produced from the same source as queries. \n",
    "- In $cross\\_attention$, the queries still get produced from x, but the keys and values come from some other, external source (e.g. an encoder module)\n",
    "\n",
    "- \"Scaled\" attention additional divides `weights` by `1/sqrt(head_size)`. This makes it so when input `Q,K` are `unit variance`, `weights` will be unit variance too and `softmax` will stay diffuse and not saturate too much. Illustration below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15e11b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d8830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c71add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tldr: this is:\n",
    "#  - weighted aggregation of information from previous tokens\n",
    "#  - allows it to change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
