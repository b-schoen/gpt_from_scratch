{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3674b7-cdcf-411d-80c5-ca44b425ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c7d994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "15ad612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "import rich.table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaaf1cc",
   "metadata": {},
   "source": [
    "# HookedTransformer\n",
    "\n",
    "* [TransformerLens - Tutorial - Trains HookedTransformer from Scratch](https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/No_Position_Experiment.ipynb)\n",
    "\n",
    "```python\n",
    "import transformers\n",
    "\n",
    "# note: it's probably easier to just operate on tokens outside of the model,\n",
    "#       that'll also make it clearer where tokenizer is used\n",
    "#\n",
    "# okay wrapping a pretrained tokenizer *can* be done:\n",
    "# - https://huggingface.co/learn/nlp-course/chapter6/8#building-a-bpe-tokenizer-from-scratch\n",
    "# - but none of the models support just naive encoding\n",
    "#   - https://huggingface.co/docs/tokenizers/api/models#tokenizers.models.BPE\n",
    "class HookedTransformer:\n",
    "    cfg: HookedTransformerConfig\n",
    "\n",
    "    # note: actually does an `isinstance` check in the constructor\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase | None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76467a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "\n",
    "from jaxtyping import Int64, Float32\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import torch\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd75509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting code copied over from transformer_lens tutorial notebook\n",
    "\n",
    "\n",
    "def line(tensor: torch.Tensor, line_labels=None, yaxis=\"\", xaxis=\"\", **kwargs):\n",
    "    tensor = transformer_lens.utils.to_numpy(tensor)\n",
    "    labels = {\"y\": yaxis, \"x\": xaxis}\n",
    "    fig = px.line(tensor, labels=labels, **kwargs)\n",
    "    if line_labels:\n",
    "        for c, label in enumerate(line_labels):\n",
    "            fig.data[c].name = label\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def imshow(tensor: torch.Tensor, yaxis=\"\", xaxis=\"\", **kwargs):\n",
    "    tensor = transformer_lens.utils.to_numpy(tensor)\n",
    "    plot_kwargs = {\n",
    "        \"color_continuous_scale\": \"RdBu\",\n",
    "        \"color_continuous_midpoint\": 0.0,\n",
    "        \"labels\": {\"x\": xaxis, \"y\": yaxis},\n",
    "    }\n",
    "    plot_kwargs.update(kwargs)\n",
    "    px.imshow(tensor, **plot_kwargs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5605e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = transformer_lens.utils.get_device()\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e9839",
   "metadata": {},
   "source": [
    "### Setup Sample Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "70bd2cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<aa|aa>>>>>>>',\n",
       " '<ab|ab>>>>>>>',\n",
       " '<ac|ac>>>>>>>',\n",
       " '<ad|ad>>>>>>>',\n",
       " '<ae|ae>>>>>>>',\n",
       " '<af|af>>>>>>>',\n",
       " '<ag|ag>>>>>>>',\n",
       " '<ah|ah>>>>>>>',\n",
       " '<ai|ai>>>>>>>',\n",
       " '<aj|aj>>>>>>>']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import itertools\n",
    "import more_itertools\n",
    "\n",
    "\n",
    "class SpecialToken:\n",
    "    # note: as assume a BOS token because transformerlens expects it\n",
    "    BOS = \"<\"\n",
    "    # we use a EOS token for convenience\n",
    "    EOS = \">\"\n",
    "\n",
    "\n",
    "# note: without length, the model doesn't need to learn induction heads, just directly copies\n",
    "\n",
    "\n",
    "# TODO(bschoen): Allow this to generalize in the future\n",
    "#\n",
    "# Good for purely attention, since seeing patterns\n",
    "def generate_sample_palindrome_then_repeated() -> Iterable[str]:\n",
    "    \"\"\"Generate palindrom samples like `<abc|cba|abc>`.\"\"\"\n",
    "\n",
    "    # Generate all combinations of lowercase letters\n",
    "    characters = string.ascii_lowercase\n",
    "\n",
    "    # note: chosen arbitrarily\n",
    "    lengths = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "    # pad to max length\n",
    "    max_length = (\n",
    "        1 + max(lengths) + 1 + max(lengths) + 1 + max(lengths) + 1 + max(lengths) + 1\n",
    "    )\n",
    "\n",
    "    # set max number to take of each length\n",
    "    max_combinations_per_length = 10000\n",
    "\n",
    "    for length in lengths:\n",
    "\n",
    "        for combination_index, combination in enumerate(\n",
    "            itertools.product(characters, repeat=length)\n",
    "        ):\n",
    "\n",
    "            if combination_index > max_combinations_per_length:\n",
    "                break\n",
    "\n",
    "            combination_str = \"\".join(combination)\n",
    "            reversed_str = \"\".join(reversed(combination_str))\n",
    "\n",
    "            sample = (\n",
    "                SpecialToken.BOS\n",
    "                + combination_str\n",
    "                + \"|\"\n",
    "                + reversed_str\n",
    "                + \"|\"\n",
    "                + combination_str\n",
    "                + SpecialToken.EOS\n",
    "            )\n",
    "\n",
    "            # Pad the sample to max_length with EOS tokens\n",
    "            padded_sample = sample.ljust(max_length, SpecialToken.EOS)\n",
    "\n",
    "            yield padded_sample  # Return the padded sample\n",
    "\n",
    "\n",
    "# TODO(bschoen): For this do we get like a \"next biggest\" head?\n",
    "# TODO(bschoen): Can we do circuit analysis on this?\n",
    "def generate_sample_sorted() -> Iterable[str]:\n",
    "    \"\"\"Generate sequence sorted `<cab|abc>`.\"\"\"\n",
    "\n",
    "    # Generate all combinations of lowercase letters\n",
    "    characters = string.ascii_lowercase\n",
    "\n",
    "    # note: chosen arbitrarily\n",
    "    # lengths = [3, 4, 5, 6, 7]\n",
    "    lengths = [2, 3, 4, 5]  # , 6, 7]\n",
    "\n",
    "    # pad to max length\n",
    "    max_length = 1 + max(lengths) + 1 + max(lengths) + 1\n",
    "\n",
    "    # set max number to take of each length\n",
    "    # max_combinations_per_length = 10000\n",
    "\n",
    "    for length in lengths:\n",
    "\n",
    "        for combination_index, combination in enumerate(\n",
    "            itertools.product(characters, repeat=length)\n",
    "        ):\n",
    "\n",
    "            # if combination_index > max_combinations_per_length:\n",
    "            #    break\n",
    "\n",
    "            combination_str = \"\".join(combination)\n",
    "            sorted_str = \"\".join(sorted(combination_str))\n",
    "\n",
    "            sample = (\n",
    "                SpecialToken.BOS + combination_str + \"|\" + sorted_str + SpecialToken.EOS\n",
    "            )\n",
    "\n",
    "            # Pad the sample to max_length with EOS tokens\n",
    "            padded_sample = sample.ljust(max_length, SpecialToken.EOS)\n",
    "\n",
    "            yield padded_sample  # Return the padded sample\n",
    "\n",
    "\n",
    "generate_sample = generate_sample_sorted\n",
    "\n",
    "# show a few examples\n",
    "[x for x in more_itertools.take(10, generate_sample())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75a15d",
   "metadata": {},
   "source": [
    "### Setup Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "09afecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch.naive_tokenizer import NaiveTokenizer\n",
    "\n",
    "vocab = string.ascii_lowercase + \"|\" + SpecialToken.BOS + SpecialToken.EOS\n",
    "\n",
    "tokenizer = NaiveTokenizer.from_text(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e0f6b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t\t<abc|cba|abc><bd|db|bd>>>>\n",
      "Tokenized:\t\u001b[44m\u001b[97m<\u001b[0m\u001b[42m\u001b[97ma\u001b[0m\u001b[43m\u001b[97mb\u001b[0m\u001b[46m\u001b[97mc\u001b[0m\u001b[45m\u001b[97m|\u001b[0m\u001b[41m\u001b[97mc\u001b[0m\u001b[44m\u001b[97mb\u001b[0m\u001b[42m\u001b[97ma\u001b[0m\u001b[43m\u001b[97m|\u001b[0m\u001b[46m\u001b[97ma\u001b[0m\u001b[45m\u001b[97mb\u001b[0m\u001b[41m\u001b[97mc\u001b[0m\u001b[44m\u001b[97m>\u001b[0m\u001b[42m\u001b[97m<\u001b[0m\u001b[43m\u001b[97mb\u001b[0m\u001b[46m\u001b[97md\u001b[0m\u001b[45m\u001b[97m|\u001b[0m\u001b[41m\u001b[97md\u001b[0m\u001b[44m\u001b[97mb\u001b[0m\u001b[42m\u001b[97m|\u001b[0m\u001b[43m\u001b[97mb\u001b[0m\u001b[46m\u001b[97md\u001b[0m\u001b[45m\u001b[97m>\u001b[0m\u001b[41m\u001b[97m>\u001b[0m\u001b[44m\u001b[97m>\u001b[0m\u001b[42m\u001b[97m>\u001b[0m\n",
      "Token ID | Token Bytes | Token String\n",
      "---------+-------------+--------------\n",
      "       0 | \u001b[38;5;2m3C\u001b[0m | '<'\n",
      "          \u001b[48;5;1m\u001b[38;5;15m<\u001b[0mabc|cba|abc><bd|db|bd>>>>\n",
      "          U+003C LESS-THAN SIGN (1 bytes: \u001b[38;5;2m3C\u001b[0m)\n",
      "       2 | \u001b[38;5;2m61\u001b[0m | 'a'\n",
      "          <\u001b[48;5;1m\u001b[38;5;15ma\u001b[0mbc|cba|abc><bd|db|bd>>>>\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <a\u001b[48;5;1m\u001b[38;5;15mb\u001b[0mc|cba|abc><bd|db|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       4 | \u001b[38;5;2m63\u001b[0m | 'c'\n",
      "          <ab\u001b[48;5;1m\u001b[38;5;15mc\u001b[0m|cba|abc><bd|db|bd>>>>\n",
      "          U+0063 LATIN SMALL LETTER C (1 bytes: \u001b[38;5;2m63\u001b[0m)\n",
      "      28 | \u001b[38;5;2m7C\u001b[0m | '|'\n",
      "          <abc\u001b[48;5;1m\u001b[38;5;15m|\u001b[0mcba|abc><bd|db|bd>>>>\n",
      "          U+007C VERTICAL LINE (1 bytes: \u001b[38;5;2m7C\u001b[0m)\n",
      "       4 | \u001b[38;5;2m63\u001b[0m | 'c'\n",
      "          <abc|\u001b[48;5;1m\u001b[38;5;15mc\u001b[0mba|abc><bd|db|bd>>>>\n",
      "          U+0063 LATIN SMALL LETTER C (1 bytes: \u001b[38;5;2m63\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|c\u001b[48;5;1m\u001b[38;5;15mb\u001b[0ma|abc><bd|db|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       2 | \u001b[38;5;2m61\u001b[0m | 'a'\n",
      "          <abc|cb\u001b[48;5;1m\u001b[38;5;15ma\u001b[0m|abc><bd|db|bd>>>>\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "      28 | \u001b[38;5;2m7C\u001b[0m | '|'\n",
      "          <abc|cba\u001b[48;5;1m\u001b[38;5;15m|\u001b[0mabc><bd|db|bd>>>>\n",
      "          U+007C VERTICAL LINE (1 bytes: \u001b[38;5;2m7C\u001b[0m)\n",
      "       2 | \u001b[38;5;2m61\u001b[0m | 'a'\n",
      "          <abc|cba|\u001b[48;5;1m\u001b[38;5;15ma\u001b[0mbc><bd|db|bd>>>>\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|cba|a\u001b[48;5;1m\u001b[38;5;15mb\u001b[0mc><bd|db|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       4 | \u001b[38;5;2m63\u001b[0m | 'c'\n",
      "          <abc|cba|ab\u001b[48;5;1m\u001b[38;5;15mc\u001b[0m><bd|db|bd>>>>\n",
      "          U+0063 LATIN SMALL LETTER C (1 bytes: \u001b[38;5;2m63\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m<bd|db|bd>>>>\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n",
      "       0 | \u001b[38;5;2m3C\u001b[0m | '<'\n",
      "          <abc|cba|abc>\u001b[48;5;1m\u001b[38;5;15m<\u001b[0mbd|db|bd>>>>\n",
      "          U+003C LESS-THAN SIGN (1 bytes: \u001b[38;5;2m3C\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|cba|abc><\u001b[48;5;1m\u001b[38;5;15mb\u001b[0md|db|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       5 | \u001b[38;5;2m64\u001b[0m | 'd'\n",
      "          <abc|cba|abc><b\u001b[48;5;1m\u001b[38;5;15md\u001b[0m|db|bd>>>>\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "      28 | \u001b[38;5;2m7C\u001b[0m | '|'\n",
      "          <abc|cba|abc><bd\u001b[48;5;1m\u001b[38;5;15m|\u001b[0mdb|bd>>>>\n",
      "          U+007C VERTICAL LINE (1 bytes: \u001b[38;5;2m7C\u001b[0m)\n",
      "       5 | \u001b[38;5;2m64\u001b[0m | 'd'\n",
      "          <abc|cba|abc><bd|\u001b[48;5;1m\u001b[38;5;15md\u001b[0mb|bd>>>>\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|cba|abc><bd|d\u001b[48;5;1m\u001b[38;5;15mb\u001b[0m|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "      28 | \u001b[38;5;2m7C\u001b[0m | '|'\n",
      "          <abc|cba|abc><bd|db\u001b[48;5;1m\u001b[38;5;15m|\u001b[0mbd>>>>\n",
      "          U+007C VERTICAL LINE (1 bytes: \u001b[38;5;2m7C\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|cba|abc><bd|db|\u001b[48;5;1m\u001b[38;5;15mb\u001b[0md>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       5 | \u001b[38;5;2m64\u001b[0m | 'd'\n",
      "          <abc|cba|abc><bd|db|b\u001b[48;5;1m\u001b[38;5;15md\u001b[0m>>>>\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc><bd|db|bd\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m>>>\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc><bd|db|bd>\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m>>\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc><bd|db|bd>>\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m>\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc><bd|db|bd>>>\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "from gpt_from_scratch import tokenizer_utils\n",
    "\n",
    "# test tokenizer\n",
    "input_text = \"<abc|cba|abc><bd|db|bd>>>>\"\n",
    "tokenizer_utils.show_token_mapping(tokenizer, input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152a119",
   "metadata": {},
   "source": [
    "### Setup Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "268db8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, target):\n",
    "    # standard cross entropy loss\n",
    "    return torch.nn.functional.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        target.view(-1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f67052",
   "metadata": {},
   "source": [
    "### Evaluate On Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e610984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss_on_test_batches(\n",
    "    model: transformer_lens.HookedTransformer,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    max_batches: int,\n",
    ") -> float:\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "\n",
    "        for batch_index, batch in enumerate(data_loader):\n",
    "\n",
    "            if batch_index > max_batches:\n",
    "                break\n",
    "\n",
    "            x, y = batch\n",
    "\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c7b6f",
   "metadata": {},
   "source": [
    "### Setup Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "43250038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoregressiveDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples: list[str], tokenizer: NaiveTokenizer) -> None:\n",
    "        self.samples = samples\n",
    "        self.tokenizer = tokenizer  # Assuming tokenizer is defined in the global scope\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        tokens = self.tokenizer.encode(sample)\n",
    "\n",
    "        # Convert to tensor and add batch dimension\n",
    "        x = torch.tensor(tokens[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(tokens[1:], dtype=torch.long)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def make_batch_dataloader(\n",
    "    samples: list[str],\n",
    "    tokenizer: NaiveTokenizer,\n",
    "    batch_size: int,\n",
    ") -> tuple[torch.utils.data.Dataset, torch.utils.data.DataLoader]:\n",
    "\n",
    "    dataset = AutoregressiveDataset(samples=samples, tokenizer=tokenizer)\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        # drop the last batch if it's incomplete\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# batch_generator = make_batch_generator(tokenizer, batch_size=4)\n",
    "# for x, y in batch_generator:\n",
    "#     # x is input, y is target (x shifted by 1)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b7cdd9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12356604 samples\n",
      "len(train_samples)=9885284\n",
      "len(test_samples)=2471320\n",
      "12: 2376204\n",
      "10: 91398\n",
      "8: 3578\n",
      "6: 140\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# split into test and train\n",
    "all_samples = list(generate_sample())\n",
    "\n",
    "# note: 4394 batches = (26 * 26 * 26) / 4\n",
    "print(f\"{len(all_samples)} samples\")\n",
    "\n",
    "# Randomly shuffle all_samples\n",
    "random.shuffle(all_samples)  # In-place shuffling of the list\n",
    "\n",
    "# Inline comment explaining the motivation\n",
    "# We shuffle the samples to ensure a random distribution of data points\n",
    "# between the training and test sets, reducing potential bias\n",
    "\n",
    "\n",
    "# max_samples = 10\n",
    "# print(f'Capping at {max_samples} batches first to make sure we can overfit')\n",
    "# all_samples = all_samples[:max_samples]\n",
    "\n",
    "test_train_ratio = 0.2\n",
    "\n",
    "test_size = int(test_train_ratio * len(all_samples))\n",
    "\n",
    "# put remaining ones into train\n",
    "train_size = len(all_samples) - test_size\n",
    "\n",
    "train_samples = all_samples[:train_size]\n",
    "test_samples = all_samples[train_size:]\n",
    "\n",
    "print(f\"{len(train_samples)=}\")\n",
    "print(f\"{len(test_samples)=}\")\n",
    "\n",
    "# now we can finally construct dataloaders\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset, train_loader = make_batch_dataloader(\n",
    "    samples=train_samples,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "# Split test_samples based on the number of '>' characters\n",
    "test_samples_by_difficulty = {}\n",
    "for sample in test_samples:\n",
    "    difficulty = len(sample) - sample.count(\">\")\n",
    "    if difficulty not in test_samples_by_difficulty:\n",
    "        test_samples_by_difficulty[difficulty] = []\n",
    "    test_samples_by_difficulty[difficulty].append(sample)\n",
    "\n",
    "# Sort the dictionary by difficulty (number of '>' characters)\n",
    "test_samples_by_difficulty = dict(\n",
    "    sorted(test_samples_by_difficulty.items(), reverse=True)\n",
    ")\n",
    "\n",
    "# Inline comment explaining the motivation\n",
    "# We sort the dictionary by difficulty to ensure a consistent order\n",
    "# when iterating through the difficulty levels, making it easier to\n",
    "# analyze and compare model performance across increasing complexities\n",
    "\n",
    "for difficulty, samples in test_samples_by_difficulty.items():\n",
    "    print(f\"{difficulty}: {len(samples)}\")\n",
    "\n",
    "# Create dataloaders for each difficulty level\n",
    "test_datasets = {}\n",
    "test_loaders = {}\n",
    "for difficulty, samples in test_samples_by_difficulty.items():\n",
    "    test_datasets[difficulty], test_loaders[difficulty] = make_batch_dataloader(\n",
    "        samples=samples,\n",
    "        tokenizer=tokenizer,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "# Inline comment explaining the motivation\n",
    "# We split the test samples based on the number of '>' characters to create\n",
    "# separate datasets for different difficulty levels. This allows us to evaluate\n",
    "# the model's performance across varying complexities of input sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf7e574",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "19115680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we know our vocab size from our sample generation\n",
    "def make_hooked_transformer_config(\n",
    "    n_layers: int,\n",
    "    d_model: int,\n",
    "    n_heads: int,\n",
    ") -> transformer_lens.HookedTransformerConfig:\n",
    "\n",
    "    for sample in generate_sample():\n",
    "        n_ctx = len(sample)\n",
    "        break\n",
    "\n",
    "    cfg = transformer_lens.HookedTransformerConfig(\n",
    "        n_layers=n_layers,\n",
    "        d_model=d_model,\n",
    "        d_head=d_model // n_heads,\n",
    "        # The number of attention heads.\n",
    "        # If not specified, will be set to d_in // d_head.\n",
    "        # (This is represented by a default value of -1)\n",
    "        n_heads=n_heads,\n",
    "        # The dimensionality of the feedforward mlp network.\n",
    "        # Defaults to 4 * d_in, and in an attn-only model is None.\n",
    "        # TODO(bschoen): Need to try out also setting `attn_only`\n",
    "        # d_mlp=None,\n",
    "        # note: transformerlens does the same thing if this is not set\n",
    "        d_vocab=len(tokenizer.byte_to_token_dict),\n",
    "        # length of the longest sample is our context length\n",
    "        n_ctx=n_ctx,\n",
    "        act_fn=\"relu\",\n",
    "        normalization_type=\"LN\",\n",
    "        # note: must be set, otherwise tries to default to cuda / cpu (not mps)\n",
    "        device=device.type,\n",
    "    )\n",
    "\n",
    "    print(f\"Num params: {cfg.n_params}\")\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a131f",
   "metadata": {},
   "source": [
    "## Setup Image Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4f4d3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert matplotlib figure to PNG for wandb upload\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "from jaxtyping import Float\n",
    "\n",
    "\n",
    "def fig_to_wandb_image(fig) -> Image:\n",
    "    \"\"\"\n",
    "    Convert a matplotlib figure to a PNG image that can be uploaded to wandb.\n",
    "\n",
    "    Args:\n",
    "        fig (matplotlib.figure.Figure): The matplotlib figure to convert\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The figure as a PIL Image object\n",
    "    \"\"\"\n",
    "    # Save the figure to a byte buffer\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=300, bbox_inches=\"tight\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Convert the buffer to a PIL Image\n",
    "    image = Image.open(buf)\n",
    "    return image\n",
    "\n",
    "\n",
    "# note: `title` is passed in for telling them apart in gifs etc\n",
    "def generate_image_for_attention_patterns(\n",
    "    input_token_str_to_cache_dict: dict[str, transformer_lens.ActivationCache],\n",
    "    title: str,\n",
    ") -> Image:\n",
    "    \"\"\"\n",
    "    Visualize attention patterns for all layers and heads in the model for multiple caches.\n",
    "\n",
    "    Args:\n",
    "        caches (List[Dict[str, Any]]): List of caches containing attention patterns from model forward passes.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: A matplotlib figure containing the visualized attention patterns.\n",
    "    \"\"\"\n",
    "    input_token_strings = list(input_token_str_to_cache_dict.keys())\n",
    "    caches = list(input_token_str_to_cache_dict.values())\n",
    "\n",
    "    # Find all attention pattern tensors in the first cache (assuming all caches have the same structure)\n",
    "    pattern_keys = [\n",
    "        key for key in caches[0].keys() if key.endswith(\".attn.hook_pattern\")\n",
    "    ]\n",
    "\n",
    "    n_layers = len(pattern_keys)\n",
    "    n_heads = caches[0][pattern_keys[0]].shape[1]\n",
    "    n_caches = len(caches)\n",
    "\n",
    "    # Calculate total number of subplots\n",
    "    total_subplots = n_layers * n_heads\n",
    "\n",
    "    # Create a figure with subplots stacked vertically for each cache\n",
    "    fig, axes = plt.subplots(\n",
    "        n_caches, total_subplots, figsize=(4 * total_subplots, 4 * n_caches)\n",
    "    )\n",
    "\n",
    "    # Set overall figure title\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    # Color maps for alternating heads\n",
    "    cmaps = [\"Blues\", \"Reds\"]\n",
    "\n",
    "    for cache_idx, cache in enumerate(caches):\n",
    "        input_token_string = input_token_strings[cache_idx]\n",
    "        for layer, key in enumerate(pattern_keys):\n",
    "            attention_pattern = cache[key]\n",
    "\n",
    "            # Remove batch dimension and move to CPU\n",
    "            reshaped_pattern = attention_pattern.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "            for head in range(n_heads):\n",
    "                subplot_index = layer * n_heads + head\n",
    "                ax = (\n",
    "                    axes[cache_idx, subplot_index]\n",
    "                    if n_caches > 1\n",
    "                    else axes[subplot_index]\n",
    "                )\n",
    "\n",
    "                # Plot the attention pattern\n",
    "                im = ax.imshow(reshaped_pattern[head], cmap=cmaps[head % len(cmaps)])\n",
    "\n",
    "                # Set title for each subplot\n",
    "                ax.set_title(f\"L{layer}-H{head}\", fontsize=8)\n",
    "\n",
    "                # Set column labels as individual characters from input_token_string at the top\n",
    "                ax.xaxis.tick_top()\n",
    "                ax.set_xticks(range(len(input_token_string)))\n",
    "                ax.set_xticklabels(list(input_token_string), fontsize=6, ha=\"right\")\n",
    "\n",
    "                ax.set_yticks([])  # Remove y-axis ticks\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    image = fig_to_wandb_image(fig)\n",
    "\n",
    "    # close figure so doesn't keep taking up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "58e3c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def convert_pngs_in_directory_to_gif(output_dir: pathlib.Path) -> pathlib.Path:\n",
    "\n",
    "    # Get a list of all PNG files in the output directory\n",
    "    # Use rglob for recursive search of PNG files\n",
    "    png_files = list(output_dir.rglob(\"*.png\"))\n",
    "\n",
    "    # sort by step\n",
    "    #\n",
    "    # files have format\n",
    "    #\n",
    "    # - `.../<key>_<step>_<hash-identifier-thing>.png`\n",
    "    # - ex: `.../attention_100_d8bda3455ffb06855d88.png`\n",
    "    #\n",
    "    png_files = sorted(png_files, key=lambda x: int(x.name.split(\"_\")[1]))\n",
    "\n",
    "    # Create a list to store the image frames\n",
    "    frames = []\n",
    "\n",
    "    # Load each PNG file and append it to the frames list\n",
    "    print(f\"Generating gif from {len(png_files)} images...\")\n",
    "    for png_file in png_files:\n",
    "        # Open the image and convert it to RGB mode (required for GIF)\n",
    "        img = Image.open(str(png_file)).convert(\"RGB\")\n",
    "        frames.append(img)\n",
    "\n",
    "    # Define the output GIF filename\n",
    "    gif_filename = output_dir / \"attention_pattern_evolution.gif\"\n",
    "\n",
    "    # Save the frames as an animated GIF\n",
    "    print(f\"Saving gif from {len(frames)} frames to {gif_filename}...\")\n",
    "    frames[0].save(\n",
    "        gif_filename,\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        optimize=False,\n",
    "        duration=200,  # Duration between frames in milliseconds\n",
    "        loop=0,  # 0 means loop indefinitely\n",
    "    )\n",
    "\n",
    "    print(f\"GIF created and saved as: {gif_filename}\")\n",
    "\n",
    "    # Optionally, log the GIF to wandb\n",
    "    # wandb.log({\"attention_pattern_evolution\": wandb.Image(str(gif_filename))})\n",
    "\n",
    "    return gif_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0438238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbConstants:\n",
    "    ENTITY = \"bronsonschoen-personal-use\"\n",
    "    PROJECT = \"toy-problem-hooked-transformer-v3\"\n",
    "    NAME = \"toy-sequence\"\n",
    "    ATTENTION_PATTERN_IMAGES = \"attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65fc8dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossValue = float\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class TrainModelResult:\n",
    "    model: transformer_lens.HookedTransformer\n",
    "\n",
    "    # returned because optuna needs it\n",
    "    # TODO(bschoen): Is this usually val loss?\n",
    "    train_loss: LossValue\n",
    "\n",
    "    # useful to retrieve files\n",
    "    wandb_run_name: str\n",
    "    wandb_run_id: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54530e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pathlib\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def download_images_from_run(result: TrainModelResult) -> pathlib.Path:\n",
    "\n",
    "    # write things to run specific directory\n",
    "    output_dir = pathlib.Path(f\"wandb_artifacts/{result.wandb_run_id}\")\n",
    "\n",
    "    # create output dir if not exists\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    api = wandb.Api()\n",
    "\n",
    "    identifier = \"/\".join(\n",
    "        [\n",
    "            WandbConstants.ENTITY,\n",
    "            WandbConstants.PROJECT,\n",
    "            result.wandb_run_id,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"Downloading {identifier}...\")\n",
    "    run = api.run(identifier)\n",
    "\n",
    "    # filter down to just attention pattern images\n",
    "    files = [\n",
    "        x\n",
    "        for x in run.files()\n",
    "        if x.name.startswith(f\"media/images/{WandbConstants.ATTENTION_PATTERN_IMAGES}\")\n",
    "    ]\n",
    "\n",
    "    for file in tqdm.tqdm(desc=\"Downloading images...\", iterable=files):\n",
    "\n",
    "        print(f\"Downloading {file.name}\")\n",
    "        file.download(\n",
    "            root=str(output_dir),\n",
    "            replace=False,\n",
    "            exist_ok=True,\n",
    "            api=api,\n",
    "        )\n",
    "\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003ea31",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f5081e3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7533cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(bschoen): Holdout set of n+1 length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ac160424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params: 6144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bronsonschoen/gpt_from_scratch/wandb/run-20240912_183842-y07bmj07</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3/runs/y07bmj07' target=\"_blank\">toy-sequence</a></strong> to <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3/runs/y07bmj07' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3/runs/y07bmj07</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name toy-sequence - y07bmj07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "997it [00:29, 46.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1996it [00:54, 46.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2996it [01:20, 46.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3996it [01:46, 43.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [02:13, 45.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5996it [02:40, 44.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6997it [03:08, 44.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8000it [03:35, 45.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9000it [04:01, 42.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9996it [04:29, 48.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10998it [04:55, 46.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11998it [05:22, 46.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12998it [05:48, 47.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13999it [06:14, 42.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14998it [06:39, 48.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15998it [07:04, 48.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16998it [07:29, 47.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18000it [07:55, 44.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19000it [08:21, 48.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19998it [08:47, 47.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20997it [09:12, 42.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21997it [09:37, 49.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22996it [10:01, 49.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23997it [10:26, 48.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25000it [10:51, 38.39it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300816207b7a4be5aced87d557c4743f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.484 MB of 3.484 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>test_loss_difficulty_10</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss_difficulty_12</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss_difficulty_6</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▁▂</td></tr><tr><td>test_loss_difficulty_8</td><td>█▄▅▄▄▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24000</td></tr><tr><td>test_loss_difficulty_10</td><td>1.3682</td></tr><tr><td>test_loss_difficulty_12</td><td>1.36596</td></tr><tr><td>test_loss_difficulty_6</td><td>2.02947</td></tr><tr><td>test_loss_difficulty_8</td><td>1.50503</td></tr><tr><td>train_loss</td><td>1.36459</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toy-sequence</strong> at: <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3/runs/y07bmj07' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3/runs/y07bmj07</a><br/> View project at: <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v3</a><br/>Synced 5 W&B file(s), 25 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240912_183842-y07bmj07/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train loss: 1.363202\n",
      "Num params: 6144\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "import torch.optim\n",
    "\n",
    "import wandb\n",
    "\n",
    "import dataclasses\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def print_json(value):\n",
    "    print(json.dumps(value, indent=2))\n",
    "\n",
    "\n",
    "# everything customizable via optuna\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ModelAndTrainingConfig:\n",
    "\n",
    "    # input\n",
    "    train_loader: torch.utils.data.DataLoader\n",
    "    test_loaders: dict[int, torch.utils.data.DataLoader]\n",
    "\n",
    "    # training\n",
    "    num_epochs: int = 10000\n",
    "    eval_test_every_n: int = 500\n",
    "    wait_between_eval_s: int | None = None\n",
    "\n",
    "    # model\n",
    "    n_layers: int = 2\n",
    "    d_model: int = 16\n",
    "    n_heads: int = 2\n",
    "\n",
    "    # optimizers\n",
    "    betas: tuple[float, float] = (0.9, 0.999)\n",
    "    learning_rate: float = 1e-3\n",
    "    max_grad_norm: float = 1.0\n",
    "    weight_decay: float = 0.1\n",
    "\n",
    "    def get_hooked_transformer_config(self) -> transformer_lens.HookedTransformerConfig:\n",
    "        return make_hooked_transformer_config(\n",
    "            n_layers=self.n_layers,\n",
    "            d_model=self.d_model,\n",
    "            n_heads=self.n_heads,\n",
    "        )\n",
    "\n",
    "    def to_dict(self) -> dict[str, str | int]:\n",
    "        dict_repr = dataclasses.asdict(self)\n",
    "        dict_repr.pop(\"train_loader\")\n",
    "        dict_repr.pop(\"test_loaders\")\n",
    "        return dict_repr\n",
    "\n",
    "\n",
    "def train_model(cfg: ModelAndTrainingConfig) -> TrainModelResult:\n",
    "\n",
    "    # create new model instance\n",
    "    ht_cfg = cfg.get_hooked_transformer_config()\n",
    "    model = transformer_lens.HookedTransformer(ht_cfg)\n",
    "\n",
    "    # setup optimizers\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg.learning_rate,\n",
    "        betas=cfg.betas,\n",
    "        weight_decay=cfg.weight_decay,\n",
    "    )\n",
    "    # scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    #    optimizer, lambda i: min(i / 100, 1.0)\n",
    "    # )\n",
    "\n",
    "    num_epochs = cfg.num_epochs\n",
    "\n",
    "    # setup wandb\n",
    "    wandb.init(\n",
    "        project=WandbConstants.PROJECT,\n",
    "        name=WandbConstants.NAME,\n",
    "        config=cfg.to_dict(),\n",
    "    )\n",
    "\n",
    "    print(f\"Run name {wandb.run.name} - {wandb.run.id}\")\n",
    "\n",
    "    # create a small (fixed) training set of each difficulty to use for visualization\n",
    "    test_example_per_difficulty = {}\n",
    "    for difficulty, test_loader in cfg.test_loaders.items():\n",
    "        # grab something from the test batch\n",
    "        x, _ = next(iter(test_loader))\n",
    "        input_tokens = x[0].to(device)\n",
    "        test_example_per_difficulty[difficulty] = input_tokens\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch, batch in tqdm.tqdm(\n",
    "        zip(\n",
    "            range(num_epochs),\n",
    "            itertools.cycle(train_loader),\n",
    "        )\n",
    "    ):\n",
    "\n",
    "        tokens, target = batch\n",
    "\n",
    "        tokens, target = tokens.to(device), target.to(device)\n",
    "\n",
    "        # ex: torch.Size([4, 9, 29])\n",
    "        logits: Float32[torch.Tensor, \"b t c\"] = model(tokens)\n",
    "\n",
    "        # print(f\"Logits:\\n{logits.shape}\")\n",
    "        loss = loss_fn(logits, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if cfg.max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # more frequently than eval, print out train loss\n",
    "        # if (epoch % (cfg.eval_test_every_n // 10)) == 0:\n",
    "        #\n",
    "        #    print(f\"Epoch {epoch}, \" f\"Train loss: {loss.item():.6f}\")\n",
    "\n",
    "        # TODO(bschoen): Shouldn't you actually divide loss by batch size?\n",
    "        # TODO(bschoen): Do we want like an `is trial` (for example logging last one)\n",
    "        if (epoch % cfg.eval_test_every_n) == 0:\n",
    "\n",
    "            # skip evaluating test loss if we just started training\n",
    "            # if epoch == 0:\n",
    "            #    continue\n",
    "\n",
    "            print(\"Evaluating test loss...\")\n",
    "\n",
    "            # compute loss at each difficulty\n",
    "            test_loss_by_difficulty = {}\n",
    "\n",
    "            for difficulty, test_loader in cfg.test_loaders.items():\n",
    "\n",
    "                test_loss = evaluate_loss_on_test_batches(\n",
    "                    model,\n",
    "                    test_loader,\n",
    "                    max_batches=100,\n",
    "                )\n",
    "\n",
    "                test_loss_by_difficulty[difficulty] = test_loss\n",
    "\n",
    "            wandb_log_dict = {\"epoch\": epoch, \"train_loss\": loss.item()}\n",
    "\n",
    "            for difficulty, test_loss in test_loss_by_difficulty.items():\n",
    "\n",
    "                wandb_log_dict[f\"test_loss_difficulty_{difficulty}\"] = test_loss\n",
    "\n",
    "            # print_json(wandb_log_dict)\n",
    "\n",
    "            # Log metrics\n",
    "            wandb.log(wandb_log_dict, step=epoch)\n",
    "\n",
    "            # Compute attention pattern visualization\n",
    "            print(\"Computing attention pattern visualization...\")\n",
    "            model.eval()\n",
    "            test_example_string_to_cache = {}\n",
    "\n",
    "            for difficulty, input_tokens in test_example_per_difficulty.items():\n",
    "\n",
    "                logits, cache = model.run_with_cache(input_tokens)\n",
    "\n",
    "                # store example by using the actual text string as key\n",
    "                input_tokens_str = \"\".join(\n",
    "                    [tokenizer.decode([x.item()]) for x in input_tokens]\n",
    "                )\n",
    "\n",
    "                test_example_string_to_cache[input_tokens_str] = cache\n",
    "\n",
    "            image = generate_image_for_attention_patterns(\n",
    "                test_example_string_to_cache,\n",
    "                title=f\"Step: {epoch}\",\n",
    "            )\n",
    "\n",
    "            wandb.log(\n",
    "                {WandbConstants.ATTENTION_PATTERN_IMAGES: wandb.Image(image)},\n",
    "                step=epoch,\n",
    "            )\n",
    "\n",
    "            if cfg.wait_between_eval_s and cfg.wait_between_eval_s is not None:\n",
    "                print(\n",
    "                    f\"Sleeping for {cfg.wait_between_eval_s} to avoid wandb rate limiting\"\n",
    "                )\n",
    "                time.sleep(cfg.wait_between_eval_s)\n",
    "\n",
    "    # capture run name and id before `finish`\n",
    "    wandb_run_name = wandb.run.name\n",
    "    wandb_run_id = wandb.run.id\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    # log locally to sanity check\n",
    "    # px.line(losses, labels={\"x\": \"Epoch\", \"y\": \"Train Loss\"})\n",
    "\n",
    "    print(f\"Final train loss: {loss.item():.6f}\")\n",
    "\n",
    "    # take model out of train\n",
    "    model.eval()\n",
    "\n",
    "    return TrainModelResult(\n",
    "        model=model,\n",
    "        train_loss=loss.item(),\n",
    "        wandb_run_name=wandb_run_name,\n",
    "        wandb_run_id=wandb_run_id,\n",
    "    )\n",
    "\n",
    "\n",
    "# train brief run to test code\n",
    "training_config = ModelAndTrainingConfig(\n",
    "    num_epochs=25000,\n",
    "    eval_test_every_n=1000,\n",
    "    weight_decay=0.1,\n",
    "    wait_between_eval_s=None,\n",
    "    train_loader=train_loader,\n",
    "    test_loaders=test_loaders,\n",
    ")\n",
    "\n",
    "result = train_model(training_config)\n",
    "\n",
    "# for compatibility with code later\n",
    "model = result.model\n",
    "cfg = training_config.get_hooked_transformer_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb1d023",
   "metadata": {},
   "source": [
    "## Save Output Image To Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e37ad4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading bronsonschoen-personal-use/toy-problem-hooked-transformer-v3/y07bmj07...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_0_40209ede86ce5e85fce3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:   4%|▍         | 1/25 [00:00<00:12,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_10000_4714e8d3cddfe0915df2.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:   8%|▊         | 2/25 [00:01<00:11,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_1000_adafa1a644a75e7057da.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  12%|█▏        | 3/25 [00:01<00:12,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_11000_6be3c17695fba2dbd0d9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  16%|█▌        | 4/25 [00:02<00:11,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_12000_95068dd82d1a846023d1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  20%|██        | 5/25 [00:02<00:10,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_13000_3d71f1c8c3b2d5099a00.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  24%|██▍       | 6/25 [00:03<00:10,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_14000_0ebe4843c650e6d36b7f.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  28%|██▊       | 7/25 [00:03<00:09,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_15000_d46b6bb3a25fd5fbf67e.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  32%|███▏      | 8/25 [00:04<00:09,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_16000_ff1253479b413f2af526.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  36%|███▌      | 9/25 [00:04<00:08,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_17000_fcfe2560853bab5a161e.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  40%|████      | 10/25 [00:05<00:08,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_18000_d44da1d5c7e98eebe8f3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  44%|████▍     | 11/25 [00:05<00:07,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_19000_96de678a132f8b7bd72e.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  48%|████▊     | 12/25 [00:06<00:07,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_20000_d54d523b21a35ec1b62c.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  52%|█████▏    | 13/25 [00:07<00:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_2000_3a929ffeda1bdad2668b.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  56%|█████▌    | 14/25 [00:07<00:06,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_21000_7a26afbf7f404c110b96.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  60%|██████    | 15/25 [00:08<00:05,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_22000_ee0143887b61ce0cd969.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  64%|██████▍   | 16/25 [00:08<00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_23000_61ae44c2d8457ba06d9d.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  68%|██████▊   | 17/25 [00:09<00:04,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_24000_86a9e7ff07f981d43eb5.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  72%|███████▏  | 18/25 [00:10<00:04,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_3000_db1cbd6a18c4d88399fe.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  76%|███████▌  | 19/25 [00:10<00:03,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_4000_27fbb6f23d068e4f5146.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  80%|████████  | 20/25 [00:11<00:02,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_5000_9aa3f5e0519617220e21.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  84%|████████▍ | 21/25 [00:11<00:02,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_6000_0fa5db96b47afcfe6965.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  88%|████████▊ | 22/25 [00:12<00:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_7000_36321db52bcaca1035c7.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  92%|█████████▏| 23/25 [00:12<00:01,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_8000_dc1cbd265fb069b873a3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...:  96%|█████████▌| 24/25 [00:13<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading media/images/attention_9000_615974c240cc6ca293e0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images...: 100%|██████████| 25/25 [00:14<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating gif from 25 images...\n",
      "Saving gif from 25 frames to wandb_artifacts/y07bmj07/attention_pattern_evolution.gif...\n",
      "GIF created and saved as: wandb_artifacts/y07bmj07/attention_pattern_evolution.gif\n",
      "wandb_artifacts/y07bmj07/attention_pattern_evolution.gif\n"
     ]
    }
   ],
   "source": [
    "output_dir = download_images_from_run(result=result)\n",
    "\n",
    "gif_filepath = convert_pngs_in_directory_to_gif(output_dir=output_dir)\n",
    "\n",
    "print(gif_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b70a9",
   "metadata": {},
   "source": [
    "## Indirect Object Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e07efb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import circuitsvis as cv\n",
    "\n",
    "\n",
    "def add_batch_dimension(\n",
    "    x: Float32[torch.Tensor, \"...\"]\n",
    ") -> Float32[torch.Tensor, \"batch ...\"]:\n",
    "    return einops.rearrange(x, \"... -> 1 ...\")\n",
    "\n",
    "\n",
    "def tokenize_string(input_string: str) -> Float32[torch.Tensor, \"seq\"]:\n",
    "\n",
    "    tokens = tokenizer.encode(input_string)\n",
    "\n",
    "    return torch.tensor(tokens, dtype=torch.long).to(device)\n",
    "\n",
    "\n",
    "def tokenize_string_as_batch(input_string: str) -> Float32[torch.Tensor, \"batch seq\"]:\n",
    "\n",
    "    return add_batch_dimension(tokenize_string(input_string))\n",
    "\n",
    "\n",
    "def get_first_mismatched_pair(\n",
    "    tokens_a: Float32[torch.Tensor, \"batch=1 seq\"],\n",
    "    tokens_b: Float32[torch.Tensor, \"batch=1 seq\"],\n",
    ") -> Float32[torch.Tensor, \"batch=1 2\"]:\n",
    "\n",
    "    assert tokens_a.shape == tokens_b.shape\n",
    "\n",
    "    for index in range(tokens_a.shape[-1]):\n",
    "\n",
    "        if tokens_a[0, index] != tokens_b[0, index]:\n",
    "\n",
    "            mismatch: Float32[torch.Tensor, \"2\"] = torch.tensor(\n",
    "                [\n",
    "                    tokens_a[0, index],\n",
    "                    tokens_b[0, index],\n",
    "                ]\n",
    "            ).to(device)\n",
    "\n",
    "            return add_batch_dimension(mismatch)\n",
    "\n",
    "\n",
    "# create a custom to_string function since using our own tokenizer\n",
    "def token_to_string(token: int) -> str:\n",
    "    return tokenizer.decode([token])\n",
    "\n",
    "\n",
    "# TODO(bschoen): Vary along things besides reversal\n",
    "\n",
    "# take an example, modify the first part of the sequence reversal to be wrong\n",
    "input_string = \"<az|\"\n",
    "correct_string = \"<az|a\"  # a|az>>>>>>>>>>>>>>>>>>>>>>>>\"\n",
    "incorrect_string = \"<az|z\"  # \"a|az>>>>>>>>>>>>>>>>>>>>>>>>\"\n",
    "\n",
    "input_string_tokens = tokenize_string_as_batch(input_string)\n",
    "correct_string_tokens = tokenize_string_as_batch(correct_string)\n",
    "incorrect_string_tokens = tokenize_string_as_batch(incorrect_string)\n",
    "\n",
    "logits, cache = model.run_with_cache(input_string_tokens)\n",
    "correct_logits, correct_cache = model.run_with_cache(correct_string_tokens)\n",
    "incorrect_logits, incorrect_cache = model.run_with_cache(incorrect_string_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "89497e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-c2ff6f85-045e\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, TokenLogProbs } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-c2ff6f85-045e\",\n",
       "      TokenLogProbs,\n",
       "      {\"prompt\": [\"<\", \"a\", \"z\", \"|\"], \"topKLogProbs\": [[-0.24078898131847382, -4.049549579620361, -4.063202857971191, -4.097551345825195, -4.1204118728637695, -4.152246952056885, -4.164917945861816, -4.198073863983154, -4.220837593078613, -4.244914531707764], [-0.314047247171402, -3.846364974975586, -3.853011131286621, -3.8696370124816895, -3.904911518096924, -3.9138436317443848, -3.9370949268341064, -3.9416143894195557, -3.978938579559326, -3.9905457496643066], [-3.0384976863861084, -3.1276373863220215, -3.153653621673584, -3.1795172691345215, -3.187739849090576, -3.2085835933685303, -3.211639404296875, -3.219111204147339, -3.220716953277588, -3.2231926918029785]], \"topKTokens\": [[\"a\", \"e\", \"l\", \"h\", \"f\", \"k\", \"c\", \"m\", \"j\", \"g\"], [\"a\", \"k\", \"l\", \"e\", \"i\", \"c\", \"g\", \"b\", \"j\", \"f\"], [\"a\", \"l\", \"d\", \"h\", \"j\", \"n\", \"b\", \"g\", \"e\", \"i\"]], \"correctTokenRank\": [0, 17, 26], \"correctTokenLogProb\": [-0.24078898131847382, -6.917020797729492, -4.346885681152344]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x4de6800b0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.logits.token_log_probs(\n",
    "    token_indices=input_string_tokens,\n",
    "    log_probs=logits.log_softmax(dim=-1),\n",
    "    to_string=token_to_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e8a02553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_token: 2 (a)\n",
      "incorrect_token: 27 (z)\n"
     ]
    }
   ],
   "source": [
    "# position where we changed the sequence\n",
    "mismatch_position_index = 4\n",
    "\n",
    "correct_token = correct_string_tokens[0, mismatch_position_index].item()\n",
    "incorrect_token = incorrect_string_tokens[0, mismatch_position_index].item()\n",
    "\n",
    "print(f\"correct_token: {correct_token} ({tokenizer.decode([correct_token])})\")\n",
    "print(f\"incorrect_token: {incorrect_token} ({tokenizer.decode([incorrect_token])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8153f90",
   "metadata": {},
   "source": [
    "### Logit Difference In Accumulated Residual Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c66789ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer_tokens.shape=torch.Size([1, 2])\n",
      "Answer residual directions shape: torch.Size([1, 2, 16])\n",
      "Logit difference directions shape: torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "# get diff in format expected by `model.tokens_to_residual_directions`\n",
    "answer_tokens = get_first_mismatched_pair(\n",
    "    correct_string_tokens,\n",
    "    incorrect_string_tokens,\n",
    ")\n",
    "\n",
    "print(f\"{answer_tokens.shape=}\")\n",
    "\n",
    "answer_residual_directions: Float32[torch.Tensor, \"batch 2 d_model\"] = (\n",
    "    model.tokens_to_residual_directions(answer_tokens)\n",
    ")\n",
    "\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "\n",
    "correct_residual_directions, incorrect_residual_directions = (\n",
    "    answer_residual_directions.unbind(dim=1)\n",
    ")\n",
    "correct_residual_directions: Float32[torch.Tensor, \"batch d_model\"] = (\n",
    "    correct_residual_directions\n",
    ")\n",
    "incorrect_residual_directions: Float32[torch.Tensor, \"batch d_model\"] = (\n",
    "    incorrect_residual_directions\n",
    ")\n",
    "\n",
    "logit_diff_directions: Float32[torch.Tensor, \"batch d_model\"] = (\n",
    "    correct_residual_directions - incorrect_residual_directions\n",
    ")\n",
    "\n",
    "print(f\"Logit difference directions shape:\", logit_diff_directions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "27f609ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_ave_logit_diff(\n",
    "    logits: Float[torch.Tensor, \"batch seq d_vocab\"],\n",
    "    answer_tokens: Float[torch.Tensor, \"batch 2\"],\n",
    "    per_prompt: bool = False,\n",
    ") -> Float[torch.Tensor, \"*batch\"]:\n",
    "    \"\"\"\n",
    "    Returns logit difference between the correct and incorrect answer.\n",
    "\n",
    "    If per_prompt=True, return the array of differences rather than the average.\n",
    "    \"\"\"\n",
    "    # SOLUTION\n",
    "    # Only the final logits are relevant for the answer\n",
    "    final_logits: Float[torch.Tensor, \"batch d_vocab\"] = logits[:, -1, :]\n",
    "    # Get the logits corresponding to the indirect object / subject tokens respectively\n",
    "    answer_logits: Float[torch.Tensor, \"batch 2\"] = final_logits.gather(\n",
    "        dim=-1, index=answer_tokens\n",
    "    )\n",
    "    # Find logit difference\n",
    "    correct_logits, incorrect_logits = answer_logits.unbind(dim=-1)\n",
    "    answer_logit_diff = correct_logits - incorrect_logits\n",
    "    return answer_logit_diff if per_prompt else answer_logit_diff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2cf3365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per prompt logit difference: tensor([-4.3593], device='mps:0', grad_fn=<SubBackward0>)\n",
      "Average logit difference: tensor(-4.3593, device='mps:0', grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "original_per_prompt_diff = logits_to_ave_logit_diff(\n",
    "    logits, answer_tokens, per_prompt=True\n",
    ")\n",
    "print(\"Per prompt logit difference:\", original_per_prompt_diff)\n",
    "original_average_logit_diff = logits_to_ave_logit_diff(logits, answer_tokens)\n",
    "print(\"Average logit difference:\", original_average_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44018d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final residual stream shape: torch.Size([1, 4, 16])\n",
      "Calculated average logit diff: -3.0110464096\n",
      "Original logit difference:     -4.3593158722\n"
     ]
    }
   ],
   "source": [
    "final_residual_stream = cache[\"resid_post\", -1]  # [batch seq d_model]\n",
    "print(f\"Final residual stream shape: {final_residual_stream.shape}\")\n",
    "final_token_residual_stream = final_residual_stream[:, -1, :]  # [batch d_model]\n",
    "\n",
    "# Apply LayerNorm scaling (to just the final sequence position)\n",
    "# pos_slice is the subset of the positions we take - here the final token of each prompt\n",
    "scaled_final_token_residual_stream = cache.apply_ln_to_stack(\n",
    "    final_token_residual_stream,\n",
    "    layer=-1,\n",
    "    pos_slice=-1,\n",
    ")\n",
    "\n",
    "batch_size = input_string_tokens.shape[0]\n",
    "\n",
    "average_logit_diff = (\n",
    "    einops.einsum(\n",
    "        scaled_final_token_residual_stream,\n",
    "        logit_diff_directions,\n",
    "        \"batch d_model, batch d_model ->\",\n",
    "    )\n",
    "    / batch_size\n",
    ")\n",
    "\n",
    "print(f\"Calculated average logit diff: {average_logit_diff:.10f}\")\n",
    "print(f\"Original logit difference:     {original_average_logit_diff:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "771a21fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack_to_logit_diff(\n",
    "    residual_stack: Float32[torch.Tensor, \"... batch d_model\"],\n",
    "    cache: transformer_lens.ActivationCache,\n",
    "    logit_diff_directions: Float[torch.Tensor, \"batch d_model\"],\n",
    ") -> Float32[torch.Tensor, \"...\"]:\n",
    "    \"\"\"\n",
    "    Gets the avg logit difference between the correct and incorrect answer for a given\n",
    "    stack of components in the residual stream.\n",
    "    \"\"\"\n",
    "    # SOLUTION\n",
    "    batch_size = residual_stack.size(-2)\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(\n",
    "        residual_stack,\n",
    "        layer=-1,\n",
    "        pos_slice=-1,\n",
    "    )\n",
    "    return (\n",
    "        einops.einsum(\n",
    "            scaled_residual_stack,\n",
    "            logit_diff_directions,\n",
    "            \"... batch d_model, batch d_model -> ...\",\n",
    "        )\n",
    "        / batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9cc02eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Layer=%{x}<br>Logit Diff=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4
         ],
         "xaxis": "x",
         "y": [
          0.3822139,
          3.597116,
          1.6930128,
          0.2855423,
          -3.0110464
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "hovermode": "x unified",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Accumulated Residual Stream"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickmode": "array",
         "ticktext": [
          "0_pre",
          "0_mid",
          "1_pre",
          "1_mid",
          "final_post"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4
         ],
         "title": {
          "text": "Layer"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Logit Diff"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gpt_from_scratch import plotly_utils\n",
    "\n",
    "accumulated_residual, labels = cache.accumulated_resid(\n",
    "    layer=-1,\n",
    "    incl_mid=True,\n",
    "    pos_slice=-1,\n",
    "    return_labels=True,\n",
    ")\n",
    "# accumulated_residual has shape (component, batch, d_model)\n",
    "\n",
    "logit_lens_logit_diffs: Float32[torch.Tensor, \"...\"] = residual_stack_to_logit_diff(\n",
    "    accumulated_residual,\n",
    "    cache,\n",
    "    logit_diff_directions,\n",
    ")  # [component]\n",
    "\n",
    "plotly_utils.line(\n",
    "    logit_lens_logit_diffs,\n",
    "    hovermode=\"x unified\",\n",
    "    title=\"Logit Difference From Accumulated Residual Stream\",\n",
    "    labels={\"x\": \"Layer\", \"y\": \"Logit Diff\"},\n",
    "    xaxis_tickvals=labels,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d73f1e",
   "metadata": {},
   "source": [
    "### Logit Difference From Each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "32f3ff0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "Layer=%{x}<br>Logit Diff=%{y}<extra></extra>",
         "legendgroup": "",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5
         ],
         "xaxis": "x",
         "y": [
          1.9721406,
          -1.5899267,
          3.214902,
          -1.9041028,
          -1.4074703,
          -3.2965894
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "hovermode": "x unified",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Each Layer"
        },
        "width": 800,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "tickmode": "array",
         "ticktext": [
          "embed",
          "pos_embed",
          "0_attn_out",
          "0_mlp_out",
          "1_attn_out",
          "1_mlp_out"
         ],
         "tickvals": [
          0,
          1,
          2,
          3,
          4,
          5
         ],
         "title": {
          "text": "Layer"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Logit Diff"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_layer_residual, labels = cache.decompose_resid(\n",
    "    layer=-1, pos_slice=-1, return_labels=True\n",
    ")\n",
    "per_layer_logit_diffs = residual_stack_to_logit_diff(\n",
    "    per_layer_residual,\n",
    "    cache,\n",
    "    logit_diff_directions,\n",
    ")\n",
    "\n",
    "plotly_utils.line(\n",
    "    per_layer_logit_diffs,\n",
    "    hovermode=\"x unified\",\n",
    "    title=\"Logit Difference From Each Layer\",\n",
    "    labels={\"x\": \"Layer\", \"y\": \"Logit Diff\"},\n",
    "    xaxis_tickvals=labels,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2515dba",
   "metadata": {},
   "source": [
    "### Logit Difference From Each Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c53ba63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly",
        "staticPlot": false
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "Head: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "xaxis": "x",
         "yaxis": "y",
         "z": [
          [
           0.8790549,
           2.1355145
          ],
          [
           1.112102,
           -2.625257
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "cmid": 0,
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Logit Difference From Each Head"
        },
        "width": 600,
        "xaxis": {
         "anchor": "y",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "scaleanchor": "y",
         "title": {
          "text": "Head"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "constrain": "domain",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Layer"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(\n",
    "    layer=-1, pos_slice=-1, return_labels=True\n",
    ")\n",
    "per_head_residual = einops.rearrange(\n",
    "    per_head_residual,\n",
    "    \"(layer head) ... -> layer head ...\",\n",
    "    layer=model.cfg.n_layers,\n",
    ")\n",
    "per_head_logit_diffs = residual_stack_to_logit_diff(\n",
    "    per_head_residual,\n",
    "    cache,\n",
    "    logit_diff_directions,\n",
    ")\n",
    "\n",
    "plotly_utils.imshow(\n",
    "    per_head_logit_diffs,\n",
    "    labels={\"x\": \"Head\", \"y\": \"Layer\"},\n",
    "    title=\"Logit Difference From Each Head\",\n",
    "    width=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9eec6d",
   "metadata": {},
   "source": [
    "### Highest Value Attention Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7c42392c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1], [1, 0], [0, 0]]\n",
      "attn_patterns_for_important_heads.shape=torch.Size([3, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-c66c366a-b3fb\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-c66c366a-b3fb\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0], [0.5470290184020996, 0.452970951795578, 0.0, 0.0], [0.26325494050979614, 0.2708369195461273, 0.46590808033943176, 0.0], [0.36389410495758057, 0.18352848291397095, 0.1702958345413208, 0.2822816073894501]], [[1.0, 0.0, 0.0, 0.0], [0.3238815665245056, 0.6761184334754944, 0.0, 0.0], [0.6471174359321594, 0.3345986008644104, 0.01828400231897831, 0.0], [0.021832719445228577, 0.051504746079444885, 0.8336246609687805, 0.09303781390190125]], [[1.0, 0.0, 0.0, 0.0], [0.29485052824020386, 0.7051494717597961, 0.0, 0.0], [0.47771987318992615, 0.2582802176475525, 0.26399990916252136, 0.0], [0.2891561686992645, 0.224507138133049, 0.20278657972812653, 0.2835501432418823]]], \"attentionHeadNames\": [\"0.1\", \"1.0\", \"0.0\"], \"tokens\": [\"<\", \"a\", \"z\", \"|\"]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x4db4bcfe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import IPython.core.display\n",
    "import IPython.display\n",
    "\n",
    "\n",
    "def topk_of_Nd_tensor(\n",
    "    tensor: Float[torch.Tensor, \"rows cols\"],\n",
    "    k: int,\n",
    ") -> list[tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Helper function: does same as tensor.topk(k).indices, but works over 2D tensors.\n",
    "    Returns a list of indices, i.e. shape [k, tensor.ndim].\n",
    "\n",
    "    Example: if tensor is 2D array of values for each head in each layer, this will\n",
    "    return a list of heads.\n",
    "    \"\"\"\n",
    "    i = torch.topk(tensor.flatten(), k).indices\n",
    "    return np.array(\n",
    "        np.unravel_index(\n",
    "            transformer_lens.utils.to_numpy(i),\n",
    "            tensor.shape,\n",
    "        )\n",
    "    ).T.tolist()\n",
    "\n",
    "\n",
    "k = 3\n",
    "\n",
    "for head_type in [\"Positive\", \"Negative\"]:\n",
    "\n",
    "    # Get the heads with largest (or smallest) contribution to the logit difference\n",
    "    top_heads = topk_of_Nd_tensor(\n",
    "        per_head_logit_diffs.cpu() * (1 if head_type == \"Positive\" else -1), k\n",
    "    )\n",
    "\n",
    "    # ex: [[0, 1], [1, 0], [0, 0]]\n",
    "    print(top_heads)\n",
    "\n",
    "    # Get all their attention patterns\n",
    "    attn_patterns_for_important_heads: Float[torch.Tensor, \"head q k\"] = torch.stack(\n",
    "        [cache[\"pattern\", layer][:, head][0] for layer, head in top_heads]\n",
    "    )\n",
    "\n",
    "    print(f\"{attn_patterns_for_important_heads.shape=}\")\n",
    "\n",
    "    # Display results\n",
    "    display(\n",
    "        cv.attention.attention_heads(\n",
    "            attention=attn_patterns_for_important_heads,\n",
    "            tokens=[x for x in input_string],\n",
    "            attention_head_names=[f\"{layer}.{head}\" for layer, head in top_heads],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de5552",
   "metadata": {},
   "source": [
    "### Activation Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3170dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean logit diff: 11.5820\n",
      "Corrupted logit diff: 7.8760\n"
     ]
    }
   ],
   "source": [
    "# TODO(bschoen): Clean and corrupted should actually switch first, should do this for search\n",
    "clean_logit_diff = logits_to_ave_logit_diff(correct_logits, answer_tokens)\n",
    "print(f\"Clean logit diff: {clean_logit_diff:.4f}\")\n",
    "\n",
    "corrupted_logit_diff = logits_to_ave_logit_diff(incorrect_logits, answer_tokens)\n",
    "print(f\"Corrupted logit diff: {corrupted_logit_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "93ebf797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_heads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mattention\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mattention_head_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnegative_color\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpositive_color\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmask_upper_tri\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mcircuitsvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRenderedHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Attention Heads\n",
      "\n",
      "Attention patterns from destination to source tokens, for a group of heads.\n",
      "\n",
      "Displays a small heatmap for each attention head. When one is selected, it\n",
      "is then shown in full size.\n",
      "\n",
      "Args:\n",
      "    attention: Attention head activations of the shape [dest_tokens x\n",
      "    src_tokens]\n",
      "    tokens: List of tokens (e.g. `[\"A\", \"person\"]`). Must be the same length\n",
      "    as the list of values.\n",
      "    max_value: Maximum value. Used to determine how dark the token color is\n",
      "    when positive (i.e. based on how close it is to the maximum value).\n",
      "    min_value: Minimum value. Used to determine how dark the token color is\n",
      "    when negative (i.e. based on how close it is to the minimum value).\n",
      "    negative_color: Color for negative values. This can be any valid CSS\n",
      "    color string. Be mindful of color blindness if not using the default\n",
      "    here.\n",
      "    positive_color: Color for positive values. This can be any valid CSS\n",
      "    color string. Be mindful of color blindness if not using the default\n",
      "    here.\n",
      "    mask_upper_tri: Whether or not to mask the upper triangular portion of\n",
      "    the attention patterns. Should be true for causal attention, false for\n",
      "    bidirectional attention.\n",
      "\n",
      "Returns:\n",
      "    Html: Attention pattern visualization\n",
      "\u001b[0;31mFile:\u001b[0m      ~/gpt_from_scratch/venv/lib/python3.12/site-packages/circuitsvis/attention.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "cv.attention.attention_heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a63158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76f240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c26324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "705bcb63",
   "metadata": {},
   "source": [
    "## Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df666bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "# TODO(bschoen): Do need to use lightning if want to do this generally\n",
    "# note: generally do want to iterate on this part itself, i.e. once find promising learning rate, searching other hyperparameters\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "\n",
    "    # TODO(bschoen): up to one per position, eh might as well try it\n",
    "\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [8, 16, 32, 64, 128])\n",
    "    n_heads = trial.suggest_int(\"n_heads\", 1, 8)\n",
    "\n",
    "    cfg = ModelAndTrainingConfig(\n",
    "        num_epochs=1000,\n",
    "        eval_test_every_n=10000,  # not worth evaluating test loss for study\n",
    "        n_layers=1,  # trial.suggest_int(\"n_layers\", 1, 2),\n",
    "        d_model=d_model,\n",
    "        n_heads=n_heads,\n",
    "        learning_rate=5e-4,\n",
    "    )\n",
    "\n",
    "    # sanity check `d_heads`\n",
    "    if (cfg.d_model % cfg.n_heads) != 0:\n",
    "        print(f\"Pruning trial for {cfg.d_model=} {cfg.n_heads=}\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    result = train_model(cfg)\n",
    "\n",
    "    return result.train_loss\n",
    "\n",
    "\n",
    "enable_optuna = False\n",
    "\n",
    "if enable_optuna:\n",
    "\n",
    "    study_storage_url = \"sqlite:///toy-problem-hooked-transformer.db\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        directions=[optuna.study.StudyDirection.MINIMIZE],\n",
    "        storage=study_storage_url,\n",
    "    )\n",
    "\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    print(\"View by launching optuna dashboard from the command line:\")\n",
    "    print(f\"optuna-dashboard {study_storage_url}\")\n",
    "\n",
    "    # now let's do a real run\n",
    "    training_config = ModelAndTrainingConfig(\n",
    "        num_epochs=10000,\n",
    "        eval_test_every_n=1000,\n",
    "        n_layers=1,\n",
    "        d_model=16,\n",
    "        n_heads=1,\n",
    "    )\n",
    "\n",
    "    result = train_model(cfg=training_config)\n",
    "\n",
    "    # for compatibility with code later\n",
    "    model = result.model\n",
    "    cfg = training_config.get_hooked_transformer_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e450e6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Using tensor([ 0,  2, 14, 22, 21, 28, 21, 22, 14,  2, 28,  2, 14, 22, 21,  1,  1,  1,\n",
      "         1,  1], device='mps:0') from tensor([ 0,  2, 14, 22, 21, 28, 21, 22, 14,  2, 28,  2, 14, 22, 21,  1,  1,  1,\n",
      "         1,  1]) (from test set)\n",
      "Batch size: 1\n",
      "Layer:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-196b20eb-860b\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-196b20eb-860b\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<\", \"a\", \"m\", \"u\", \"t\", \"|\", \"t\", \"u\", \"m\", \"a\", \"|\", \"a\", \"m\", \"u\", \"t\", \">\", \">\", \">\", \">\", \">\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8303080201148987, 0.16969196498394012, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43168365955352783, 0.43933266401290894, 0.12898366153240204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00293550337664783, 0.9628477692604065, 0.026195377111434937, 0.008021291345357895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014253566041588783, 0.3583834767341614, 0.008714658208191395, 0.6001347303390503, 0.018513571470975876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04573999345302582, 0.0014987707836553454, 0.10098908841609955, 0.012385389767587185, 0.7779974937438965, 0.06138927862048149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10405641794204712, 0.4316331446170807, 0.00741685600951314, 0.4158991575241089, 0.02971881441771984, 0.008519385941326618, 0.002756216563284397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019610198214650154, 0.06289960443973541, 0.7841379046440125, 0.024730734527111053, 0.005121127236634493, 0.09917165338993073, 0.0019708871841430664, 0.0023578694090247154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.060707587748765945, 0.8057061433792114, 0.042277686297893524, 0.033792633563280106, 0.000953318492975086, 0.011990088038146496, 0.0005683447234332561, 0.0004676021635532379, 0.043536603450775146, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029916904866695404, 0.007835973985493183, 0.5444332361221313, 0.021964700892567635, 0.3646632134914398, 0.008309480734169483, 0.015242783352732658, 0.0007359661976806819, 0.0019079806515946984, 0.004989814478904009, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0287159513682127, 0.002121563069522381, 0.008965153247117996, 0.20573465526103973, 0.0911613181233406, 0.24592989683151245, 0.014234884642064571, 0.18570204079151154, 0.0019407160580158234, 0.11060942709445953, 0.10488435626029968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030057772994041443, 0.007030196953564882, 0.7579734921455383, 0.0052116867154836655, 0.0642547681927681, 0.04532629996538162, 0.008277041837573051, 0.0018692479934543371, 0.0030342498794198036, 0.025756778195500374, 0.02036910690367222, 0.03083939105272293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05707787722349167, 0.07927586138248444, 0.0020581637509167194, 0.7267448306083679, 0.009554912336170673, 0.017302900552749634, 0.0034289632458239794, 0.02013213559985161, 0.02180042676627636, 0.0002496928791515529, 0.04486997053027153, 0.0014917155494913459, 0.01601259969174862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00803462602198124, 0.0006724202539771795, 0.002130819484591484, 0.03569954261183739, 0.9265246987342834, 0.0015218073967844248, 0.009713859297335148, 0.0008558437111787498, 5.2733208576682955e-05, 0.0007544047548435628, 0.005844038911163807, 0.0004083729872945696, 0.0006514648557640612, 0.00713539170101285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0094343526288867, 0.01869853399693966, 0.009227831847965717, 0.06321708112955093, 0.003590809879824519, 0.1380065381526947, 0.015996379777789116, 0.2481532096862793, 0.043512701988220215, 0.1910780817270279, 0.031981486827135086, 0.19695726037025452, 0.011310242116451263, 0.01221520733088255, 0.006620281375944614, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001148200943134725, 0.00013741360453423113, 0.0002075704833259806, 0.03737979754805565, 0.06916888803243637, 0.01155070774257183, 0.04965231195092201, 0.2875634729862213, 0.0005858037038706243, 0.49231699109077454, 0.005791313014924526, 0.03407036140561104, 0.0001633371430216357, 0.008641870692372322, 0.0008126895409077406, 0.0008093594224192202, 0.0, 0.0, 0.0, 0.0], [0.003667482640594244, 0.003465309739112854, 0.0010380145395174623, 0.007440309971570969, 0.004226327873766422, 0.01865760050714016, 0.04531796649098396, 0.36300480365753174, 0.03512318804860115, 0.4193320572376251, 0.010832094587385654, 0.06562267988920212, 0.003100384958088398, 0.017779981717467308, 0.0007876968593336642, 0.0002442128607071936, 0.0003599691845010966, 0.0, 0.0, 0.0], [0.008914926089346409, 0.04337163642048836, 0.0021246555261313915, 0.051125455647706985, 0.02077314630150795, 0.03664955869317055, 0.10069455951452255, 0.2750549912452698, 0.04295605421066284, 0.17293788492679596, 0.030415555462241173, 0.11016204208135605, 0.011952905915677547, 0.042261384427547455, 0.01525562722235918, 0.010362029075622559, 0.009410289116203785, 0.015577256679534912, 0.0, 0.0], [0.00467582605779171, 0.03930766507983208, 0.0176935326308012, 0.01214132271707058, 0.010212931782007217, 0.019630227237939835, 0.08315558731555939, 0.0693017914891243, 0.0733538269996643, 0.2995475232601166, 0.008136560209095478, 0.2663302421569824, 0.034118156880140305, 0.03552565351128578, 0.009487725794315338, 0.002459063194692135, 0.00467853806912899, 0.002960678655654192, 0.007283099461346865, 0.0], [0.0030217389576137066, 0.008938225917518139, 0.008480818942189217, 0.01325904205441475, 0.012102022767066956, 0.027633601799607277, 0.048703789710998535, 0.0990656241774559, 0.017872130498290062, 0.438480019569397, 0.008456269279122353, 0.2606408894062042, 0.006160615012049675, 0.025212395936250687, 0.004465512465685606, 0.002246072283014655, 0.002310629468411207, 0.0015704751713201404, 0.0047713653184473515, 0.006608814466744661]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3236260712146759, 0.6763738989830017, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6625966429710388, 0.08141113072633743, 0.2559922933578491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14692705869674683, 0.02916208654642105, 0.7612237930297852, 0.06268702447414398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22506345808506012, 0.12594613432884216, 0.063261978328228, 0.5779212713241577, 0.007807173300534487, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00627435278147459, 0.005787703674286604, 0.07039948552846909, 0.006172711495310068, 0.909247636795044, 0.0021181455813348293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01671784557402134, 0.3144344091415405, 0.0015551953110843897, 0.24107210338115692, 0.0023054592311382294, 0.3835993707180023, 0.040315646678209305, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07150477170944214, 0.009877021424472332, 0.7738454937934875, 0.04118456691503525, 0.08487297594547272, 0.007147248834371567, 0.007346687838435173, 0.004221267066895962, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08547831326723099, 0.04272592440247536, 0.006301993038505316, 0.13021419942378998, 0.019136663526296616, 0.14121486246585846, 0.06518139690160751, 0.36485275626182556, 0.14489391446113586, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056163519620895386, 0.06483684480190277, 0.5428005456924438, 0.048579175025224686, 0.04348103329539299, 0.04912018030881882, 0.13128238916397095, 0.005076785106211901, 0.0320507287979126, 0.026608766987919807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01465738844126463, 0.013090393505990505, 0.0196026973426342, 0.08154670894145966, 0.48559483885765076, 0.011643137782812119, 0.008043758571147919, 0.22096681594848633, 0.012912245467305183, 0.11227599531412125, 0.019665975123643875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10014893859624863, 0.03556501120328903, 0.35169023275375366, 0.008169051259756088, 0.05685543641448021, 0.027235189452767372, 0.07723528146743774, 0.03576700761914253, 0.1700172871351242, 0.05037206411361694, 0.05404001846909523, 0.03290450572967529, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02219531498849392, 0.004773546010255814, 0.0017910710303112864, 0.07022073864936829, 0.026204144582152367, 0.019795799627900124, 0.002327539026737213, 0.7228666543960571, 0.05723327025771141, 0.018500739708542824, 0.03763776645064354, 0.008305109106004238, 0.008148347027599812, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006961921229958534, 0.28619977831840515, 0.00692789489403367, 0.08209508657455444, 0.004070732276886702, 0.11852952092885971, 0.28297775983810425, 0.008019368164241314, 0.018756823614239693, 0.013386626727879047, 0.03887243568897247, 0.06253888458013535, 0.029681803658604622, 0.04098137095570564, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07829170674085617, 0.007231186609715223, 0.048753682523965836, 0.03428356349468231, 0.20783960819244385, 0.010121049359440804, 0.002714333822950721, 0.3608264923095703, 0.05741152539849281, 0.09505067765712738, 0.026631144806742668, 0.01885419897735119, 0.026576653122901917, 0.015420314855873585, 0.009993845596909523, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027659615501761436, 0.08374424278736115, 0.047232821583747864, 0.05733282119035721, 0.14384685456752777, 0.037933461368083954, 0.04547524452209473, 0.06660779565572739, 0.03484823554754257, 0.10615301877260208, 0.03449901193380356, 0.09007178246974945, 0.0368322916328907, 0.048747025430202484, 0.0527450293302536, 0.0862707570195198, 0.0, 0.0, 0.0, 0.0], [0.024067852646112442, 0.01607995107769966, 0.08382905274629593, 0.02688598819077015, 0.4059535562992096, 0.0073300008662045, 0.012991352006793022, 0.0808982327580452, 0.020598679780960083, 0.14978256821632385, 0.012798788957297802, 0.0507311150431633, 0.031766485422849655, 0.032548945397138596, 0.020610487088561058, 0.019150791689753532, 0.0039761983789503574, 0.0, 0.0, 0.0], [0.010147955268621445, 0.14297780394554138, 0.011776532046496868, 0.060076430439949036, 0.029636796563863754, 0.03822608292102814, 0.10071635246276855, 0.02130955271422863, 0.014322934672236443, 0.06679278612136841, 0.022111786529421806, 0.08763497322797775, 0.021336080506443977, 0.04981990158557892, 0.051407381892204285, 0.12271176278591156, 0.0596516914665699, 0.08934321254491806, 0.0, 0.0], [0.03605414181947708, 0.020995719358325005, 0.12436866015195847, 0.01371610164642334, 0.20913709700107574, 0.011676233261823654, 0.05173046141862869, 0.053294844925403595, 0.062233973294496536, 0.12626411020755768, 0.018780633807182312, 0.051172759383916855, 0.06694116443395615, 0.08032763749361038, 0.032999906688928604, 0.016304219141602516, 0.007667618338018656, 0.009997455403208733, 0.006337324623018503, 0.0], [0.021968845278024673, 0.020392831414937973, 0.2108408361673355, 0.023085489869117737, 0.3236035108566284, 0.005595596972852945, 0.014640789479017258, 0.036099668592214584, 0.02375042624771595, 0.12672880291938782, 0.00703659001737833, 0.041257619857788086, 0.046495672315359116, 0.03219037503004074, 0.020519239827990532, 0.01841028966009617, 0.006310523021966219, 0.005883736070245504, 0.00799877755343914, 0.007190393749624491]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x4f3062a80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1\n",
      "Layer:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-f544067a-8860\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-f544067a-8860\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<\", \"a\", \"m\", \"u\", \"t\", \"|\", \"t\", \"u\", \"m\", \"a\", \"|\", \"a\", \"m\", \"u\", \"t\", \">\", \">\", \">\", \">\", \">\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8045199513435364, 0.19548004865646362, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6127120852470398, 0.1728353649377823, 0.2144525647163391, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4946766495704651, 0.1296587437391281, 0.17330342531204224, 0.20236122608184814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08396990597248077, 0.06842894107103348, 0.13892240822315216, 0.1930030882358551, 0.5156756639480591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17067083716392517, 0.1048772782087326, 0.12666186690330505, 0.12084189057350159, 0.1350228488445282, 0.3419252336025238, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05130156874656677, 0.05536770448088646, 0.060467272996902466, 0.06866564601659775, 0.12234374135732651, 0.4606824815273285, 0.18117156624794006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02248077653348446, 0.016343578696250916, 0.026558808982372284, 0.03213118761777878, 0.07688497751951218, 0.5501098036766052, 0.12735618650913239, 0.14813467860221863, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06967579573392868, 0.13618789613246918, 0.09352760761976242, 0.09756103903055191, 0.025180861353874207, 0.1301184892654419, 0.04940110445022583, 0.08526436984539032, 0.31308290362358093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006547480821609497, 0.0019454644061625004, 0.003996600396931171, 0.004656385630369186, 0.2926669418811798, 0.2005883902311325, 0.2150467038154602, 0.16808150708675385, 0.006329049821943045, 0.10014146566390991, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2455189824104309, 0.22528323531150818, 0.17006368935108185, 0.13330356776714325, 0.016844656318426132, 0.036460962146520615, 0.021833661943674088, 0.012826671823859215, 0.08281610906124115, 0.020182479172945023, 0.034865982830524445, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016725150868296623, 0.0124265281483531, 0.018108772113919258, 0.020368356257677078, 0.035198431462049484, 0.30268463492393494, 0.06363838165998459, 0.06649406254291534, 0.02317381650209427, 0.04566008597612381, 0.3318174481391907, 0.0637042373418808, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018802283331751823, 0.016916874796152115, 0.01775963604450226, 0.020367057994008064, 0.1156599149107933, 0.12699885666370392, 0.12763603031635284, 0.09685860574245453, 0.021940534934401512, 0.09236085414886475, 0.1348613202571869, 0.10143531113862991, 0.10840272903442383, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016238264739513397, 0.0088881254196167, 0.017108313739299774, 0.019513169303536415, 0.043253764510154724, 0.27779996395111084, 0.06013140082359314, 0.056141264736652374, 0.010533341206610203, 0.049721866846084595, 0.19353066384792328, 0.045752789825201035, 0.09950992465019226, 0.1018771082162857, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14471520483493805, 0.16522929072380066, 0.13511046767234802, 0.11979822814464569, 0.01559942401945591, 0.05913470685482025, 0.028088323771953583, 0.021283457055687904, 0.08947622030973434, 0.026372287422418594, 0.06369395554065704, 0.022307846695184708, 0.03456796333193779, 0.022017020732164383, 0.05260561406612396, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15668119490146637, 0.16423609852790833, 0.12990416586399078, 0.10893721878528595, 0.013848595321178436, 0.04893089830875397, 0.02504625730216503, 0.017531638965010643, 0.09101025015115738, 0.021231329068541527, 0.05496088042855263, 0.01865074597299099, 0.03010762669146061, 0.01784686930477619, 0.048643771559000015, 0.05243249237537384, 0.0, 0.0, 0.0, 0.0], [0.1371091902256012, 0.1841643750667572, 0.15039047598838806, 0.1321212351322174, 0.005936686415225267, 0.06615667045116425, 0.01384474616497755, 0.011820397339761257, 0.08447366952896118, 0.015489816665649414, 0.05808289349079132, 0.012621661648154259, 0.02023177035152912, 0.01271046046167612, 0.031053993850946426, 0.031114323064684868, 0.03267758712172508, 0.0, 0.0, 0.0], [0.11965660750865936, 0.14803701639175415, 0.1246112510561943, 0.1128053218126297, 0.00993878673762083, 0.059982866048812866, 0.019889624789357185, 0.01713583432137966, 0.08183910697698593, 0.020775895565748215, 0.059768516570329666, 0.017904017120599747, 0.026838092133402824, 0.01691492088139057, 0.03980373963713646, 0.039361659437417984, 0.04109037667512894, 0.04364638030529022, 0.0, 0.0], [0.11755847185850143, 0.1246253177523613, 0.11311780661344528, 0.09928783029317856, 0.011519095860421658, 0.06029611825942993, 0.02073214203119278, 0.018297070637345314, 0.07982653379440308, 0.02053999714553356, 0.058075375854969025, 0.01872842200100422, 0.028074707835912704, 0.01783580891788006, 0.04054464027285576, 0.03963379189372063, 0.04114246368408203, 0.04494978114962578, 0.04521467909216881, 0.0], [0.12694130837917328, 0.1405194252729416, 0.11972054839134216, 0.10290520638227463, 0.009604386053979397, 0.046652376651763916, 0.017314758151769638, 0.014049905352294445, 0.07486749440431595, 0.017280470579862595, 0.045816801488399506, 0.014528981409966946, 0.022792750969529152, 0.014321547001600266, 0.035662733018398285, 0.03668217360973358, 0.03591325134038925, 0.03974568098783493, 0.042610231786966324, 0.04206999018788338]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7516331672668457, 0.2483668476343155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5828126668930054, 0.12834419310092926, 0.28884315490722656, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5152045488357544, 0.1101783886551857, 0.23372092843055725, 0.14089611172676086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36824268102645874, 0.13671515882015228, 0.2195168435573578, 0.18592670559883118, 0.08959852904081345, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6634977459907532, 0.1307092308998108, 0.11883378773927689, 0.06944357603788376, 0.012528599239885807, 0.004987029358744621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4057176411151886, 0.15657588839530945, 0.19588378071784973, 0.14466939866542816, 0.036941442638635635, 0.03200144320726395, 0.028210461139678955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4873528778553009, 0.101730115711689, 0.1770244538784027, 0.13007737696170807, 0.03419831022620201, 0.020700450986623764, 0.021708227694034576, 0.02720806747674942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14252224564552307, 0.058129116892814636, 0.1582198292016983, 0.16581818461418152, 0.058989278972148895, 0.10377375036478043, 0.055904313921928406, 0.08005192875862122, 0.17659136652946472, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.41322851181030273, 0.09593306481838226, 0.14996854960918427, 0.10297736525535583, 0.02810186706483364, 0.009296368807554245, 0.025444846600294113, 0.016809992492198944, 0.1411360800266266, 0.017103375867009163, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2115115374326706, 0.06021163612604141, 0.049465395510196686, 0.034929707646369934, 0.013658647425472736, 0.013302871957421303, 0.0049835555255413055, 0.017266325652599335, 0.5678273439407349, 0.008264230564236641, 0.018578743562102318, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31893107295036316, 0.05460742488503456, 0.09181255847215652, 0.06791286170482635, 0.020358769223093987, 0.016741568222641945, 0.008810840547084808, 0.01792258210480213, 0.3666003942489624, 0.011778255924582481, 0.009871480986475945, 0.014652133919298649, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3170989751815796, 0.09634924679994583, 0.10046468675136566, 0.063863106071949, 0.014686656184494495, 0.01059417612850666, 0.013361271470785141, 0.015910234302282333, 0.3159993290901184, 0.009710540995001793, 0.016654949635267258, 0.01419985480606556, 0.011106916703283787, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3549635410308838, 0.10806423425674438, 0.10960226505994797, 0.07664690166711807, 0.02602227032184601, 0.010751004330813885, 0.01455953624099493, 0.01656150259077549, 0.21688489615917206, 0.01567656919360161, 0.01474862452596426, 0.013619846664369106, 0.00983635988086462, 0.012062512338161469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021968604996800423, 0.004765510559082031, 0.002811364596709609, 0.002133755711838603, 0.004419753793627024, 0.009897777810692787, 0.0008162482408806682, 0.0067171091213822365, 0.09725235402584076, 0.002636802149936557, 0.029372304677963257, 0.006903511472046375, 0.0018196996534243226, 0.002903908723965287, 0.805581271648407, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009996181353926659, 0.0022468692623078823, 0.001410864875651896, 0.0011506043374538422, 0.002729425672441721, 0.007705416064709425, 0.0004719756543636322, 0.0044232700020074844, 0.05442097410559654, 0.0016794748371466994, 0.018141597509384155, 0.004703394137322903, 0.001153975841589272, 0.0018686983967199922, 0.44898170232772827, 0.43891558051109314, 0.0, 0.0, 0.0, 0.0], [0.008825081400573254, 0.0018970262026414275, 0.0011394516332075, 0.0008885237039066851, 0.0018241254147142172, 0.0042085302993655205, 0.0003096253494732082, 0.002638433827087283, 0.038297172635793686, 0.0010814941488206387, 0.011156031861901283, 0.0027156148571521044, 0.0007037302711978555, 0.0011795738246291876, 0.32240721583366394, 0.32978174090385437, 0.2709466516971588, 0.0, 0.0, 0.0], [0.006700034718960524, 0.0013845819048583508, 0.0007832061965018511, 0.0005800439976155758, 0.0011443550465628505, 0.002306526293978095, 0.000207693810807541, 0.0016330472426488996, 0.02510569617152214, 0.000666995532810688, 0.0074734934605658054, 0.0016459864564239979, 0.00046021092566661537, 0.0007319992873817682, 0.2487979531288147, 0.26151329278945923, 0.20125813782215118, 0.23760674893856049, 0.0, 0.0], [0.0035417191684246063, 0.000847275776322931, 0.0005099588888697326, 0.00041664441232569516, 0.0011329815024510026, 0.0023463780526071787, 0.0001918823691084981, 0.001518245437182486, 0.012522599659860134, 0.000704211532138288, 0.006320068147033453, 0.0015214435989037156, 0.000435998837929219, 0.0008300524204969406, 0.19700869917869568, 0.19589942693710327, 0.16351044178009033, 0.18980000913143158, 0.22094197571277618, 0.0], [0.003424042835831642, 0.000798518885858357, 0.0004767782229464501, 0.00038088136352598667, 0.0009205404203385115, 0.0019945453386753798, 0.00014925593859516084, 0.0012955652782693505, 0.013880250975489616, 0.000564643822144717, 0.005412491504102945, 0.0013133760076016188, 0.0003417827538214624, 0.0006303985137492418, 0.16140888631343842, 0.1634616106748581, 0.13334912061691284, 0.15505076944828033, 0.17829135060310364, 0.1768551468849182]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x4e9fa4ce0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "Using tensor([ 0,  3,  3, 26, 28, 26,  3,  3, 28,  3,  3, 26,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='mps:0') from tensor([ 0,  3,  3, 26, 28, 26,  3,  3, 28,  3,  3, 26,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1]) (from test set)\n",
      "Batch size: 1\n",
      "Layer:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-b36ea213-5d95\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-b36ea213-5d95\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<\", \"b\", \"b\", \"y\", \"|\", \"y\", \"b\", \"b\", \"|\", \"b\", \"b\", \"y\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8648219108581543, 0.1351780742406845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48997142910957336, 0.3904362916946411, 0.11959227919578552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007724300492554903, 0.7766596674919128, 0.17141728103160858, 0.04419868439435959, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0427851565182209, 0.026925919577479362, 0.013638988137245178, 0.6984859704971313, 0.21816396713256836, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02253749966621399, 0.010289906524121761, 0.7647305727005005, 0.024049539119005203, 0.15600037574768066, 0.02239205315709114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0030350997112691402, 0.9766259789466858, 0.00032427094993181527, 0.011877288110554218, 0.008016218431293964, 1.6835932910908014e-05, 0.00010428002860862762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019050592556595802, 0.11281204968690872, 0.8117427229881287, 0.016972502693533897, 0.020719939842820168, 0.012830552645027637, 0.001787084504030645, 0.004084518179297447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09626010060310364, 0.6496542096138, 0.03152572363615036, 0.02901219017803669, 0.07584776729345322, 0.008304196409881115, 0.00576748326420784, 0.01190696656703949, 0.09172137081623077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021409880369901657, 0.003699713619425893, 0.7621219754219055, 0.0075293914414942265, 0.11034109443426132, 0.012060977518558502, 0.02149474248290062, 0.0013510299613699317, 0.0014271774562075734, 0.05856397747993469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014247170649468899, 0.020422285422682762, 0.010561109520494938, 0.5863087773323059, 0.2162925899028778, 0.06961443275213242, 0.004093485418707132, 0.037814121693372726, 0.006103217601776123, 0.01779448799788952, 0.01674835942685604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007460954133421183, 0.0017265538917854428, 0.5335804224014282, 0.0014124673325568438, 0.030680300667881966, 0.027908818796277046, 0.008878393098711967, 0.0021692318841814995, 0.0025471067056059837, 0.29306334257125854, 0.004000149201601744, 0.08657227456569672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.011329997330904007, 0.016574792563915253, 0.0005019832169637084, 0.461168110370636, 0.021408360451459885, 0.07063072919845581, 0.04139561206102371, 0.2592658996582031, 0.020247405394911766, 0.01182768028229475, 0.05782187357544899, 0.02067549154162407, 0.007152066100388765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004012503661215305, 0.00010266385652357712, 0.0010252096690237522, 0.047173645347356796, 0.2520669400691986, 0.1808660626411438, 0.0628950297832489, 0.02871699631214142, 0.00013286792091093957, 0.3207952380180359, 0.053617287427186966, 0.02635282650589943, 0.000660126272123307, 0.02158261463046074, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012393798679113388, 0.00014390554861165583, 0.0009416299872100353, 0.015418868511915207, 0.0019606929272413254, 0.25720998644828796, 0.026800986379384995, 0.21622994542121887, 0.005320338997989893, 0.3934512138366699, 0.014567355625331402, 0.06560693681240082, 0.00015306590648833662, 0.0006229310529306531, 0.000332788797095418, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000833572936244309, 9.36663036554819e-06, 0.00017894693883135915, 0.024128511548042297, 0.0128393042832613, 0.273602694272995, 0.03921566158533096, 0.10875152796506882, 0.00023578322725370526, 0.49342042207717896, 0.022424230352044106, 0.022851964458823204, 4.365213681012392e-05, 0.0005650005768984556, 0.00031172772287391126, 0.0005875801434740424, 0.0, 0.0, 0.0, 0.0], [0.004264058079570532, 0.0003163965593557805, 0.0011747874086722732, 0.010995236225426197, 0.00218958524055779, 0.20514051616191864, 0.07111994922161102, 0.2999309301376343, 0.0146332373842597, 0.3164716958999634, 0.04302976280450821, 0.0282842256128788, 0.0003416975087020546, 0.001063216826878488, 0.00034218159271404147, 0.00028393795946612954, 0.0004185240250080824, 0.0, 0.0, 0.0], [0.008694198913872242, 0.012150760740041733, 0.002319301012903452, 0.07183307409286499, 0.01215264480561018, 0.1604323834180832, 0.13095086812973022, 0.24447457492351532, 0.025608673691749573, 0.11578301340341568, 0.06496689468622208, 0.07924440503120422, 0.007055165711790323, 0.017971651628613472, 0.011888009496033192, 0.010105472058057785, 0.009177296422421932, 0.015191573649644852, 0.0, 0.0], [0.008413377217948437, 0.009334028698503971, 0.03071226365864277, 0.026738356798887253, 0.004984176252037287, 0.1195569783449173, 0.14350752532482147, 0.12561334669589996, 0.04510897770524025, 0.24634960293769836, 0.023607755079865456, 0.15722861886024475, 0.010799003764986992, 0.010985658504068851, 0.00578530877828598, 0.004424678161740303, 0.008418252691626549, 0.00532724941149354, 0.013104732148349285, 0.0], [0.0037587827537208796, 0.0013790084049105644, 0.011412670835852623, 0.020690450444817543, 0.005073645617812872, 0.19465823471546173, 0.06271050870418549, 0.11214086413383484, 0.010795524343848228, 0.37235257029533386, 0.019767429679632187, 0.15469850599765778, 0.0017015965422615409, 0.00477073946967721, 0.0023117801174521446, 0.00279392022639513, 0.002874223981052637, 0.0019535357132554054, 0.005935166962444782, 0.008220795542001724]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5902310013771057, 0.4097689986228943, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6663860082626343, 0.15544559061527252, 0.17816847562789917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15968263149261475, 0.058868493884801865, 0.7451286911964417, 0.03632023185491562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.057212457060813904, 0.05828756466507912, 0.062279533594846725, 0.6593546867370605, 0.16286572813987732, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028823094442486763, 0.029482504352927208, 0.900796115398407, 0.008726058527827263, 0.020017113536596298, 0.012155129574239254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009564964100718498, 0.7401571869850159, 0.002198674948886037, 0.12360399961471558, 0.02064385637640953, 0.030905406922101974, 0.07292589545249939, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07696565240621567, 0.008438408374786377, 0.8265088200569153, 0.026929188519716263, 0.020546920597553253, 0.02373318187892437, 0.011988570913672447, 0.004889270756393671, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010004752315580845, 0.00486358255147934, 0.001248199143446982, 0.03673442080616951, 0.04667796194553375, 0.060076966881752014, 0.013907866552472115, 0.8120874166488647, 0.014398903585970402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02320821024477482, 0.016633981838822365, 0.890600860118866, 0.005749378353357315, 0.012816069647669792, 0.0069747306406497955, 0.022266024723649025, 0.0009483883040957153, 0.005854834336787462, 0.014947479590773582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04317602515220642, 0.040216442197561264, 0.060655124485492706, 0.5030398368835449, 0.07537571340799332, 0.11541126668453217, 0.01343571487814188, 0.059690020978450775, 0.010967424139380455, 0.04646380618214607, 0.031568579375743866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12109164148569107, 0.02122521959245205, 0.5557503700256348, 0.002349473536014557, 0.02502337284386158, 0.010979595594108105, 0.0396796278655529, 0.021150927990674973, 0.06315578520298004, 0.07549412548542023, 0.05050891637802124, 0.013590924441814423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01224081963300705, 0.007571470458060503, 0.001906336983665824, 0.09542449563741684, 0.03161565214395523, 0.05146783962845802, 0.004869009368121624, 0.6272197961807251, 0.013950963504612446, 0.05508245527744293, 0.07787460833787918, 0.01735384576022625, 0.003422742011025548, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004905897658318281, 0.1547127366065979, 0.013166635297238827, 0.033086542040109634, 0.013461608439683914, 0.04250594228506088, 0.2842400372028351, 0.007951329462230206, 0.030744096264243126, 0.022721195593476295, 0.010639320127665997, 0.0922602117061615, 0.11564770340919495, 0.17395669221878052, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.045877065509557724, 0.014621416106820107, 0.08597038686275482, 0.08146819472312927, 0.051897551864385605, 0.12248948961496353, 0.01800519973039627, 0.14414680004119873, 0.008160308003425598, 0.2153209149837494, 0.10475187748670578, 0.053356800228357315, 0.015974136069417, 0.022313615307211876, 0.015646303072571754, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02534738928079605, 0.057558417320251465, 0.049877528101205826, 0.09590182453393936, 0.05258976295590401, 0.1275540590286255, 0.04150158911943436, 0.07474632561206818, 0.017901793122291565, 0.09746179729700089, 0.06679274886846542, 0.09057997167110443, 0.03272145986557007, 0.04935126379132271, 0.041055165231227875, 0.07905888557434082, 0.0, 0.0, 0.0, 0.0], [0.030714048072695732, 0.01063311193138361, 0.09962772578001022, 0.06664958596229553, 0.05310098081827164, 0.12025205790996552, 0.01498252060264349, 0.11683090776205063, 0.004128835164010525, 0.23576928675174713, 0.11008618772029877, 0.06441415101289749, 0.013340641744434834, 0.017531242221593857, 0.0124253761023283, 0.024439163506031036, 0.005074201617389917, 0.0, 0.0, 0.0], [0.009246103465557098, 0.07438971102237701, 0.014053468592464924, 0.07328599691390991, 0.01876378431916237, 0.07602100074291229, 0.09591292589902878, 0.020074553787708282, 0.015392918139696121, 0.03964581713080406, 0.020139602944254875, 0.07677088677883148, 0.05303853377699852, 0.09289993345737457, 0.07280466705560684, 0.11180634051561356, 0.05435043200850487, 0.08140325546264648, 0.0, 0.0], [0.056239161640405655, 0.01624429225921631, 0.15121807157993317, 0.026126636192202568, 0.052491478621959686, 0.0660218894481659, 0.05261674523353577, 0.07693737000226974, 0.023261861875653267, 0.19159986078739166, 0.08390488475561142, 0.057405032217502594, 0.028898654505610466, 0.03681764006614685, 0.01734406128525734, 0.02543218620121479, 0.011960356496274471, 0.01559455692768097, 0.009885290637612343, 0.0], [0.03176365792751312, 0.01582510769367218, 0.27201953530311584, 0.05017905682325363, 0.03575236350297928, 0.08395672589540482, 0.017366532236337662, 0.05915157496929169, 0.004470747895538807, 0.2074383944272995, 0.05472835898399353, 0.045257698744535446, 0.02157772332429886, 0.020179416984319687, 0.014122304506599903, 0.02661851979792118, 0.009124071337282658, 0.008507001213729382, 0.011565033346414566, 0.010396231897175312]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x4ea5c58e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1\n",
      "Layer:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-71c871cc-7edf\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-71c871cc-7edf\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<\", \"b\", \"b\", \"y\", \"|\", \"y\", \"b\", \"b\", \"|\", \"b\", \"b\", \"y\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.872202455997467, 0.12779748439788818, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6301869750022888, 0.10375460982322693, 0.26605838537216187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09055035561323166, 0.048647139221429825, 0.09284354001283646, 0.7679589986801147, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19642163813114166, 0.16062314808368683, 0.15990038216114044, 0.11718639731407166, 0.36586835980415344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04121244698762894, 0.013628420419991016, 0.025809060782194138, 0.1579466611146927, 0.6096948385238647, 0.15170863270759583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.048892758786678314, 0.020085139200091362, 0.03222702071070671, 0.12627248466014862, 0.4847496449947357, 0.14400315284729004, 0.1437697410583496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03372401371598244, 0.03855542838573456, 0.051688406616449356, 0.09228524565696716, 0.28849899768829346, 0.116588294506073, 0.22527574002742767, 0.15338389575481415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1443929523229599, 0.19725953042507172, 0.15679025650024414, 0.05683651193976402, 0.06367326527833939, 0.0706658735871315, 0.08630019426345825, 0.045858707278966904, 0.17822277545928955, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014429355040192604, 0.004241656046360731, 0.008622280322015285, 0.06934879720211029, 0.3393392860889435, 0.06830395013093948, 0.06509579718112946, 0.2160380333662033, 0.15146440267562866, 0.06311646103858948, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07617195695638657, 0.036810461431741714, 0.045018285512924194, 0.05284251272678375, 0.18245042860507965, 0.06508345901966095, 0.07491383701562881, 0.0833808034658432, 0.1682298481464386, 0.06411825865507126, 0.1509801745414734, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1457119584083557, 0.1725512444972992, 0.14190320670604706, 0.04078582674264908, 0.04810220003128052, 0.043616779148578644, 0.06318128108978271, 0.03144681081175804, 0.1505531221628189, 0.048604607582092285, 0.062061160802841187, 0.05148179829120636, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1981291025876999, 0.14775119721889496, 0.12918679416179657, 0.036160971969366074, 0.06187012046575546, 0.04257518798112869, 0.05067816004157066, 0.028784912079572678, 0.05975991487503052, 0.04514427110552788, 0.0708991065621376, 0.05151565745472908, 0.07754459977149963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2146470993757248, 0.204360231757164, 0.14985109865665436, 0.03489508852362633, 0.027235979214310646, 0.03329847753047943, 0.03509381040930748, 0.02332167513668537, 0.030977338552474976, 0.03372332081198692, 0.03676449507474899, 0.03802219778299332, 0.0380064994096756, 0.0998026430606842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19349563121795654, 0.22760142385959625, 0.16138747334480286, 0.026980513706803322, 0.022671110928058624, 0.029028838500380516, 0.0332934632897377, 0.01639685407280922, 0.03901834785938263, 0.031011294573545456, 0.032185472548007965, 0.025935469195246696, 0.03604846075177193, 0.08023769408464432, 0.04470795765519142, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1823120266199112, 0.1577357053756714, 0.11962097138166428, 0.0265809353441, 0.02741272933781147, 0.027185315266251564, 0.029156949371099472, 0.01982925273478031, 0.03058505989611149, 0.027563659474253654, 0.036954913288354874, 0.03747450187802315, 0.04270293936133385, 0.10136161744594574, 0.056669604033231735, 0.07685387134552002, 0.0, 0.0, 0.0, 0.0], [0.17180009186267853, 0.21902643144130707, 0.15077732503414154, 0.023519964888691902, 0.021829089149832726, 0.027345025911927223, 0.03458660468459129, 0.014009999111294746, 0.049729324877262115, 0.029788251966238022, 0.030442606657743454, 0.019103404134511948, 0.028881164267659187, 0.062019914388656616, 0.03453488275408745, 0.0433347187936306, 0.03927110508084297, 0.0, 0.0, 0.0], [0.12857361137866974, 0.14021611213684082, 0.11010949313640594, 0.030054861679673195, 0.031218361109495163, 0.03274775668978691, 0.041119445115327835, 0.021018706262111664, 0.05314376950263977, 0.035259414464235306, 0.03886577859520912, 0.03125052526593208, 0.03731639310717583, 0.0691516250371933, 0.04465086758136749, 0.052394527941942215, 0.05039488151669502, 0.05251387879252434, 0.0, 0.0], [0.14125585556030273, 0.15179948508739471, 0.11498499661684036, 0.024889208376407623, 0.022981230169534683, 0.026506682857871056, 0.031190304085612297, 0.016778212040662766, 0.041977573186159134, 0.028326164931058884, 0.03051276132464409, 0.026599351316690445, 0.03361564129590988, 0.0686708390712738, 0.04187709093093872, 0.05059881880879402, 0.04568150267004967, 0.049682989716529846, 0.05207127705216408, 0.0], [0.1363762468099594, 0.1366441249847412, 0.10543635487556458, 0.02214200235903263, 0.02321997471153736, 0.023642033338546753, 0.0279642753303051, 0.015033557079732418, 0.03580460697412491, 0.025219645351171494, 0.03084501065313816, 0.025459304451942444, 0.03549082949757576, 0.0693206638097763, 0.04231772944331169, 0.05167633667588234, 0.045896999537944794, 0.05022396892309189, 0.05344516038894653, 0.04384114220738411]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7380359172821045, 0.2619640529155731, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5534070730209351, 0.20794399082660675, 0.23864895105361938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.48838329315185547, 0.19650013744831085, 0.2526973485946655, 0.062419306486845016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2857432961463928, 0.2757267653942108, 0.24445053935050964, 0.1187763437628746, 0.07530304789543152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16112634539604187, 0.2421673983335495, 0.3028129041194916, 0.11943680047988892, 0.05792757868766785, 0.11652892082929611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18993917107582092, 0.22582793235778809, 0.278807669878006, 0.09612727910280228, 0.04567451402544975, 0.08941848576068878, 0.07420491427183151, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32086193561553955, 0.18914388120174408, 0.2178219109773636, 0.08467313647270203, 0.03743421658873558, 0.05634607374668121, 0.045770253986120224, 0.047948624938726425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2446364164352417, 0.20595300197601318, 0.1941567063331604, 0.08442701399326324, 0.044640347361564636, 0.07065637409687042, 0.057627152651548386, 0.06054209545254707, 0.03736083582043648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17137795686721802, 0.19316141307353973, 0.25407594442367554, 0.08071700483560562, 0.03913954645395279, 0.07390744984149933, 0.06404421478509903, 0.04820069670677185, 0.008727246895432472, 0.06664852797985077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21891073882579803, 0.20356915891170502, 0.19263195991516113, 0.07006914168596268, 0.03566699102520943, 0.05894291773438454, 0.04535798355937004, 0.05049925670027733, 0.030033567920327187, 0.05502460151910782, 0.039293643087148666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12887214124202728, 0.02859503962099552, 0.021675674244761467, 0.036673687398433685, 0.029623622074723244, 0.019017517566680908, 0.015217543579638004, 0.04025895148515701, 0.3497571647167206, 0.022448495030403137, 0.011637862771749496, 0.2962223291397095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06454545259475708, 0.007990101352334023, 0.005801843479275703, 0.005380939692258835, 0.00550301605835557, 0.0029488548170775175, 0.002570010256022215, 0.005436863284558058, 0.027186520397663116, 0.0031223809346556664, 0.0029129681643098593, 0.32953134179115295, 0.5370696783065796, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.033680759370326996, 0.007815574295818806, 0.00544526893645525, 0.008925044909119606, 0.009125923737883568, 0.005323569756001234, 0.004370121285319328, 0.010803185403347015, 0.10794475674629211, 0.006116794887930155, 0.003579898737370968, 0.1927260011434555, 0.19682632386684418, 0.40731680393218994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0047503188252449036, 0.0008295016014017165, 0.0006081222090870142, 0.0012479767901822925, 0.001338128000497818, 0.000706312304828316, 0.0006332821794785559, 0.0014517437666654587, 0.01310559082776308, 0.0008180662989616394, 0.0005533004296012223, 0.07549281418323517, 0.12532208859920502, 0.22780916094779968, 0.5453335642814636, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009023833088576794, 0.0018106625648215413, 0.0012284794356673956, 0.002324769040569663, 0.0023407558910548687, 0.0012883602175861597, 0.0010895049199461937, 0.0027905346360057592, 0.032065100967884064, 0.0014884306583553553, 0.0008529557380825281, 0.07141771912574768, 0.08625497668981552, 0.1767430454492569, 0.3948291540145874, 0.21445171535015106, 0.0, 0.0, 0.0, 0.0], [0.005792633630335331, 0.0007753388490527868, 0.0005698730237782001, 0.0008011307218112051, 0.0007502368534915149, 0.0004202515119686723, 0.0003526575746946037, 0.0008287793607451022, 0.006410861387848854, 0.0004749234358314425, 0.0003223200619686395, 0.04102751612663269, 0.06572874635457993, 0.15291570127010345, 0.3318828046321869, 0.1790175586938858, 0.21192868053913116, 0.0, 0.0, 0.0], [0.004236268345266581, 0.000520153611432761, 0.0003988488460890949, 0.0004696351243183017, 0.00051572808297351, 0.0002546312171034515, 0.00022522768995258957, 0.00048438215162605047, 0.003424335503950715, 0.000285490183159709, 0.0002395102201262489, 0.0324060283601284, 0.05580682307481766, 0.1295786052942276, 0.2599865198135376, 0.14530585706233978, 0.17074722051620483, 0.19511470198631287, 0.0, 0.0], [0.003014707937836647, 0.0004445009399205446, 0.0003386932366993278, 0.0005283716600388288, 0.0005238545127213001, 0.0002906480513047427, 0.0002520753478165716, 0.0005478106904774904, 0.004293011035770178, 0.00033233038266189396, 0.0002260113542433828, 0.028463145717978477, 0.048024728894233704, 0.09437104314565659, 0.22043448686599731, 0.11297652125358582, 0.14411984384059906, 0.16228798031806946, 0.1785302311182022, 0.0], [0.0032725739292800426, 0.000456588197266683, 0.0003364179574418813, 0.0005078846006654203, 0.000498454028274864, 0.00026664359029382467, 0.00022686329612042755, 0.0005450082826428115, 0.004613614175468683, 0.0003041406744159758, 0.00020669448713306338, 0.025047559291124344, 0.03927185758948326, 0.08774576336145401, 0.193703755736351, 0.1037166565656662, 0.1257813274860382, 0.1412142664194107, 0.1577766388654709, 0.11450725048780441]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x4e60fcfe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "Using tensor([ 0,  7,  9, 28,  9,  7, 28,  7,  9,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1], device='mps:0') from tensor([ 0,  7,  9, 28,  9,  7, 28,  7,  9,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1]) (from test set)\n",
      "Batch size: 1\n",
      "Layer:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-d23792b7-28d5\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-d23792b7-28d5\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<\", \"f\", \"h\", \"|\", \"h\", \"f\", \"|\", \"f\", \"h\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.778436005115509, 0.22156399488449097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49132591485977173, 0.39824938774108887, 0.11042462289333344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2644822895526886, 0.07882258296012878, 0.49228036403656006, 0.16441474854946136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00809384509921074, 0.6847922801971436, 0.00856915395706892, 0.27891603112220764, 0.019628703594207764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029140843078494072, 0.004737005569040775, 0.44049885869026184, 0.008343266323208809, 0.49241942167282104, 0.02486060932278633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09420377761125565, 0.48972001671791077, 0.009639662690460682, 0.21362096071243286, 0.1471983641386032, 0.011898953467607498, 0.0337182991206646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015792179852724075, 0.09288296103477478, 0.6726266145706177, 0.1749069094657898, 0.0042155166156589985, 0.027364272624254227, 0.009246786125004292, 0.0029647054616361856, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001674009021371603, 0.9797550439834595, 0.0009956889552995563, 0.01640130952000618, 4.8025605792645365e-05, 9.335233698948286e-06, 0.00032330112298950553, 1.8785747670335695e-05, 0.0007744323229417205, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008900420740246773, 0.0002680542238522321, 0.07943232357501984, 0.0030374275520443916, 0.37928977608680725, 0.28049445152282715, 0.03408987820148468, 0.06831292808055878, 0.008934137411415577, 0.13724057376384735, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0042387088760733604, 0.0013020653277635574, 0.0029477260541170835, 0.09237205237150192, 0.057153597474098206, 0.4389980435371399, 0.01988275535404682, 0.2904830873012543, 0.003665406256914139, 0.0713411197066307, 0.01761547662317753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002967687789350748, 2.1130188542883843e-05, 0.03073567897081375, 0.0009704747353680432, 0.0279880091547966, 0.7135351300239563, 0.023406868800520897, 0.10200037807226181, 0.00412610312923789, 0.08893954008817673, 0.0017278859158977866, 0.0035810789559036493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015188942663371563, 0.033366359770298004, 0.0008346039103344083, 0.15603844821453094, 0.0438215471804142, 0.08927304297685623, 0.03573025390505791, 0.4718249440193176, 0.04369935765862465, 0.019802527502179146, 0.059152912348508835, 0.021679015830159187, 0.009588032029569149, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002217472530901432, 7.37423324608244e-05, 0.0008501781849190593, 0.0018975260900333524, 0.7959529161453247, 0.04601658135652542, 0.007761281915009022, 0.020157523453235626, 0.00017143200966529548, 0.08394566178321838, 0.02220785617828369, 0.006455626338720322, 0.00036481276038102806, 0.011927434243261814, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0020092586055397987, 0.0002901753468904644, 0.0017933979397639632, 0.008628930896520615, 0.007033225614577532, 0.44879150390625, 0.019423432648181915, 0.46773457527160645, 0.01706717349588871, 0.018673468381166458, 0.0026515384670346975, 0.004105784464627504, 0.0002481475821696222, 0.0010098835919052362, 0.0005395106854848564, 0.0, 0.0, 0.0, 0.0, 0.0], [0.001839512144215405, 2.943856452475302e-05, 0.0005718852044083178, 0.003737270599231124, 0.17307522892951965, 0.3860544264316559, 0.016047149896621704, 0.35347527265548706, 0.0017157564871013165, 0.050253864377737045, 0.007279644720256329, 0.0025928232353180647, 9.633074660087004e-05, 0.0012468318454921246, 0.0006879144930280745, 0.001296660047955811, 0.0, 0.0, 0.0, 0.0], [0.006386487279087305, 0.0005719579639844596, 0.0019912791904062033, 0.004324131179600954, 0.00993429310619831, 0.26891303062438965, 0.03179142251610756, 0.586301863193512, 0.06648437678813934, 0.013322277925908566, 0.004924636334180832, 0.0013853736454620957, 0.0005117770051583648, 0.0015924316830933094, 0.0005125022726133466, 0.0004252678481861949, 0.0006268437136895955, 0.0, 0.0, 0.0], [0.011313164606690407, 0.019329000264406204, 0.0035657642874866724, 0.027748942375183105, 0.03796650469303131, 0.17372740805149078, 0.0698447898030281, 0.384787380695343, 0.07294123619794846, 0.04555444046854973, 0.03429379314184189, 0.026033738628029823, 0.009180405177175999, 0.02338528260588646, 0.015469055622816086, 0.013149560429155827, 0.011941788718104362, 0.019767753779888153, 0.0, 0.0], [0.013985883444547653, 0.01410430297255516, 0.04825294390320778, 0.01861511543393135, 0.02474554441869259, 0.20322184264659882, 0.08214496821165085, 0.2108350247144699, 0.19691362977027893, 0.045082878321409225, 0.011399203911423683, 0.03287848085165024, 0.017951611429452896, 0.018261892721056938, 0.00961714331060648, 0.007355315610766411, 0.013993996195495129, 0.008855698630213737, 0.02178451232612133, 0.0], [0.007476578000932932, 0.003000448225066066, 0.025526579469442368, 0.014010485261678696, 0.03217492997646332, 0.40487170219421387, 0.046398818492889404, 0.2575373351573944, 0.05314282327890396, 0.05718790367245674, 0.009506952948868275, 0.02837522327899933, 0.003384639974683523, 0.009489456191658974, 0.004598353989422321, 0.005557374097406864, 0.005717108491808176, 0.0038857711479067802, 0.01180561725050211, 0.016351955011487007]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5694605112075806, 0.4305395185947418, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.686667799949646, 0.15109826624393463, 0.1622338891029358, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22848279774188995, 0.02225393056869507, 0.7374817132949829, 0.011781491339206696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06451010704040527, 0.19595620036125183, 0.028782537207007408, 0.7094400525093079, 0.0013110823929309845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.026552274823188782, 0.02270779013633728, 0.891921877861023, 0.00608663447201252, 0.03934856876730919, 0.013382802717387676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018191689625382423, 0.24402785301208496, 0.00865132361650467, 0.20694038271903992, 0.2101842612028122, 0.21934333443641663, 0.09266118705272675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0869758352637291, 0.014228771440684795, 0.788753867149353, 0.008610456250607967, 0.06297365576028824, 0.02889174595475197, 0.005707584321498871, 0.00385804264806211, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06953664869070053, 0.0710572823882103, 0.0039724381640553474, 0.344631165266037, 0.007010408211499453, 0.030601292848587036, 0.22754622995853424, 0.14062274992465973, 0.10502180457115173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02444733865559101, 0.028830919414758682, 0.6859911680221558, 0.00641693826764822, 0.13067755103111267, 0.03919105604290962, 0.015032589435577393, 0.005113229621201754, 0.01688464544713497, 0.04741455242037773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0468980073928833, 0.04464327171444893, 0.069219209253788, 0.08615422993898392, 0.24996411800384521, 0.15295648574829102, 0.01644493080675602, 0.0964018851518631, 0.01970580220222473, 0.13735957443714142, 0.08025245368480682, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056183524429798126, 0.009080346673727036, 0.4407528340816498, 0.0010846966179087758, 0.2882693111896515, 0.030370457097887993, 0.006589852273464203, 0.04148675501346588, 0.07975800335407257, 0.023658759891986847, 0.01850104331970215, 0.004264453426003456, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01907629892230034, 0.004870726261287928, 0.001934565487317741, 0.03430764377117157, 0.08328087627887726, 0.030086709186434746, 0.004857763182371855, 0.7059435248374939, 0.0363970547914505, 0.026342734694480896, 0.03828231617808342, 0.009285683743655682, 0.005334058776497841, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003936453722417355, 0.17699600756168365, 0.01529149990528822, 0.032927628606557846, 0.010976118966937065, 0.03661432862281799, 0.18648585677146912, 0.007126234471797943, 0.02272569201886654, 0.06190952658653259, 0.03022557497024536, 0.18240876495838165, 0.09279481321573257, 0.13958148658275604, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05610787868499756, 0.012417576275765896, 0.07953561097383499, 0.010849651880562305, 0.3629414141178131, 0.0828905925154686, 0.0064238146878778934, 0.15433844923973083, 0.03648995980620384, 0.06720177084207535, 0.04668721929192543, 0.01815451681613922, 0.019536443054676056, 0.027289653196930885, 0.01913551241159439, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029873475432395935, 0.053423136472702026, 0.053605008870363235, 0.03247802332043648, 0.15097209811210632, 0.09500409662723541, 0.02505224570631981, 0.07876675575971603, 0.03979706019163132, 0.07722392678260803, 0.06079142540693283, 0.06472300738096237, 0.038564279675483704, 0.05816354230046272, 0.048386070877313614, 0.09317582100629807, 0.0, 0.0, 0.0, 0.0], [0.030993588268756866, 0.008337837643921375, 0.086123988032341, 0.005103408824652433, 0.49218493700027466, 0.07119617611169815, 0.0034417782444506884, 0.10949819535017014, 0.021361755207180977, 0.04974641650915146, 0.03428775072097778, 0.014250816777348518, 0.013462059199810028, 0.01769079826772213, 0.012538467533886433, 0.024661598727107048, 0.005120383575558662, 0.0, 0.0, 0.0], [0.008948014117777348, 0.08621703833341599, 0.014297999441623688, 0.033570267260074615, 0.026759454980492592, 0.05922289937734604, 0.05796252191066742, 0.020716147497296333, 0.017672553658485413, 0.07431111484766006, 0.04072307050228119, 0.10832912474870682, 0.05132859945297241, 0.08990488946437836, 0.07045748829841614, 0.108201764523983, 0.05259820446372032, 0.07877886295318604, 0.0, 0.0], [0.06349298357963562, 0.013479398563504219, 0.16354097425937653, 0.008490610867738724, 0.24393634498119354, 0.050559233874082565, 0.021659892052412033, 0.07614296674728394, 0.08116848021745682, 0.056514203548431396, 0.03720445558428764, 0.019054966047406197, 0.03262605890631676, 0.04156644642353058, 0.019581129774451256, 0.028712473809719086, 0.013503025285899639, 0.017605969682335854, 0.011160314083099365, 0.0], [0.03233009949326515, 0.01108454167842865, 0.22449612617492676, 0.004424350801855326, 0.3792252838611603, 0.0549345389008522, 0.0036371785681694746, 0.05085619166493416, 0.025246446952223778, 0.05181360989809036, 0.023586025461554527, 0.014098110608756542, 0.021962521597743034, 0.02053927443921566, 0.014374148100614548, 0.027093209326267242, 0.009286780841648579, 0.008658704347908497, 0.011771272867918015, 0.010581625625491142]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x4f3061a00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 1\n",
      "Layer:  1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-e81c5f0d-aa2c\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-e81c5f0d-aa2c\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"<\", \"f\", \"h\", \"|\", \"h\", \"f\", \"|\", \"f\", \"h\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\", \">\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.844169557094574, 0.15583045780658722, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5665462613105774, 0.12585994601249695, 0.30759379267692566, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17195746302604675, 0.18135827779769897, 0.20091165602207184, 0.44577252864837646, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03953053429722786, 0.07665643095970154, 0.07929766178131104, 0.7660735249519348, 0.03844186291098595, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02197030559182167, 0.010262270458042622, 0.020187096670269966, 0.08442005515098572, 0.7923276424407959, 0.07083263248205185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1614026576280594, 0.23139947652816772, 0.18923796713352203, 0.14242108166217804, 0.043640974909067154, 0.10663970559835434, 0.12525811791419983, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03463089093565941, 0.06027719005942345, 0.06334482133388519, 0.35616427659988403, 0.016602423042058945, 0.067487433552742, 0.3567865192890167, 0.044706493616104126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030109697952866554, 0.1137588694691658, 0.07723071426153183, 0.4088945686817169, 0.0020399990025907755, 0.052889011800289154, 0.28264132142066956, 0.015478548593819141, 0.016957245767116547, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12169481068849564, 0.08075452595949173, 0.0903470516204834, 0.07048055529594421, 0.1034996509552002, 0.07284170389175415, 0.09363262355327606, 0.09822375327348709, 0.13161355257034302, 0.13691173493862152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1959128975868225, 0.15829485654830933, 0.14148613810539246, 0.05474841967225075, 0.037540651857852936, 0.06070195138454437, 0.05105817690491676, 0.04450305923819542, 0.05532693862915039, 0.0998900830745697, 0.10053682327270508, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12524732947349548, 0.15588821470737457, 0.12024495750665665, 0.08629963546991348, 0.014827319420874119, 0.05864374339580536, 0.07858539372682571, 0.03659369796514511, 0.054798275232315063, 0.07886309921741486, 0.07875539362430573, 0.11125299334526062, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14797745645046234, 0.15696488320827484, 0.12978272140026093, 0.08333607763051987, 0.019499266520142555, 0.05758567526936531, 0.06718006730079651, 0.030521700158715248, 0.033573176711797714, 0.07287406176328659, 0.06986434012651443, 0.08129935711622238, 0.04954124987125397, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09750808030366898, 0.10417532175779343, 0.09633355587720871, 0.08890064060688019, 0.025363478809595108, 0.05766908824443817, 0.0806996300816536, 0.03946090489625931, 0.04882156103849411, 0.07231017202138901, 0.07269368320703506, 0.08282601833343506, 0.06852737814188004, 0.06471049040555954, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12756125628948212, 0.15506336092948914, 0.11912290006875992, 0.07830844074487686, 0.012173834256827831, 0.05140592157840729, 0.059659942984580994, 0.025344982743263245, 0.030595095828175545, 0.06260284036397934, 0.05776628106832504, 0.07592480629682541, 0.03852206468582153, 0.05368116870522499, 0.05226707085967064, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10801025480031967, 0.1035507395863533, 0.08909183740615845, 0.05873532593250275, 0.019794508814811707, 0.04591263830661774, 0.0544615313410759, 0.03192375227808952, 0.04063348472118378, 0.06746004521846771, 0.06667105853557587, 0.08063624799251556, 0.047364238649606705, 0.05917569249868393, 0.06054464355111122, 0.06603392958641052, 0.0, 0.0, 0.0, 0.0], [0.10758553445339203, 0.13735932111740112, 0.10519946366548538, 0.09468887001276016, 0.009484936483204365, 0.046731602400541306, 0.07059576362371445, 0.021345429122447968, 0.025048447772860527, 0.05111607536673546, 0.04788978025317192, 0.06376873701810837, 0.03444572538137436, 0.0458175390958786, 0.04460342228412628, 0.047362320125103, 0.04695698991417885, 0.0, 0.0, 0.0], [0.09661231189966202, 0.10901866853237152, 0.09042671322822571, 0.07894011586904526, 0.012779262848198414, 0.044199712574481964, 0.06436958909034729, 0.023371754214167595, 0.027379218488931656, 0.05427845939993858, 0.0518462173640728, 0.06315001100301743, 0.040568672120571136, 0.048375677317380905, 0.04893398657441139, 0.050919059664011, 0.05159646272659302, 0.04323413223028183, 0.0, 0.0], [0.08313284069299698, 0.08550287038087845, 0.07337994873523712, 0.07340408861637115, 0.01431945338845253, 0.04160769283771515, 0.06345442682504654, 0.02678254060447216, 0.0329793356359005, 0.053206946700811386, 0.051171790808439255, 0.06484248489141464, 0.04092912748456001, 0.04809606820344925, 0.04941536486148834, 0.0506485290825367, 0.05163797363638878, 0.04346513748168945, 0.05202341079711914, 0.0], [0.08587083965539932, 0.09419219195842743, 0.07818732410669327, 0.05999382585287094, 0.012839526869356632, 0.038887642323970795, 0.05288928747177124, 0.023314274847507477, 0.028887534514069557, 0.05103742331266403, 0.050584517419338226, 0.0621325820684433, 0.03693791851401329, 0.045155372470617294, 0.04630434140563011, 0.04968024045228958, 0.04666021093726158, 0.039345335215330124, 0.049638498574495316, 0.04746110737323761]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7695931196212769, 0.23040685057640076, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5787988901138306, 0.18139784038066864, 0.2398032695055008, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6637073159217834, 0.14473459124565125, 0.17717494070529938, 0.014383193105459213, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24795089662075043, 0.22036586701869965, 0.25071290135383606, 0.15572811663150787, 0.125242218375206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6238364577293396, 0.1414606124162674, 0.20329459011554718, 0.005402516573667526, 0.014931670390069485, 0.011074149049818516, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4516264796257019, 0.19121253490447998, 0.19143816828727722, 0.053003739565610886, 0.03207392618060112, 0.04909030720591545, 0.03155484050512314, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.43859681487083435, 0.16264407336711884, 0.18665482103824615, 0.07444436848163605, 0.03709287568926811, 0.040012530982494354, 0.02979438751935959, 0.030760163441300392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14131131768226624, 0.11667357385158539, 0.11051508039236069, 0.3321553170681, 0.03899867460131645, 0.05284116789698601, 0.07956552505493164, 0.040317077189683914, 0.0876222550868988, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13590537011623383, 0.02228262834250927, 0.021169638261198997, 0.09839459508657455, 0.013760055415332317, 0.01815170980989933, 0.02849668823182583, 0.025731444358825684, 0.06167212873697281, 0.5744357109069824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04436268284916878, 0.008225321769714355, 0.006662625353783369, 0.06559473276138306, 0.006393589079380035, 0.01014089398086071, 0.015845201909542084, 0.01673918589949608, 0.03855140134692192, 0.4888281524181366, 0.29865625500679016, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03606504574418068, 0.008374134078621864, 0.006680693477392197, 0.11881229281425476, 0.005464867223054171, 0.009003682993352413, 0.021306069567799568, 0.012826980091631413, 0.031975653022527695, 0.2022801786661148, 0.10206075012683868, 0.44514963030815125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013132505118846893, 0.00184729287866503, 0.0015111877582967281, 0.014531254768371582, 0.001594671979546547, 0.002355126431211829, 0.0037264523562043905, 0.004305946175009012, 0.010464904829859734, 0.21083472669124603, 0.14508689939975739, 0.40112897753715515, 0.18948011100292206, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0317397378385067, 0.006014728918671608, 0.005713819991797209, 0.018694067373871803, 0.0037804620806127787, 0.0056677223183214664, 0.0065040988847613335, 0.007714841980487108, 0.014258120208978653, 0.19376294314861298, 0.1432366818189621, 0.279086172580719, 0.16953644156455994, 0.11429015547037125, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.005355119239538908, 0.0009720867965370417, 0.0007932041771709919, 0.014487296342849731, 0.0011598406126722693, 0.0017567368922755122, 0.003335939720273018, 0.003016119357198477, 0.005678419955074787, 0.1276891976594925, 0.08117713034152985, 0.21626286208629608, 0.12581926584243774, 0.07457336038351059, 0.33792340755462646, 0.0, 0.0, 0.0, 0.0, 0.0], [0.009579178877174854, 0.0017223565373569727, 0.0014100676635280252, 0.018901772797107697, 0.0014104698784649372, 0.0022060242481529713, 0.0042444560676813126, 0.003562135621905327, 0.008044028654694557, 0.11113707721233368, 0.06741011887788773, 0.2117340862751007, 0.09893147647380829, 0.06502702832221985, 0.2697770595550537, 0.12490260601043701, 0.0, 0.0, 0.0, 0.0], [0.007320011500269175, 0.0009192738798446953, 0.0007762594032101333, 0.007276930380612612, 0.0006845805328339338, 0.0010022175265476108, 0.0017266839276999235, 0.0016789674991741776, 0.004108174704015255, 0.08894506096839905, 0.061473745852708817, 0.1645892709493637, 0.0867147371172905, 0.04887586832046509, 0.2511333227157593, 0.10919596999883652, 0.163579061627388, 0.0, 0.0, 0.0], [0.005239393096417189, 0.0006611125427298248, 0.000558531261049211, 0.005245810374617577, 0.0005408011493273079, 0.0007887998363003135, 0.0013611646136268973, 0.0013828410301357508, 0.00327252596616745, 0.07829909026622772, 0.05609821900725365, 0.14085189998149872, 0.0783565416932106, 0.042472075670957565, 0.22072169184684753, 0.09793058782815933, 0.14314821362495422, 0.12307076156139374, 0.0, 0.0], [0.004578725900501013, 0.0005703679635189474, 0.0004978649085387588, 0.004549604374915361, 0.0005027852021157742, 0.0006811551284044981, 0.001183124491944909, 0.0011215440463274717, 0.002419488737359643, 0.06301126629114151, 0.04736028611660004, 0.10271581262350082, 0.07237086445093155, 0.03520352765917778, 0.1859157234430313, 0.07837275415658951, 0.12416747212409973, 0.1104162335395813, 0.1643614023923874, 0.0], [0.0057519543915987015, 0.0008526991587132215, 0.0007174779893830419, 0.008036118932068348, 0.0006350067560561001, 0.0009643844095990062, 0.0018186579691246152, 0.0015770681202411652, 0.003858292708173394, 0.06180039420723915, 0.03931999206542969, 0.11914756149053574, 0.05718293786048889, 0.03487909957766533, 0.16055157780647278, 0.072108693420887, 0.11110196262598038, 0.09194868057966232, 0.13980208337306976, 0.08794541656970978]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x3156317f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Look at some example output\n",
    "import circuitsvis as cv\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "def visualize_pattern_hook(\n",
    "    pattern: Float32[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
    "    hook: transformer_lens.hook_points.HookPoint,\n",
    "    tokens_as_strings: list[str],\n",
    ") -> None:\n",
    "    print(f\"Batch size: {pattern.shape[0]}\")\n",
    "    print(\"Layer: \", hook.layer())\n",
    "    display(\n",
    "        cv.attention.attention_patterns(\n",
    "            tokens=tokens_as_strings, attention=pattern.mean(0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "test_input_string_to_cache = {}\n",
    "\n",
    "for difficulty, test_loader in test_loaders.items():\n",
    "\n",
    "    print(difficulty)\n",
    "\n",
    "    # grab something from the test batch\n",
    "    example_batch = next(iter(test_loader))\n",
    "\n",
    "    x, y = example_batch\n",
    "\n",
    "    example_sample = x[0]\n",
    "\n",
    "    # example_sample = torch.tensor(tokenizer.encode(\"<az|za|az>>>>>>>>>>\"))\n",
    "\n",
    "    # grab the first part of it, ex: `<abc|`\n",
    "    example_prompt = example_sample  # [:8]\n",
    "\n",
    "    example_prompt = example_prompt.to(device)\n",
    "\n",
    "    print(f\"Using {example_prompt} from {example_sample} (from test set)\")\n",
    "\n",
    "    # note: already encoded\n",
    "    input_tokens = example_prompt\n",
    "\n",
    "    # first let's get these as strings so can easily work with them\n",
    "    input_tokens_as_strings = [token_to_string(x.item()) for x in input_tokens]\n",
    "\n",
    "    # wrap to bind input tokens\n",
    "    visualize_pattern_hook_fn = functools.partial(\n",
    "        visualize_pattern_hook, tokens_as_strings=input_tokens_as_strings\n",
    "    )\n",
    "\n",
    "    model.run_with_hooks(\n",
    "        input_tokens,\n",
    "        return_type=None,  # For efficiency, we don't need to calculate the logits\n",
    "        fwd_hooks=[(lambda name: name.endswith(\"pattern\"), visualize_pattern_hook_fn)],\n",
    "    )\n",
    "\n",
    "    logits_batch, cache = model.run_with_cache(input_tokens)\n",
    "\n",
    "    # store so can plot together later\n",
    "    test_input_string_to_cache[\"\".join(input_tokens_as_strings)] = cache\n",
    "\n",
    "    logits = logits_batch[0]\n",
    "\n",
    "    log_probs = logits.log_softmax(dim=-1)\n",
    "\n",
    "    cv.logits.token_log_probs(\n",
    "        token_indices=input_tokens,\n",
    "        log_probs=log_probs,\n",
    "        to_string=token_to_string,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f25d2143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_ln_to_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mresidual_stack\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Float[torch.Tensor, 'num_components *batch_and_pos_dims d_model']\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[int]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmlp_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpos_slice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Union[Slice, SliceInput]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbatch_slice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Union[Slice, SliceInput]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mhas_batch_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Float[torch.Tensor, 'num_components *batch_and_pos_dims_out d_model']\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Apply Layer Norm to a Stack.\n",
      "\n",
      "Takes a stack of components of the residual stream (eg outputs of decompose_resid or\n",
      "accumulated_resid), treats them as the input to a specific layer, and applies the layer norm\n",
      "scaling of that layer to them, using the cached scale factors - simulating what that\n",
      "component of the residual stream contributes to that layer's input.\n",
      "\n",
      "The layernorm scale is global across the entire residual stream for each layer, batch\n",
      "element and position, which is why we need to use the cached scale factors rather than just\n",
      "applying a new LayerNorm.\n",
      "\n",
      "If the model does not use LayerNorm or RMSNorm, it returns the residual stack unchanged.\n",
      "\n",
      "Args:\n",
      "    residual_stack:\n",
      "        A tensor, whose final dimension is d_model. The other trailing dimensions are\n",
      "        assumed to be the same as the stored hook_scale - which may or may not include batch\n",
      "        or position dimensions.\n",
      "    layer:\n",
      "        The layer we're taking the input to. In [0, n_layers], n_layers means the unembed.\n",
      "        None maps to the n_layers case, ie the unembed.\n",
      "    mlp_input:\n",
      "        Whether the input is to the MLP or attn (ie ln2 vs ln1). Defaults to False, ie ln1.\n",
      "        If layer==n_layers, must be False, and we use ln_final\n",
      "    pos_slice:\n",
      "        The slice to take of positions, if residual_stack is not over the full context, None\n",
      "        means do nothing. It is assumed that pos_slice has already been applied to\n",
      "        residual_stack, and this is only applied to the scale. See utils.Slice for details.\n",
      "        Defaults to None, do nothing.\n",
      "    batch_slice:\n",
      "        The slice to take on the batch dimension. Defaults to None, do nothing.\n",
      "    has_batch_dim:\n",
      "        Whether residual_stack has a batch dimension.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/gpt_from_scratch/venv/lib/python3.12/site-packages/transformer_lens/ActivationCache.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "cache.apply_ln_to_stack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59c96b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_head_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'int'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mincl_remainder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpos_slice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Union[Slice, SliceInput]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mapply_ln\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"Union[Float[torch.Tensor, 'num_components *batch_and_pos_dims d_model'], Tuple[Float[torch.Tensor, 'num_components *batch_and_pos_dims d_model'], List[str]]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;32mdef\u001b[0m \u001b[0mstack_head_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mreturn_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mincl_remainder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpos_slice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSlice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSliceInput\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mapply_ln\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mFloat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_components *batch_and_pos_dims d_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFloat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_components *batch_and_pos_dims d_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"Stack Head Results.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Returns a stack of all head results (ie residual stream contribution) up to layer L. A good\u001b[0m\n",
      "\u001b[0;34m        way to decompose the outputs of attention layers into attribution by specific heads. Note\u001b[0m\n",
      "\u001b[0;34m        that the num_components axis has length layer x n_heads ((layer head_index) in einops\u001b[0m\n",
      "\u001b[0;34m        notation).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Args:\u001b[0m\n",
      "\u001b[0;34m            layer:\u001b[0m\n",
      "\u001b[0;34m                Layer index - heads at all layers strictly before this are included. layer must be\u001b[0m\n",
      "\u001b[0;34m                in [1, n_layers-1], or any of (n_layers, -1, None), which all mean the final layer.\u001b[0m\n",
      "\u001b[0;34m            return_labels:\u001b[0m\n",
      "\u001b[0;34m                Whether to also return a list of labels of the form \"L0H0\" for the heads.\u001b[0m\n",
      "\u001b[0;34m            incl_remainder:\u001b[0m\n",
      "\u001b[0;34m                Whether to return a final term which is \"the rest of the residual stream\".\u001b[0m\n",
      "\u001b[0;34m            pos_slice:\u001b[0m\n",
      "\u001b[0;34m                A slice object to apply to the pos dimension. Defaults to None, do nothing.\u001b[0m\n",
      "\u001b[0;34m            apply_ln:\u001b[0m\n",
      "\u001b[0;34m                Whether to apply LayerNorm to the stack.\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSlice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpos_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSlice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpos_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSlice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_slice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# mypy can't seem to infer this\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Default to the residual stream immediately pre unembed\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"blocks.0.attn.hook_result\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Tried to stack head results when they weren't cached. Computing head results now\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_head_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcomponents\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Note that this has shape batch x pos x head_index x d_model\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"result\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"attn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mL\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34mH\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m\"... concat_head_index d_model -> concat_head_index ... d_model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mincl_remainder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mremainder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resid_post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremainder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"remainder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mincl_remainder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# There are no components, so the remainder is the entire thing.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m[\u001b[0m\u001b[0mpos_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resid_post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"remainder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# If this is called with layer 0, we return an empty tensor of the right shape to be\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# stacked correctly. This uses the shape of hook_embed, which is pretty janky since it\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# assumes embed is in the cache. But it's hard to explicitly code the shape, since it\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# depends on the pos slice, whether we have a batch dim, etc. And it's pretty messy!\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m*\u001b[0m\u001b[0mpos_slice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hook_embed\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mapply_ln\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcomponents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_ln_to_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_slice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_slice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mreturn_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/gpt_from_scratch/venv/lib/python3.12/site-packages/transformer_lens/ActivationCache.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "cache.stack_head_results??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8b78938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m      \n",
      "\u001b[0mtransformer_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_act_patch_resid_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'HookedTransformer'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcorrupted_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Int[torch.Tensor, 'batch pos']\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclean_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'ActivationCache'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpatching_metric\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Callable[[Float[torch.Tensor, 'batch pos d_vocab']], Float[torch.Tensor, '']]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpatch_setter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Callable[[CorruptedActivation, Sequence[int], ActivationCache], PatchedActivation]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mlayer_pos_patch_setter\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x177e2a8e0\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivation_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'resid_pre'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex_axis_names\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[Sequence[AxisNames]]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'layer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mindex_df\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Optional[pd.DataFrame]'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mreturn_index_df\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Union[torch.Tensor, Tuple[torch.Tensor, pd.DataFrame]]'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCall signature:\u001b[0m  \u001b[0mtransformer_lens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_act_patch_resid_pre\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m            partial\n",
      "\u001b[0;31mString form:\u001b[0m     functools.partial(<function generic_activation_patch at 0x177e2a840>, patch_setter=<function layer_pos_patch_setter at 0x177e2a8e0>, activation_name='resid_pre', index_axis_names=('layer', 'pos'))\n",
      "\u001b[0;31mFile:\u001b[0m            ~/.pyenv/versions/3.12.5/lib/python3.12/functools.py\n",
      "\u001b[0;31mSource:\u001b[0m         \n",
      "\u001b[0;32mclass\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"New function with partial application of the given arguments\u001b[0m\n",
      "\u001b[0;34m    and keywords.\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0m__slots__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"keywords\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__dict__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__weakref__\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the first argument must be callable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m@\u001b[0m\u001b[0mrecursive_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mqualname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__qualname__\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m!\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"functools\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"\u001b[0m\u001b[0;34mfunctools.\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"argument to __setstate__ must be a tuple\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mexpected 4 items in state, got \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m           \u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid partial state\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# just in case it's a subclass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# XXX does it need to be *exactly* dict?\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mnamespace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClass docstring:\u001b[0m\n",
      "partial(func, *args, **keywords) - new function with partial application\n",
      "of the given arguments and keywords."
     ]
    }
   ],
   "source": [
    "import transformer_lens.patching\n",
    "\n",
    "transformer_lens.patching.get_act_patch_resid_pre??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2f20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b41fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "\n",
    "def logit_attribution(\n",
    "    embed: Float32[torch.Tensor, \"seq d_model\"],\n",
    "    l1_results: Float32[torch.Tensor, \"seq nheads d_model\"],\n",
    "    l2_results: Float32[torch.Tensor, \"seq nheads d_model\"],\n",
    "    W_U: Float32[torch.Tensor, \"d_model d_vocab\"],\n",
    "    tokens: Int64[torch.Tensor, \"seq\"],\n",
    ") -> Float32[torch.Tensor, \"seq-1 n_components\"]:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        embed: the embeddings of the tokens (i.e. token + position embeddings)\n",
    "        l1_results: the outputs of the attention heads at layer 1 (with head as one of the dimensions)\n",
    "        l2_results: the outputs of the attention heads at layer 2 (with head as one of the dimensions)\n",
    "        W_U: the unembedding matrix\n",
    "        tokens: the token ids of the sequence\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (seq_len-1, n_components)\n",
    "        represents the concatenation (along dim=-1) of logit attributions from:\n",
    "            the direct path (seq-1,1)\n",
    "            layer 0 logits (seq-1, n_heads)\n",
    "            layer 1 logits (seq-1, n_heads)\n",
    "        so n_components = 1 + 2*n_heads\n",
    "    \"\"\"\n",
    "    W_U_correct_tokens = W_U[:, tokens[1:]]\n",
    "    # SOLUTION\n",
    "    direct_attributions = einops.einsum(\n",
    "        W_U_correct_tokens, embed[:-1], \"emb seq, seq emb -> seq\"\n",
    "    )\n",
    "    l1_attributions = einops.einsum(\n",
    "        W_U_correct_tokens, l1_results[:-1], \"emb seq, seq nhead emb -> seq nhead\"\n",
    "    )\n",
    "    l2_attributions = einops.einsum(\n",
    "        W_U_correct_tokens, l2_results[:-1], \"emb seq, seq nhead emb -> seq nhead\"\n",
    "    )\n",
    "    return torch.concat(\n",
    "        [direct_attributions.unsqueeze(-1), l1_attributions, l2_attributions], dim=-1\n",
    "    )\n",
    "\n",
    "\n",
    "logits, cache = model.run_with_cache(input_tokens, remove_batch_dim=True)\n",
    "str_tokens = input_tokens_as_strings\n",
    "tokens = input_tokens\n",
    "\n",
    "with t.inference_mode():\n",
    "    embed = cache[\"embed\"]\n",
    "    l1_results = cache[\"result\", 0]\n",
    "    l2_results = cache[\"result\", 1]\n",
    "    logit_attr = logit_attribution(\n",
    "        embed,\n",
    "        l1_results,\n",
    "        l2_results,\n",
    "        model.W_U,\n",
    "        tokens[0],\n",
    "    )\n",
    "\n",
    "    # Uses fancy indexing to get a len(tokens[0])-1 length tensor, where the kth entry is the predicted logit for the correct k+1th token\n",
    "    correct_token_logits = logits[0, torch.arange(len(tokens[0]) - 1), tokens[0, 1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13997a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a544cede",
   "metadata": {},
   "source": [
    "## Looking at it with CircuitsViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before even going to SAE, let's look at circuitsviz here\n",
    "import circuitsvis as cv\n",
    "\n",
    "import circuitsvis.activations\n",
    "import circuitsvis.attention\n",
    "import circuitsvis.logits\n",
    "import circuitsvis.tokens\n",
    "import circuitsvis.topk_samples\n",
    "import circuitsvis.topk_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b587d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see what we have\n",
    "import tabulate\n",
    "\n",
    "print(f\"{len(input_tokens)=}\")\n",
    "\n",
    "# show the first few elements of the `HookedTransformerConfig`, since that has things like `d_model`, num heads, etc\n",
    "print(tabulate.tabulate([(k, v) for k, v in cfg.__dict__.items()][:10]))\n",
    "\n",
    "print(tabulate.tabulate([(k, v.shape) for k, v in cache.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519db727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Viridis256\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable Bokeh output in the notebook\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "def tensor_to_dataframe(\n",
    "    tensor: torch.Tensor, labels: list[str], tokens: list[str]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a 2D PyTorch tensor to a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): A 2D tensor to convert.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame representation of the input tensor.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input tensor is not 2D.\n",
    "    \"\"\"\n",
    "    if tensor.dim() != 2:\n",
    "        raise ValueError(f\"Input tensor must be 2D, got {tensor.dim()}D\")\n",
    "    if len(labels) != 2:\n",
    "        raise ValueError(f\"Expected labels for both dimensions, got {len(labels)}\")\n",
    "\n",
    "    # Convert tensor to numpy array\n",
    "    numpy_array = tensor.detach().cpu().numpy()\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(numpy_array)\n",
    "\n",
    "    # Name the index the first label\n",
    "    df.index.name = labels[0]\n",
    "\n",
    "    # Name the columns the second label\n",
    "    df.columns = [f\"{labels[1]}_{i}\" for i in range(numpy_array.shape[1])]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def visualize_tensor_heatmap(\n",
    "    tensor: torch.Tensor,\n",
    "    title: str = \"Tensor Heatmap\",\n",
    "    colormap: list[str] = Viridis256,\n",
    "    width: int = 800,\n",
    "    height: int = 400,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualize a 2D tensor as a heatmap.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): A 2D tensor to visualize.\n",
    "        title (str): Title of the heatmap.\n",
    "        colormap (List[str]): A list of colors to use for the heatmap.\n",
    "        width (int): Width of the plot in pixels.\n",
    "        height (int): Height of the plot in pixels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure tensor is 2D\n",
    "    if tensor.dim() != 2:\n",
    "        raise ValueError(f\"Input tensor must be 2D, got {tensor.shape}\")\n",
    "\n",
    "    # convert tensor to dataframe\n",
    "    df = tensor_to_dataframe(tensor)\n",
    "\n",
    "    # Create a 2D grid of coordinates\n",
    "    y, x = np.mgrid[0 : data.shape[0], 0 : data.shape[1]]\n",
    "\n",
    "    # Flatten the arrays\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    z = data.flatten()\n",
    "\n",
    "    # Create a ColumnDataSource\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            z=z,\n",
    "            color=Viridis256[:: int(256 / len(z))][: len(z)],  # Map values to colors\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    p = figure(\n",
    "        title=\"Tensor Heatmap\",\n",
    "        x_range=(0, data.shape[1]),\n",
    "        y_range=(0, data.shape[0]),\n",
    "        toolbar_location=\"below\",\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset\",\n",
    "    )\n",
    "\n",
    "    # Add rectangular glyphs\n",
    "    p.rect(\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        width=1,\n",
    "        height=1,\n",
    "        source=source,\n",
    "        fill_color=\"color\",\n",
    "        line_color=None,\n",
    "    )\n",
    "\n",
    "    # Add hover tool\n",
    "    hover = HoverTool(tooltips=[(\"x\", \"@x\"), (\"y\", \"@y\"), (\"value\", \"@z{0.000}\")])\n",
    "    p.add_tools(hover)\n",
    "\n",
    "    # Invert y-axis to match tensor indexing\n",
    "    p.y_range.start, p.y_range.end = p.y_range.end, p.y_range.start\n",
    "\n",
    "    # Show the plot\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5317b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate.tabulate([(k, v[0].shape) for k, v in cache.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ad382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's go ahead and just use first batch\n",
    "def first_batch(tensor: Float32[torch.Tensor, \"b t c\"]) -> Float32[torch.Tensor, \"t c\"]:\n",
    "    return tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb2343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea0d0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from typing import Iterable, TypeVar\n",
    "\n",
    "import tabulate\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "# alias for `print(tabulate.tabulate(data))`\n",
    "def print_table(data: T) -> None:\n",
    "    print(tabulate.tabulate(data))\n",
    "\n",
    "\n",
    "# Define a function to print module weights recursively\n",
    "def print_module_weights(module: nn.Module) -> Iterable[tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Recursively prints the weights of a PyTorch module and its submodules.\n",
    "\n",
    "    This function traverses through the module hierarchy, printing information\n",
    "    about parameters that require gradients and are not hook-related.\n",
    "\n",
    "    Example:\n",
    "        >>> print_table(print_module_weights(model))\n",
    "\n",
    "        ------------------  ----------------------\n",
    "        embed.W_E           torch.Size([29, 14])\n",
    "        pos_embed.W_pos     torch.Size([9, 14])\n",
    "        blocks.0.ln1.w      torch.Size([14])\n",
    "        blocks.0.ln1.b      torch.Size([14])\n",
    "        blocks.0.ln2.w      torch.Size([14])\n",
    "        blocks.0.ln2.b      torch.Size([14])\n",
    "        blocks.0.attn.W_Q   torch.Size([3, 14, 4])\n",
    "        blocks.0.attn.W_O   torch.Size([3, 4, 14])\n",
    "        blocks.0.attn.b_Q   torch.Size([3, 4])\n",
    "        blocks.0.attn.b_O   torch.Size([14])\n",
    "        blocks.0.attn.W_K   torch.Size([3, 14, 4])\n",
    "        blocks.0.attn.W_V   torch.Size([3, 14, 4])\n",
    "        blocks.0.attn.b_K   torch.Size([3, 4])\n",
    "        blocks.0.attn.b_V   torch.Size([3, 4])\n",
    "        blocks.0.mlp.W_in   torch.Size([14, 56])\n",
    "        blocks.0.mlp.b_in   torch.Size([56])\n",
    "        blocks.0.mlp.W_out  torch.Size([56, 14])\n",
    "        blocks.0.mlp.b_out  torch.Size([14])\n",
    "        ln_final.w          torch.Size([14])\n",
    "        ln_final.b          torch.Size([14])\n",
    "        unembed.W_U         torch.Size([14, 29])\n",
    "        unembed.b_U         torch.Size([29])\n",
    "        ------------------  ----------------------\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): The PyTorch module to inspect.\n",
    "        prefix (str, optional): A string prefix for indentation in the output.\n",
    "                                Defaults to an empty string.\n",
    "\n",
    "    Returns:\n",
    "        Iterable[tuple[str, str]]: A list of tuples, where each tuple contains\n",
    "            the name and shape of the parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through named parameters of the module\n",
    "    for name, param in module.named_parameters():\n",
    "\n",
    "        # Check if parameter requires gradient and doesn't start with 'hook_'\n",
    "        if param.requires_grad and not name.startswith(\"hook_\"):\n",
    "\n",
    "            # yield parameter name and type\n",
    "            yield f\"{name}\", f\"{param.shape}\"\n",
    "\n",
    "\n",
    "def print_cache(cache: transformer_lens.ActivationCache) -> None:\n",
    "    print(tabulate.tabulate([(k, v[0].shape) for k, v in cache.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weights in the model:\")\n",
    "print_table(print_module_weights(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80fb6a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cached activations:\n",
      "------------------------------  -----------------------\n",
      "hook_embed                      torch.Size([20, 16])\n",
      "hook_pos_embed                  torch.Size([20, 16])\n",
      "blocks.0.hook_resid_pre         torch.Size([20, 16])\n",
      "blocks.0.ln1.hook_scale         torch.Size([20, 1])\n",
      "blocks.0.ln1.hook_normalized    torch.Size([20, 16])\n",
      "blocks.0.attn.hook_q            torch.Size([20, 2, 8])\n",
      "blocks.0.attn.hook_k            torch.Size([20, 2, 8])\n",
      "blocks.0.attn.hook_v            torch.Size([20, 2, 8])\n",
      "blocks.0.attn.hook_attn_scores  torch.Size([2, 20, 20])\n",
      "blocks.0.attn.hook_pattern      torch.Size([2, 20, 20])\n",
      "blocks.0.attn.hook_z            torch.Size([20, 2, 8])\n",
      "blocks.0.hook_attn_out          torch.Size([20, 16])\n",
      "blocks.0.hook_resid_mid         torch.Size([20, 16])\n",
      "blocks.0.ln2.hook_scale         torch.Size([20, 1])\n",
      "blocks.0.ln2.hook_normalized    torch.Size([20, 16])\n",
      "blocks.0.mlp.hook_pre           torch.Size([20, 64])\n",
      "blocks.0.mlp.hook_post          torch.Size([20, 64])\n",
      "blocks.0.hook_mlp_out           torch.Size([20, 16])\n",
      "blocks.0.hook_resid_post        torch.Size([20, 16])\n",
      "blocks.1.hook_resid_pre         torch.Size([20, 16])\n",
      "blocks.1.ln1.hook_scale         torch.Size([20, 1])\n",
      "blocks.1.ln1.hook_normalized    torch.Size([20, 16])\n",
      "blocks.1.attn.hook_q            torch.Size([20, 2, 8])\n",
      "blocks.1.attn.hook_k            torch.Size([20, 2, 8])\n",
      "blocks.1.attn.hook_v            torch.Size([20, 2, 8])\n",
      "blocks.1.attn.hook_attn_scores  torch.Size([2, 20, 20])\n",
      "blocks.1.attn.hook_pattern      torch.Size([2, 20, 20])\n",
      "blocks.1.attn.hook_z            torch.Size([20, 2, 8])\n",
      "blocks.1.hook_attn_out          torch.Size([20, 16])\n",
      "blocks.1.hook_resid_mid         torch.Size([20, 16])\n",
      "blocks.1.ln2.hook_scale         torch.Size([20, 1])\n",
      "blocks.1.ln2.hook_normalized    torch.Size([20, 16])\n",
      "blocks.1.mlp.hook_pre           torch.Size([20, 64])\n",
      "blocks.1.mlp.hook_post          torch.Size([20, 64])\n",
      "blocks.1.hook_mlp_out           torch.Size([20, 16])\n",
      "blocks.1.hook_resid_post        torch.Size([20, 16])\n",
      "ln_final.hook_scale             torch.Size([20, 1])\n",
      "ln_final.hook_normalized        torch.Size([20, 16])\n",
      "------------------------------  -----------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Cached activations:\")\n",
    "print_cache(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6910da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac58f3d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 57\u001b[0m\n\u001b[1;32m     36\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cache_key \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhook_embed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhook_pos_embed\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mln_final.hook_normalized\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     55\u001b[0m ]:\n\u001b[0;32m---> 57\u001b[0m     \u001b[43mplot_cache_activation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_tokens_as_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tokens_as_strings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m, in \u001b[0;36mplot_cache_activation\u001b[0;34m(cache, cache_key, input_tokens_as_strings)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_cache_activation\u001b[39m(\n\u001b[1;32m      2\u001b[0m     cache: transformer_lens\u001b[38;5;241m.\u001b[39mActivationCache,\n\u001b[1;32m      3\u001b[0m     cache_key: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m      4\u001b[0m     input_tokens_as_strings: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m      5\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     activations \u001b[38;5;241m=\u001b[39m \u001b[43mfirst_batch\u001b[49m(cache[cache_key])\n\u001b[1;32m      9\u001b[0m     figsize \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# make figure smaller for vectors\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'first_batch' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_cache_activation(\n",
    "    cache: transformer_lens.ActivationCache,\n",
    "    cache_key: str,\n",
    "    input_tokens_as_strings: list[str],\n",
    ") -> None:\n",
    "\n",
    "    activations = first_batch(cache[cache_key])\n",
    "\n",
    "    figsize = (4, 4)\n",
    "\n",
    "    # make figure smaller for vectors\n",
    "    if activations.shape[-1] == 1:\n",
    "        figsize = (4, 1.5)\n",
    "\n",
    "    # for larger activations like MLP, allow it to be taller\n",
    "    elif activations.shape[-1] > 20:\n",
    "        figsize = (4, 12)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    sns.heatmap(\n",
    "        activations.cpu().numpy().T,\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        xticklabels=input_tokens_as_strings,\n",
    "    )\n",
    "\n",
    "    plt.title(cache_key)\n",
    "\n",
    "    # TODO(bschoen): Allow specifying this\n",
    "    #\n",
    "    plt.ylabel(\"Embedding Dimension\")\n",
    "    plt.xlabel(\"Token\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for cache_key in [\n",
    "    \"hook_embed\",\n",
    "    \"hook_pos_embed\",\n",
    "    \"blocks.0.hook_resid_pre\",\n",
    "    \"blocks.0.ln1.hook_scale\",\n",
    "    \"blocks.0.ln1.hook_normalized\",\n",
    "    \"blocks.0.hook_attn_out\",\n",
    "    \"blocks.0.hook_resid_mid\",\n",
    "    \"blocks.0.ln2.hook_scale\",\n",
    "    \"blocks.0.ln2.hook_normalized\",\n",
    "    \"blocks.0.mlp.hook_pre\",\n",
    "    \"blocks.0.mlp.hook_post\",\n",
    "    \"blocks.0.hook_mlp_out\",\n",
    "    \"blocks.0.hook_resid_post\",\n",
    "    \"ln_final.hook_scale\",\n",
    "    \"ln_final.hook_normalized\",\n",
    "]:\n",
    "\n",
    "    plot_cache_activation(\n",
    "        cache=cache,\n",
    "        cache_key=cache_key,\n",
    "        input_tokens_as_strings=input_tokens_as_strings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedf265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize MLP\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "\n",
    "def plot_mlp_weights_and_biases(model):\n",
    "    # Function to plot heatmaps for MLP weights and biases\n",
    "\n",
    "    def plot_weight_bias_pair(weight, bias, title):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        sns.heatmap(weight.detach().cpu().numpy(), ax=ax1, cmap=\"coolwarm\", center=0)\n",
    "        ax1.set_title(f\"{title} - Weights\")\n",
    "        ax1.set_xlabel(\"Output dimension\")\n",
    "        ax1.set_ylabel(\"Input dimension\")\n",
    "\n",
    "        sns.heatmap(\n",
    "            bias.detach().cpu().numpy().reshape(-1, 1),\n",
    "            ax=ax2,\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "        )\n",
    "        ax2.set_title(f\"{title} - Biases\")\n",
    "        ax2.set_xlabel(\"Bias\")\n",
    "        ax2.set_ylabel(\"Dimension\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # MLP weights and biases\n",
    "    plot_weight_bias_pair(\n",
    "        model.blocks[0].mlp.W_in, model.blocks[0].mlp.b_in, \"MLP Input\"\n",
    "    )\n",
    "    plot_weight_bias_pair(\n",
    "        model.blocks[0].mlp.W_out, model.blocks[0].mlp.b_out, \"MLP Output\"\n",
    "    )\n",
    "\n",
    "    # Layer Norm final\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(\n",
    "        model.ln_final.w.detach().cpu().numpy().reshape(1, -1),\n",
    "        cmap=\"coolwarm\",\n",
    "        center=1,\n",
    "    )\n",
    "    plt.title(\"Layer Norm Final - Weights\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(\n",
    "        model.ln_final.b.detach().cpu().numpy().reshape(1, -1),\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "    )\n",
    "    plt.title(\"Layer Norm Final - Biases\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Unembed\n",
    "    plot_weight_bias_pair(model.unembed.W_U, model.unembed.b_U, \"Unembed\")\n",
    "\n",
    "\n",
    "# Call the function\n",
    "plot_mlp_weights_and_biases(model)\n",
    "\n",
    "# Comment: Additional visualizations that could be useful:\n",
    "# 1. Histograms of weight/bias distributions\n",
    "# 2. 3D surface plots for weights to show patterns\n",
    "# 3. Network architecture diagram with weight magnitudes represented by line thickness\n",
    "# 4. Animated heatmaps showing weight changes during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight_bias_activation(\n",
    "    weight,\n",
    "    bias,\n",
    "    activation,\n",
    "    title: str,\n",
    ") -> None:\n",
    "\n",
    "    activation = first_batch(activation)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "    sns.heatmap(weight.detach().cpu().numpy().T, ax=ax1, cmap=\"coolwarm\", center=0)\n",
    "    ax1.set_title(f\"{title} - Weight\")\n",
    "\n",
    "    sns.barplot(x=list(range(len(bias))), y=bias.detach().cpu().numpy(), ax=ax2)\n",
    "    ax2.set_title(f\"{title} - Bias\")\n",
    "    ax2.set_xlabel(\"Index\")\n",
    "    ax2.set_ylabel(\"Value\")\n",
    "\n",
    "    sns.heatmap(activation.detach().cpu().numpy().T, ax=ax3, cmap=\"coolwarm\", center=0)\n",
    "    ax3.set_title(f\"{title} - Activation\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_weight_bias_activation(\n",
    "    model.embed.W_E,\n",
    "    torch.zeros(model.embed.W_E.shape[1]),\n",
    "    cache[\"hook_embed\"],\n",
    "    \"Embedding\",\n",
    ")\n",
    "plot_weight_bias_activation(\n",
    "    model.pos_embed.W_pos,\n",
    "    torch.zeros(model.pos_embed.W_pos.shape[1]),\n",
    "    cache[\"hook_pos_embed\"],\n",
    "    \"Positional Embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(bschoen): Hook residual pre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8937bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting LayerNorm components\n",
    "\n",
    "\n",
    "def plot_layernorm(scale, normalized, title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    scale = first_batch(scale)\n",
    "    normalized = first_batch(normalized)\n",
    "\n",
    "    sns.barplot(\n",
    "        x=list(range(len(scale))), y=scale.squeeze().detach().cpu().numpy(), ax=ax1\n",
    "    )\n",
    "    ax1.set_title(f\"{title} - Scale\")\n",
    "    ax1.set_xlabel(\"Index\")\n",
    "    ax1.set_ylabel(\"Value\")\n",
    "\n",
    "    sns.heatmap(normalized.detach().cpu().numpy().T, ax=ax2, cmap=\"coolwarm\", center=0)\n",
    "    ax2.set_title(f\"{title} - Normalized\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_layernorm(\n",
    "    cache[\"blocks.0.ln1.hook_scale\"],\n",
    "    cache[\"blocks.0.ln1.hook_normalized\"],\n",
    "    \"LayerNorm 1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MLP components\n",
    "plot_weight_bias_activation(\n",
    "    model.blocks[0].mlp.W_in,\n",
    "    model.blocks[0].mlp.b_in,\n",
    "    cache[\"blocks.0.mlp.hook_pre\"],\n",
    "    \"MLP Input\",\n",
    ")\n",
    "plot_weight_bias_activation(\n",
    "    model.blocks[0].mlp.W_out,\n",
    "    model.blocks[0].mlp.b_out,\n",
    "    cache[\"blocks.0.mlp.hook_post\"],\n",
    "    \"MLP Output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdf33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c51ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ff7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a5f4f8",
   "metadata": {},
   "source": [
    "#### circuitsvis.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cc70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens := List of tokens if single sample (e.g. `[\"A\", \"person\"]`) or list of lists of tokens (e.g. `[[[\"A\", \"person\"], [\"is\", \"walking\"]]]`)\n",
    "# activations := Activations of the shape [tokens x layers x neurons] if single sample or list of [tokens x layers x neurons] if multiple samples\n",
    "\n",
    "# take first batch for now\n",
    "activations = cache[\"blocks.0.hook_mlp_out\"][0]\n",
    "print(f\"{activations.shape=}\")\n",
    "\n",
    "# reshape [tokens x neurons] -> [tokens x 1 x neurons]\n",
    "#  - `-1` means to automatically infer the size of the last dimension\n",
    "activations_view = activations.view(len(input_tokens), cfg.n_layers, -1)\n",
    "\n",
    "print(f\"{activations_view.shape=}\")\n",
    "\n",
    "# convert to strings (which this function expects)\n",
    "input_tokens_as_strings = [token_to_string(x.item()) for x in input_tokens]\n",
    "\n",
    "# TODO(bschoen): Is there a way to essentially stack these? Claude can probably give the React for that\n",
    "\n",
    "# so here we can visualize activations for a `torch.Size([1, 8, 16])`, which is most\n",
    "# of them since this is the size of the embedding dimension\n",
    "circuitsvis.activations.text_neuron_activations(\n",
    "    tokens=[token_to_string(x.item()) for x in input_tokens],\n",
    "    activations=activations_view,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f7aa2",
   "metadata": {},
   "source": [
    "#### circuitsvis.attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ba9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens: List of tokens (e.g. `[\"A\", \"person\"]`). Must be the same length as the list of values.\n",
    "# attention: Attention head activations of the shape [dest_tokens x src_tokens]\n",
    "# max_value: Maximum value. Used to determine how dark the token color is when positive (i.e. based on how close it is to the maximum value).\n",
    "# min_value: Minimum value. Used to determine how dark the token color is when negative (i.e. based on how close it is to the minimum value).\n",
    "# negative_color: Color for negative values\n",
    "# positive_color: Color for positive values.\n",
    "# show_axis_labels: Whether to show axis labels.\n",
    "# mask_upper_tri: Whether or not to mask the upper triangular portion of the attention patterns. Should be true for causal attention, false for bidirectional attention.\n",
    "\n",
    "\n",
    "# take first batch\n",
    "# ex: torch.Size([4, 8, 8]) -> [n_heads, n_ctx, n_ctx]\n",
    "# note: `blocks.0.attn.hook_attn_scores` is too early (not normalized?)\n",
    "attention = cache[\"blocks.0.attn.hook_pattern\"][0]\n",
    "\n",
    "print(f\"{attention.shape=}\")\n",
    "\n",
    "circuitsvis.attention.attention_heads(\n",
    "    tokens=input_tokens_as_strings,\n",
    "    attention=attention,\n",
    "    max_value=1,\n",
    "    min_value=-1,\n",
    "    negative_color=\"blue\",\n",
    "    positive_color=\"red\",\n",
    "    mask_upper_tri=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d512f",
   "metadata": {},
   "source": [
    "#### circuitsvis.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the normal one we usually show, i.e.\n",
    "# cv.logits.token_log_probs(\n",
    "#     token_indices=input_tokens,\n",
    "#     log_probs=log_probs,\n",
    "#     to_string=token_to_string,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a72925",
   "metadata": {},
   "source": [
    "#### circuitsvis.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa878bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, we'll look at each\n",
    "\n",
    "# take first batch, ex: torch.Size([8, 16])\n",
    "pos_embed = cache[\"hook_pos_embed\"][0]\n",
    "\n",
    "# low level function for coloring tokens according to single value\n",
    "for i in range(cfg.d_model):\n",
    "    display(\n",
    "        circuitsvis.tokens.colored_tokens(\n",
    "            tokens=input_tokens_as_strings,\n",
    "            values=pos_embed[:, i],\n",
    "            negative_color=\"blue\",\n",
    "            positive_color=\"red\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # only display a few for example\n",
    "    # if i >= 2:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first batch\n",
    "# ex: torch.size([8, 16]) = [n_ctx, d_model]\n",
    "attention_out = cache[\"blocks.0.hook_attn_out\"][0]\n",
    "\n",
    "circuitsvis.tokens.colored_tokens_multi(\n",
    "    tokens=input_tokens_as_strings,\n",
    "    values=attention_out,\n",
    "    labels=[str(x) for x in range(cfg.d_model)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitsvis.tokens.visualize_model_performance(\n",
    "    tokens=input_tokens,\n",
    "    str_tokens=input_tokens_as_strings,\n",
    "    logits=logits,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0406d0",
   "metadata": {},
   "source": [
    "#### circuitsvis.topk_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d155e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitsvis.topk_samples.topk_samples??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90d626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e239f06",
   "metadata": {},
   "source": [
    "#### circuitsvis.topk_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitsvis.topk_tokens.topk_tokens??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0533d521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee20ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4195832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c59598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86be5940",
   "metadata": {},
   "source": [
    "## SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_index in range(cfg.n_layers):\n",
    "    imshow(\n",
    "        transformer_lens.utils.to_numpy(cache[\"attn\", layer_index].mean([0, 1])),\n",
    "        title=f\"Layer {layer_index} Attention Pattern\",\n",
    "        height=400,\n",
    "        width=400,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dataclasses\n",
    "\n",
    "Loss = Float32[torch.Tensor, \"\"]\n",
    "MSELoss = Float32[torch.Tensor, \"\"]\n",
    "WeightedSparsityLoss = Float32[torch.Tensor, \"\"]\n",
    "\n",
    "Logits = Float32[torch.Tensor, \"n_ctx d_vocab\"]\n",
    "BatchedLogits = Float32[torch.Tensor, \"batch n_ctx d_vocab\"]\n",
    "\n",
    "ModelActivations = Float32[torch.Tensor, \"n_ctx d_model\"]\n",
    "BatchedModelActivations = Float32[torch.Tensor, \"batch n_ctx d_model\"]\n",
    "\n",
    "FlattenedModelActivations = Float32[torch.Tensor, \"d_sae_in\"]\n",
    "\n",
    "BatchedFlattenedModelActivations = Float32[torch.Tensor, \"batch d_sae_in\"]\n",
    "BatchedSAEActivations = Float32[torch.Tensor, \"batch d_sae_model\"]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SAEOutput:\n",
    "    sae_activations: BatchedSAEActivations\n",
    "    reconstructed_model_activations: BatchedFlattenedModelActivations\n",
    "\n",
    "\n",
    "def sparse_loss_kl_divergence(\n",
    "    flattened_model_activations: BatchedFlattenedModelActivations,\n",
    "    sae_output: SAEOutput,\n",
    "    sparsity_target: float,\n",
    "    sparsity_weight: float,\n",
    "    epsilon: float = 1e-7,\n",
    ") -> tuple[Loss, MSELoss, WeightedSparsityLoss]:\n",
    "\n",
    "    # same as dense loss (this is constant?)\n",
    "    mse_loss = F.mse_loss(\n",
    "        sae_output.reconstructed_model_activations,\n",
    "        flattened_model_activations,\n",
    "    )\n",
    "\n",
    "    # KL divergence for sparsity\n",
    "    avg_activation = torch.mean(sae_output.sae_activations, dim=0)\n",
    "\n",
    "    # print(f'[pre-clamping] {avg_activation=}')\n",
    "\n",
    "    # Add epsilon for numerical stability\n",
    "    avg_activation = torch.clamp(avg_activation, epsilon, 1 - epsilon)\n",
    "\n",
    "    kl_div = sparsity_target * torch.log(sparsity_target / avg_activation) + (\n",
    "        1 - sparsity_target\n",
    "    ) * torch.log((1 - sparsity_target) / (1 - avg_activation))\n",
    "    kl_div = torch.sum(kl_div)\n",
    "\n",
    "    # `sparsity_weight` decides how much we weight `KL-Divergence`\n",
    "    sparsity_penalty = sparsity_weight * kl_div\n",
    "\n",
    "    # print(f\"{mse_loss=}, {avg_activation=}, {kl_div.item()}, {sparsity_penalty=}\")\n",
    "\n",
    "    return mse_loss + sparsity_penalty, mse_loss, sparsity_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ac6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_loss_l1_norm(\n",
    "    flattened_model_activations: BatchedFlattenedModelActivations,\n",
    "    sae_output: SAEOutput,\n",
    "    sparsity_weight: float,\n",
    ") -> tuple[Loss, MSELoss, WeightedSparsityLoss]:\n",
    "\n",
    "    # Reconstruction loss (Mean Squared Error)\n",
    "    mse_loss = F.mse_loss(\n",
    "        sae_output.reconstructed_model_activations,\n",
    "        flattened_model_activations,\n",
    "    )\n",
    "\n",
    "    # L1 sparsity penalty\n",
    "    l1_penalty = torch.mean(torch.abs(sae_output.sae_activations))\n",
    "\n",
    "    sparsity_penalty = sparsity_weight * l1_penalty\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = mse_loss + sparsity_penalty\n",
    "\n",
    "    return total_loss, mse_loss, sparsity_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc92db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SparseAutoencoderConfig:\n",
    "    d_in: int\n",
    "    d_model: int\n",
    "\n",
    "\n",
    "# TODO(bschoen): Start using the config pattern, it stays typesafe and allows\n",
    "#                easy logging to things like wandb\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: SparseAutoencoderConfig,\n",
    "    ) -> None:\n",
    "\n",
    "        print(f\"Creating SparseAutoencoder with {cfg}\")\n",
    "\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "\n",
    "        self.d_in = cfg.d_in\n",
    "        self.d_model = cfg.d_model\n",
    "\n",
    "        self.encoder = nn.Linear(cfg.d_in, cfg.d_model)\n",
    "        self.decoder = nn.Linear(cfg.d_model, cfg.d_in)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: BatchedFlattenedModelActivations,\n",
    "    ) -> SAEOutput:\n",
    "\n",
    "        # TODO(bschoen): Which activation function should we use?\n",
    "        encoded = F.gelu(self.encoder(x))\n",
    "\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return SAEOutput(\n",
    "            sae_activations=encoded,\n",
    "            reconstructed_model_activations=decoded,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class LightningSparseAutoencoderConfig:\n",
    "\n",
    "    model_config: transformer_lens.HookedTransformerConfig\n",
    "    sae_config: SparseAutoencoderConfig\n",
    "    learning_rate: float\n",
    "    sparsity_weight: float\n",
    "\n",
    "\n",
    "# note: this kind of lightning adapter is a common pattern: https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#starter-example\n",
    "class LightningSparseAutoencoder(lightning.pytorch.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: LightningSparseAutoencoderConfig,\n",
    "    ) -> None:\n",
    "\n",
    "        super(LightningSparseAutoencoder, self).__init__()\n",
    "\n",
    "        self.model = transformer_lens.HookedTransformer(cfg=cfg.model_config)\n",
    "        self.sae = SparseAutoencoder(cfg=cfg.sae_config)\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        return self.model(inputs, target)\n",
    "\n",
    "    def training_step(self, batch, batch_idx: int) -> Loss:\n",
    "        inputs, target = batch\n",
    "\n",
    "        self.model\n",
    "        output = self(inputs, target)\n",
    "        loss = torch.nn.functional.cr(output, target.view(-1))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_id = \"blocks.0.hook_mlp_out\"\n",
    "\n",
    "cache[hook_id].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "sae_num_epochs = 100000\n",
    "sae_expansion_factor = 64\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "# both arbitrary for now\n",
    "# - Start small: A common approach is to begin with a relatively small sparsity weight,\n",
    "#                typically in the range of 1e-5 to 1e-3. This allows the model to\n",
    "#                learn meaningful representations before enforcing strong sparsity\n",
    "#                constraints.\n",
    "sparsity_weight: float = 1e-3  # Weight of the sparsity loss in the total loss\n",
    "sparsity_target: float = 0.05  # Target average activation of hidden neurons\n",
    "\n",
    "print(f\"Training SAE for {hook_id}...\")\n",
    "sae_d_in = (cfg.n_ctx - 1) * cfg.d_model  # -1 since not predicting first token\n",
    "sae_d_model = sae_d_in * sae_expansion_factor\n",
    "\n",
    "sae_cfg = SparseAutoencoderConfig(\n",
    "    d_in=sae_d_in,\n",
    "    d_model=sae_d_model,\n",
    ")\n",
    "\n",
    "sae_model = SparseAutoencoder(cfg=sae_cfg)\n",
    "sae_model.to(device)\n",
    "\n",
    "sae_optimizer = optim.Adam(sae_model.parameters(), lr=learning_rate)\n",
    "\n",
    "wandb.init(\n",
    "    project=\"toy-problem-hooked-transformer-sae\",\n",
    "    config={\n",
    "        \"sae_num_epochs\": sae_num_epochs,\n",
    "        \"sae_expansion_factor\": sae_expansion_factor,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"sparsity_weight\": sparsity_weight,\n",
    "        \"sparsity_target\": sparsity_target,\n",
    "        \"sae_d_in\": sae_d_in,\n",
    "        \"sae_d_model\": sae_d_model,\n",
    "        \"hook_id\": hook_id,\n",
    "    },\n",
    ")\n",
    "\n",
    "# put model itself into eval mode so doesn't change\n",
    "model.eval()\n",
    "\n",
    "# go through the training data again, this time training the sae on the activations\n",
    "for epoch, batch in tqdm.tqdm(\n",
    "    zip(\n",
    "        range(sae_num_epochs),\n",
    "        itertools.cycle(train_loader),\n",
    "    )\n",
    "):\n",
    "\n",
    "    tokens, target = batch\n",
    "\n",
    "    tokens, target = tokens.to(device), target.to(device)\n",
    "\n",
    "    # run through the model (with cache) to get the activations\n",
    "    logits, cache = model.run_with_cache(tokens)\n",
    "\n",
    "    # ex: torch.Size([4, 8, 16])\n",
    "    activations = cache[hook_id]\n",
    "\n",
    "    # ex: torch.Size([4, 128])\n",
    "    flattened_activations = activations.reshape(activations.size(0), -1)\n",
    "\n",
    "    sae_optimizer.zero_grad()\n",
    "\n",
    "    # now the SAE model is given the *activations*\n",
    "    sae_output = sae_model.forward(flattened_activations)\n",
    "\n",
    "    # compute loss\n",
    "\n",
    "    total_loss, reconstruction_loss, weighted_sparsity_loss = sparse_loss_kl_divergence(\n",
    "        flattened_activations,\n",
    "        sae_output,\n",
    "        sparsity_target=sparsity_target,\n",
    "        sparsity_weight=sparsity_weight,\n",
    "    )\n",
    "\n",
    "    \"\"\"total_loss, reconstruction_loss, weighted_sparsity_loss = sparse_loss_l1_norm(\n",
    "        flattened_model_activations=flattened_activations,\n",
    "        sae_output=sae_output,\n",
    "        sparsity_weight=sparsity_weight,\n",
    "    )\"\"\"\n",
    "\n",
    "    total_loss.backward()\n",
    "\n",
    "    sae_optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(\n",
    "            f\"Step {epoch}, \"\n",
    "            f\"Total Loss: {total_loss.item():.6f}, \"\n",
    "            f\"Reconstruction Loss: {reconstruction_loss.item():.6f}, \"\n",
    "            f\"Sparsity Loss: {weighted_sparsity_loss.item():.6f}\",\n",
    "        )\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"total_loss\": total_loss.item(),\n",
    "                \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "                \"weighted_sparsity_loss\": weighted_sparsity_loss.item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a407f",
   "metadata": {},
   "source": [
    "#### Dictionary Learning Implementation\n",
    "\n",
    "See [simple_dictionary_learning.ipynb](simple_dictionary_learning.ipynb) for a details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a1011",
   "metadata": {},
   "source": [
    "#### Extracting the learned dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SparseAutoencoder with d_in=128, d_model=512, sparsity_target=0.05\n",
    "dictionary: Float32[torch.Tensor, \"sae_hidden sae_in\"] = (\n",
    "    sae_model.encoder.weight.detach()\n",
    ")\n",
    "\n",
    "# ex: Dictionary shape: torch.Size([512, 128])\n",
    "print(f\"Dictionary shape: {dictionary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape dictionary elements to match original activation shape\n",
    "# (essentially `unflatting`)\n",
    "reshaped_dictionary = dictionary.reshape(sae_d_model, (cfg.n_ctx - 1), cfg.d_model)\n",
    "\n",
    "# Motivation: Extract the learned features (dictionary elements) from the encoder weights\n",
    "# ex: Dictionary shape: torch.Size([512, 8, 16])\n",
    "print(f\"Dictionary shape: {reshaped_dictionary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's always worth checking this sort of thing when you do this by hand\n",
    "# to check that you haven't got the wrong site, or are missing a\n",
    "# scaling factor or something like this.\n",
    "#\n",
    "# This is like the overfitting thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afd13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f65ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at an example batch from `test`\n",
    "\n",
    "# set both to eval mode\n",
    "model.eval()\n",
    "sae_model.eval()\n",
    "\n",
    "# grab something from the test batch\n",
    "example_batch = next(iter(test_loader))\n",
    "\n",
    "x, y = example_batch\n",
    "\n",
    "_, cache = model.run_with_cache(x)\n",
    "\n",
    "activations = cache[hook_id]\n",
    "\n",
    "print(f\"Activations shape: {activations.shape}\")\n",
    "\n",
    "# flatten it\n",
    "flattened_activations = activations.reshape(activations.size(0), -1)\n",
    "\n",
    "print(f\"{flattened_activations.shape=}\")\n",
    "\n",
    "sae_outputs = sae_model(flattened_activations)\n",
    "\n",
    "print(f\"{sae_outputs.sae_activations.shape=}\")\n",
    "print(f\"{sae_outputs.reconstructed_model_activations.shape=}\")\n",
    "\n",
    "# now we can get the dictionary\n",
    "dictionary = sae_model.encoder.weight.detach()\n",
    "\n",
    "print(f\"Dictionary shape: {dictionary.shape}\")\n",
    "\n",
    "# now we can get the sparse coefficients\n",
    "alpha = dictionary @ flattened_activations.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef94946",
   "metadata": {},
   "source": [
    "### Determine Quality Of SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sparsity(\n",
    "    sae_activations: BatchedSAEActivations,\n",
    "    threshold: float = 1e-5,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate sparsity of SAE activations across a batch.\n",
    "\n",
    "    Args:\n",
    "    sae_activations (torch.Tensor): The activations from the Sparse Autoencoder.\n",
    "                                    Shape: (batch, d_sae_model)\n",
    "    threshold (float): The threshold below which an activation is considered \"inactive\".\n",
    "\n",
    "    Returns:\n",
    "    float: The average sparsity value across the batch (fraction of inactive neurons).\n",
    "    \"\"\"\n",
    "    # Count the number of neurons that are below the threshold (inactive)\n",
    "    inactive_neurons = torch.sum(torch.abs(sae_activations) < threshold, dim=1)\n",
    "\n",
    "    # Calculate the fraction of inactive neurons for each item in the batch\n",
    "    sparsity_per_item = inactive_neurons.float() / sae_activations.shape[1]\n",
    "\n",
    "    # Take the mean across the batch\n",
    "    average_sparsity = torch.mean(sparsity_per_item)\n",
    "\n",
    "    return average_sparsity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce98afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_explained_variance(\n",
    "    reconstructed_model_activations: BatchedFlattenedModelActivations,\n",
    "    flattened_activations: BatchedFlattenedModelActivations,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the explained variance of the SAE activations.\n",
    "    \"\"\"\n",
    "\n",
    "    numerator = torch.mean(\n",
    "        (reconstructed_model_activations[:, 1:] - flattened_activations[:, 1:]) ** 2\n",
    "    )\n",
    "    denominator = flattened_activations[:, 1:].to(torch.float32).var()\n",
    "\n",
    "    explained_variance = 1 - (numerator / denominator)\n",
    "\n",
    "    return explained_variance.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained_variance=0.995 -> good, basically all the variance is explained by our SAE\n",
    "# sparsity=0.0045 -> good, very sparse, and more sparse than our target of 0.05\n",
    "explained_variance = calculate_explained_variance(\n",
    "    sae_outputs.reconstructed_model_activations,\n",
    "    flattened_activations,\n",
    ")\n",
    "print(f\"{explained_variance=:.4f}\")\n",
    "\n",
    "sparsity = calculate_sparsity(sae_outputs.sae_activations)\n",
    "print(f\"{sparsity=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze the relationship between SAE activations and input features\n",
    "\n",
    "# TODO(bschoen): Oh `imshow` is huge here!\n",
    "\n",
    "# 1. Visualize the dictionary (encoder weights)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(dictionary.cpu().T, aspect=\"auto\", cmap=\"RdBu_r\")\n",
    "plt.colorbar()\n",
    "plt.title(\"SAE Dictionary (Encoder Weights)\")\n",
    "plt.xlabel(\"Dictionary Elements\")\n",
    "plt.ylabel(\"Input Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Find the most active neurons for each input\n",
    "top_k = 5  # Number of top activations to consider\n",
    "\n",
    "# so this is essentially the top 5 activations over `batch_size` examples\n",
    "top_activations = torch.topk(sae_outputs.sae_activations, k=top_k, dim=1)\n",
    "\n",
    "# Visualization of top activations\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.heatmap(\n",
    "    top_activations.values.detach().cpu().numpy(), cmap=\"viridis\", annot=True, fmt=\".2f\"\n",
    ")\n",
    "plt.title(\"Top 5 Activation Values\")\n",
    "plt.xlabel(\"Top K\")\n",
    "plt.ylabel(\"Batch Sample\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(\n",
    "    top_activations.indices.detach().cpu().numpy(), cmap=\"YlOrRd\", annot=True, fmt=\"d\"\n",
    ")\n",
    "plt.title(\"Indices of Top 5 Activations\")\n",
    "plt.xlabel(\"Top K\")\n",
    "plt.ylabel(\"Batch Sample\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: frequency of top neurons\n",
    "top_neuron_counts = torch.bincount(\n",
    "    top_activations.indices.flatten().detach().cpu(),\n",
    "    minlength=sae_outputs.sae_activations.shape[1],\n",
    ")\n",
    "top_10_neurons = torch.topk(top_neuron_counts, k=10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(10), top_10_neurons.values.detach().cpu().numpy())\n",
    "plt.title(\"Top 10 Most Frequently Activated Neurons\")\n",
    "plt.xlabel(\"Neuron Index\")\n",
    "plt.ylabel(\"Activation Frequency\")\n",
    "plt.xticks(range(10), top_10_neurons.indices.detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_outputs.sae_activations[:, 1210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sae_outputs.sae_activations.shape=}\")\n",
    "print(f\"{top_activations.values.shape=}\")\n",
    "print(f\"{top_activations.indices.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_activations.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4932383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex: 51 and 410 show up a lot\n",
    "sns.heatmap(top_activations.values.cpu().T, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Analyze feature importance for each neuron\n",
    "feature_importance = torch.abs(dictionary).sum(dim=1)\n",
    "top_features = torch.topk(feature_importance, k=10)\n",
    "\n",
    "print(f\"{dictionary.shape=}\")\n",
    "print(f\"{feature_importance.shape=}\")\n",
    "print(f\"{top_features.values.shape=}\")\n",
    "print(f\"{top_features.indices.shape=}\")\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597dd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop 10 most important neurons:\")\n",
    "for i, (value, index) in enumerate(\n",
    "    zip(top_features.values.tolist(), top_features.indices.tolist())\n",
    "):\n",
    "    print(f\"Neuron {index}:\\t{value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0168d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77201da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features.indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualize activations for a few examples\n",
    "\n",
    "# first look at a single batch\n",
    "sae_activations = sae_outputs.sae_activations[0].detach().cpu()\n",
    "\n",
    "print(f\"{sae_activations.shape=}\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "\n",
    "# Look at a single batch\n",
    "plt.bar(range(sae_activations.shape[0]), sae_activations)\n",
    "\n",
    "plt.title(f\"SAE Activations for Example\")\n",
    "plt.xlabel(\"Neuron\")\n",
    "plt.ylabel(\"Activation\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fa395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a496682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Reconstruct input features from SAE activations\n",
    "#\n",
    "# Take a single batch first\n",
    "reconstructed_model_activations = (\n",
    "    sae_outputs.reconstructed_model_activations.detach().cpu()\n",
    ")\n",
    "\n",
    "# 6. Compare original and reconstructed features\n",
    "num_features = 5\n",
    "\n",
    "plt.figure(figsize=(15, 3 * num_features))\n",
    "for i in range(num_features):\n",
    "    plt.subplot(num_features, 1, i + 1)\n",
    "    plt.ylim(-1, 1)  # Set y-axis range from -1 to 1\n",
    "    plt.plot(flattened_activations[:, i].cpu(), label=\"Original\", alpha=0.5)\n",
    "    plt.plot(reconstructed_model_activations[:, i], label=\"Reconstructed\", alpha=0.5)\n",
    "    plt.title(f\"Feature {i}: Original vs Reconstructed\")\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b59930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Correlation between SAE activations and input features\n",
    "correlation_matrix = torch.corrcoef(\n",
    "    torch.cat([sae_outputs.sae_activations, flattened_activations], dim=1).T\n",
    ")\n",
    "num_neurons = sae_outputs.sae_activations.shape[1]\n",
    "neuron_feature_correlation = correlation_matrix[:num_neurons, num_neurons:]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(\n",
    "    neuron_feature_correlation.detach().cpu(),\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation between SAE Neurons and Input Features\")\n",
    "plt.xlabel(\"Input Features\")\n",
    "plt.ylabel(\"SAE Neurons\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d72027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385d16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02318ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47054e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_outputs.sae_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960382a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c6bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdbe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect max activations\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # go through the training data again, but don't cycle, no reason to go through more than once\n",
    "    for batch in tqdm.tqdm(train_loader):\n",
    "\n",
    "        tokens, target = batch\n",
    "\n",
    "        tokens, target = tokens.to(device), target.to(device)\n",
    "\n",
    "        # run through the model (with cache) to get the activations\n",
    "        logits, cache = model.run_with_cache(tokens)\n",
    "\n",
    "        # ex: torch.Size([4, 8, 16])\n",
    "        activations = cache[hook_id]\n",
    "\n",
    "        # ex: torch.Size([4, 128])\n",
    "        flattened_activations = activations.reshape(activations.size(0), -1)\n",
    "\n",
    "        # now the SAE model is given the *activations*\n",
    "        encoded, decoded = sae_model(flattened_activations)\n",
    "\n",
    "        sae_activations = encoded\n",
    "\n",
    "        # sae_activations.reshape(sae_d_model, (cfg.n_ctx - 1), cfg.d_model)\n",
    "\n",
    "        # max_activations = torch.max(encoded, dim=1)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc950af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = sae_model.encoder.weight @ flattened_activations[0]\n",
    "\n",
    "print(f\"{alpha.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9278a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.abs(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04427556",
   "metadata": {},
   "outputs": [],
   "source": [
    "8 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474f153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
