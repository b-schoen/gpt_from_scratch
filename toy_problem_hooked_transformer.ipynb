{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3674b7-cdcf-411d-80c5-ca44b425ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7d994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e872e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens as tl\n",
    "\n",
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15ad612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "import rich.table\n",
    "\n",
    "import dataclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaaf1cc",
   "metadata": {},
   "source": [
    "# HookedTransformer\n",
    "\n",
    "* [TransformerLens - Tutorial - Trains HookedTransformer from Scratch](https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/No_Position_Experiment.ipynb)\n",
    "\n",
    "```python\n",
    "import transformers\n",
    "\n",
    "# note: it's probably easier to just operate on tokens outside of the model,\n",
    "#       that'll also make it clearer where tokenizer is used\n",
    "#\n",
    "# okay wrapping a pretrained tokenizer *can* be done:\n",
    "# - https://huggingface.co/learn/nlp-course/chapter6/8#building-a-bpe-tokenizer-from-scratch\n",
    "# - but none of the models support just naive encoding\n",
    "#   - https://huggingface.co/docs/tokenizers/api/models#tokenizers.models.BPE\n",
    "class HookedTransformer:\n",
    "    cfg: HookedTransformerConfig\n",
    "\n",
    "    # note: actually does an `isinstance` check in the constructor\n",
    "    tokenizer: transformers.PreTrainedTokenizerBase | None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76467a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "\n",
    "from jaxtyping import Int64, Float32\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import string\n",
    "import itertools\n",
    "import more_itertools\n",
    "import dataclasses\n",
    "\n",
    "import torch\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbd75509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting code copied over from transformer_lens tutorial notebook\n",
    "\n",
    "\n",
    "def line(tensor: torch.Tensor, line_labels=None, yaxis=\"\", xaxis=\"\", **kwargs):\n",
    "    tensor = transformer_lens.utils.to_numpy(tensor)\n",
    "    labels = {\"y\": yaxis, \"x\": xaxis}\n",
    "    fig = px.line(tensor, labels=labels, **kwargs)\n",
    "    if line_labels:\n",
    "        for c, label in enumerate(line_labels):\n",
    "            fig.data[c].name = label\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def imshow(tensor: torch.Tensor, yaxis=\"\", xaxis=\"\", **kwargs):\n",
    "    tensor = transformer_lens.utils.to_numpy(tensor)\n",
    "    plot_kwargs = {\n",
    "        \"color_continuous_scale\": \"RdBu\",\n",
    "        \"color_continuous_midpoint\": 0.0,\n",
    "        \"labels\": {\"x\": xaxis, \"y\": yaxis},\n",
    "    }\n",
    "    plot_kwargs.update(kwargs)\n",
    "    px.imshow(tensor, **plot_kwargs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27dc4a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cache(cache: tl.ActivationCache) -> None:\n",
    "\n",
    "    table = rich.table.Table(\"Hook Name\", \"Shape\")\n",
    "\n",
    "    for k, v in cache.items():\n",
    "        table.add_row(k, str(v.shape))\n",
    "\n",
    "    rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5605e578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = transformer_lens.utils.get_device()\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a69f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1e9839",
   "metadata": {},
   "source": [
    "### Setup Sample Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70bd2cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<aaaa|aaaa>',\n",
       " '<aaab|aaab>',\n",
       " '<aaac|aaac>',\n",
       " '<aaad|aaad>',\n",
       " '<aaae|aaae>',\n",
       " '<aaaf|aaaf>',\n",
       " '<aaag|aaag>',\n",
       " '<aaah|aaah>',\n",
       " '<aaai|aaai>',\n",
       " '<aaaj|aaaj>']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SpecialToken:\n",
    "    # note: as assume a BOS token because transformerlens expects it\n",
    "    BOS = \"<\"\n",
    "    # we use a EOS token for convenience\n",
    "    EOS = \">\"\n",
    "\n",
    "\n",
    "# note: without length, the model doesn't need to learn induction heads, just directly copies\n",
    "\n",
    "\n",
    "# TODO(bschoen): Allow this to generalize in the future\n",
    "#\n",
    "# Good for purely attention, since seeing patterns\n",
    "def generate_sample_palindrome_then_repeated() -> Iterable[str]:\n",
    "    \"\"\"Generate palindrom samples like `<abc|cba|abc>`.\"\"\"\n",
    "\n",
    "    # Generate all combinations of lowercase letters\n",
    "    characters = string.ascii_lowercase\n",
    "\n",
    "    # note: chosen arbitrarily\n",
    "    lengths = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "    # pad to max length\n",
    "    max_length = 1 + max(lengths) + 1 + max(lengths) + 1 + max(lengths) + 1 + max(lengths) + 1\n",
    "\n",
    "    # set max number to take of each length\n",
    "    max_combinations_per_length = 10000\n",
    "\n",
    "    for length in lengths:\n",
    "\n",
    "        for combination_index, combination in enumerate(\n",
    "            itertools.product(characters, repeat=length)\n",
    "        ):\n",
    "\n",
    "            if combination_index > max_combinations_per_length:\n",
    "                break\n",
    "\n",
    "            combination_str = \"\".join(combination)\n",
    "            reversed_str = \"\".join(reversed(combination_str))\n",
    "\n",
    "            sample = (\n",
    "                SpecialToken.BOS\n",
    "                + combination_str\n",
    "                + \"|\"\n",
    "                + reversed_str\n",
    "                + \"|\"\n",
    "                + combination_str\n",
    "                + SpecialToken.EOS\n",
    "            )\n",
    "\n",
    "            # Pad the sample to max_length with EOS tokens\n",
    "            padded_sample = sample.ljust(max_length, SpecialToken.EOS)\n",
    "\n",
    "            yield padded_sample  # Return the padded sample\n",
    "\n",
    "\n",
    "# TODO(bschoen): For this do we get like a \"next biggest\" head?\n",
    "# TODO(bschoen): Can we do circuit analysis on this?\n",
    "def generate_sample_sorted() -> Iterable[str]:\n",
    "    \"\"\"Generate sequence sorted `<cab|abc>`.\"\"\"\n",
    "\n",
    "    # Generate all combinations of lowercase letters\n",
    "    characters = string.ascii_lowercase\n",
    "\n",
    "    # note: chosen arbitrarily\n",
    "    # lengths = [3, 4, 5, 6, 7]\n",
    "    # lengths = [2, 3, 4, 5]  # , 6, 7]\n",
    "    lengths = [4]\n",
    "\n",
    "    # pad to max length\n",
    "    max_length = 1 + max(lengths) + 1 + max(lengths) + 1\n",
    "\n",
    "    # set max number to take of each length\n",
    "    # max_combinations_per_length = 10000\n",
    "\n",
    "    for length in lengths:\n",
    "\n",
    "        for combination_index, combination in enumerate(\n",
    "            itertools.product(characters, repeat=length)\n",
    "        ):\n",
    "\n",
    "            # if combination_index > max_combinations_per_length:\n",
    "            #    break\n",
    "\n",
    "            combination_str = \"\".join(combination)\n",
    "            sorted_str = \"\".join(sorted(combination_str))\n",
    "\n",
    "            sample = SpecialToken.BOS + combination_str + \"|\" + sorted_str + SpecialToken.EOS\n",
    "\n",
    "            # Pad the sample to max_length with EOS tokens\n",
    "            padded_sample = sample.ljust(max_length, SpecialToken.EOS)\n",
    "\n",
    "            yield padded_sample  # Return the padded sample\n",
    "\n",
    "\n",
    "generate_sample = generate_sample_sorted\n",
    "\n",
    "# show a few examples\n",
    "[x for x in more_itertools.take(10, generate_sample())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75a15d",
   "metadata": {},
   "source": [
    "### Setup Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09afecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch.naive_tokenizer import NaiveTokenizer\n",
    "import random\n",
    "\n",
    "vocab = string.ascii_lowercase + \"|\" + SpecialToken.BOS + SpecialToken.EOS\n",
    "\n",
    "tokenizer = NaiveTokenizer.from_text(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f6b6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t\t<abc|cba|abc><bd|db|bd>>>>\n",
      "Tokenized:\t\u001b[44m\u001b[97m<\u001b[0m\u001b[41m\u001b[97ma\u001b[0m\u001b[42m\u001b[97mb\u001b[0m\u001b[45m\u001b[97mc\u001b[0m\u001b[43m\u001b[97m|\u001b[0m\u001b[46m\u001b[97mc\u001b[0m\u001b[44m\u001b[97mb\u001b[0m\u001b[41m\u001b[97ma\u001b[0m\u001b[42m\u001b[97m|\u001b[0m\u001b[45m\u001b[97ma\u001b[0m\u001b[43m\u001b[97mb\u001b[0m\u001b[46m\u001b[97mc\u001b[0m\u001b[44m\u001b[97m>\u001b[0m\u001b[41m\u001b[97m<\u001b[0m\u001b[42m\u001b[97mb\u001b[0m\u001b[45m\u001b[97md\u001b[0m\u001b[43m\u001b[97m|\u001b[0m\u001b[46m\u001b[97md\u001b[0m\u001b[44m\u001b[97mb\u001b[0m\u001b[41m\u001b[97m|\u001b[0m\u001b[42m\u001b[97mb\u001b[0m\u001b[45m\u001b[97md\u001b[0m\u001b[43m\u001b[97m>\u001b[0m\u001b[46m\u001b[97m>\u001b[0m\u001b[44m\u001b[97m>\u001b[0m\u001b[41m\u001b[97m>\u001b[0m\n",
      "Token ID | Token Bytes | Token String\n",
      "---------+-------------+--------------\n",
      "       0 | \u001b[38;5;2m3C\u001b[0m | '<'\n",
      "          \u001b[48;5;1m\u001b[38;5;15m<\u001b[0mabc|cba|abc><bd|db|bd>>>>\n",
      "          U+003C LESS-THAN SIGN (1 bytes: \u001b[38;5;2m3C\u001b[0m)\n",
      "       2 | \u001b[38;5;2m61\u001b[0m | 'a'\n",
      "          <\u001b[48;5;1m\u001b[38;5;15ma\u001b[0mbc|cba|abc><bd|db|bd>>>>\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <a\u001b[48;5;1m\u001b[38;5;15mb\u001b[0mc|cba|abc><bd|db|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       4 | \u001b[38;5;2m63\u001b[0m | 'c'\n",
      "          <ab\u001b[48;5;1m\u001b[38;5;15mc\u001b[0m|cba|abc><bd|db|bd>>>>\n",
      "          U+0063 LATIN SMALL LETTER C (1 bytes: \u001b[38;5;2m63\u001b[0m)\n",
      "      28 | \u001b[38;5;2m7C\u001b[0m | '|'\n",
      "          <abc\u001b[48;5;1m\u001b[38;5;15m|\u001b[0mcba|abc><bd|db|bd>>>>\n",
      "          U+007C VERTICAL LINE (1 bytes: \u001b[38;5;2m7C\u001b[0m)\n",
      "       4 | \u001b[38;5;2m63\u001b[0m | 'c'\n",
      "          <abc|\u001b[48;5;1m\u001b[38;5;15mc\u001b[0mba|abc><bd|db|bd>>>>\n",
      "          U+0063 LATIN SMALL LETTER C (1 bytes: \u001b[38;5;2m63\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|c\u001b[48;5;1m\u001b[38;5;15mb\u001b[0ma|abc><bd|db|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       2 | \u001b[38;5;2m61\u001b[0m | 'a'\n",
      "          <abc|cb\u001b[48;5;1m\u001b[38;5;15ma\u001b[0m|abc><bd|db|bd>>>>\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "      28 | \u001b[38;5;2m7C\u001b[0m | '|'\n",
      "          <abc|cba\u001b[48;5;1m\u001b[38;5;15m|\u001b[0mabc><bd|db|bd>>>>\n",
      "          U+007C VERTICAL LINE (1 bytes: \u001b[38;5;2m7C\u001b[0m)\n",
      "       2 | \u001b[38;5;2m61\u001b[0m | 'a'\n",
      "          <abc|cba|\u001b[48;5;1m\u001b[38;5;15ma\u001b[0mbc><bd|db|bd>>>>\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|cba|a\u001b[48;5;1m\u001b[38;5;15mb\u001b[0mc><bd|db|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       4 | \u001b[38;5;2m63\u001b[0m | 'c'\n",
      "          <abc|cba|ab\u001b[48;5;1m\u001b[38;5;15mc\u001b[0m><bd|db|bd>>>>\n",
      "          U+0063 LATIN SMALL LETTER C (1 bytes: \u001b[38;5;2m63\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m<bd|db|bd>>>>\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n",
      "       0 | \u001b[38;5;2m3C\u001b[0m | '<'\n",
      "          <abc|cba|abc>\u001b[48;5;1m\u001b[38;5;15m<\u001b[0mbd|db|bd>>>>\n",
      "          U+003C LESS-THAN SIGN (1 bytes: \u001b[38;5;2m3C\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|cba|abc><\u001b[48;5;1m\u001b[38;5;15mb\u001b[0md|db|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       5 | \u001b[38;5;2m64\u001b[0m | 'd'\n",
      "          <abc|cba|abc><b\u001b[48;5;1m\u001b[38;5;15md\u001b[0m|db|bd>>>>\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "      28 | \u001b[38;5;2m7C\u001b[0m | '|'\n",
      "          <abc|cba|abc><bd\u001b[48;5;1m\u001b[38;5;15m|\u001b[0mdb|bd>>>>\n",
      "          U+007C VERTICAL LINE (1 bytes: \u001b[38;5;2m7C\u001b[0m)\n",
      "       5 | \u001b[38;5;2m64\u001b[0m | 'd'\n",
      "          <abc|cba|abc><bd|\u001b[48;5;1m\u001b[38;5;15md\u001b[0mb|bd>>>>\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|cba|abc><bd|d\u001b[48;5;1m\u001b[38;5;15mb\u001b[0m|bd>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "      28 | \u001b[38;5;2m7C\u001b[0m | '|'\n",
      "          <abc|cba|abc><bd|db\u001b[48;5;1m\u001b[38;5;15m|\u001b[0mbd>>>>\n",
      "          U+007C VERTICAL LINE (1 bytes: \u001b[38;5;2m7C\u001b[0m)\n",
      "       3 | \u001b[38;5;2m62\u001b[0m | 'b'\n",
      "          <abc|cba|abc><bd|db|\u001b[48;5;1m\u001b[38;5;15mb\u001b[0md>>>>\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "       5 | \u001b[38;5;2m64\u001b[0m | 'd'\n",
      "          <abc|cba|abc><bd|db|b\u001b[48;5;1m\u001b[38;5;15md\u001b[0m>>>>\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc><bd|db|bd\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m>>>\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc><bd|db|bd>\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m>>\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc><bd|db|bd>>\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m>\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n",
      "       1 | \u001b[38;5;2m3E\u001b[0m | '>'\n",
      "          <abc|cba|abc><bd|db|bd>>>\u001b[48;5;1m\u001b[38;5;15m>\u001b[0m\n",
      "          U+003E GREATER-THAN SIGN (1 bytes: \u001b[38;5;2m3E\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "from gpt_from_scratch import tokenizer_utils\n",
    "\n",
    "# test tokenizer\n",
    "input_text = \"<abc|cba|abc><bd|db|bd>>>>\"\n",
    "tokenizer_utils.show_token_mapping(tokenizer, input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cf19b4",
   "metadata": {},
   "source": [
    "### Setup Model Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8db3c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float, Int\n",
    "\n",
    "\n",
    "def add_batch_dimension(x: Float32[torch.Tensor, \"...\"]) -> Float32[torch.Tensor, \"batch ...\"]:\n",
    "\n",
    "    return einops.rearrange(x, \"... -> 1 ...\")\n",
    "\n",
    "\n",
    "def tokenize_string(\n",
    "    tokenizer: tokenizer_utils.Tokenizer,\n",
    "    input_string: str,\n",
    ") -> Int[torch.Tensor, \"seq\"]:\n",
    "\n",
    "    tokens = tokenizer.encode(input_string)\n",
    "\n",
    "    return torch.tensor(tokens, dtype=torch.long)\n",
    "\n",
    "\n",
    "def tokenize_string_as_batch(\n",
    "    tokenizer: tokenizer_utils.Tokenizer,\n",
    "    input_string: str,\n",
    ") -> Float32[torch.Tensor, \"batch seq\"]:\n",
    "\n",
    "    return add_batch_dimension(tokenize_string(tokenizer, input_string))\n",
    "\n",
    "\n",
    "def tokens_to_string(\n",
    "    tokenizer: tokenizer_utils.Tokenizer,\n",
    "    tokens: Int[torch.Tensor, \"seq\"],\n",
    ") -> str:\n",
    "\n",
    "    return tokenizer.decode(tokens.tolist())\n",
    "\n",
    "\n",
    "# note: will currently generate up to context length\n",
    "def generate(\n",
    "    model: tl.HookedTransformer,\n",
    "    tokenizer: tokenizer_utils.Tokenizer,\n",
    "    input_string: str,\n",
    ") -> str:\n",
    "\n",
    "    # tokenize input string\n",
    "    tokens: Int[torch.Tensor, \"batch=1 seq\"] = tokenize_string_as_batch(tokenizer, input_string)\n",
    "\n",
    "    # while shorter than context length\n",
    "    while tokens.shape[-1] < model.cfg.n_ctx:\n",
    "\n",
    "        # pass current tokens through model\n",
    "        logits: Float[torch.Tensor, \"batch=1 seq d_vocab\"] = model.forward(tokens)\n",
    "\n",
    "        # get logits corresponding to next token\n",
    "        final_logits: Float[torch.Tensor, \"batch=1 d_vocab\"] = logits[:, -1, :]\n",
    "\n",
    "        # just sample the max logit (equivalent to temperature 0)\n",
    "        output_tokens: Int[torch.Tensor, \"batch=1\"] = final_logits.argmax(-1)\n",
    "\n",
    "        # append to tokens\n",
    "        tokens = torch.cat([tokens, output_tokens.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "    # convert from tokens to string\n",
    "    output_string = tokenizer.decode(tokens[0].tolist())\n",
    "\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3882db",
   "metadata": {},
   "source": [
    "### Setup Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98635a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sequence_accuracy_on_test_batches(\n",
    "    model: tl.HookedTransformer,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    separator_token_id: int,\n",
    "    max_batches: int | None = None,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluates the average token-level accuracy of the model in predicting\n",
    "    the second half of sequences in the test batches.\n",
    "\n",
    "    Note:\n",
    "        This holds generally for anything where we're predicting after the first `|`, which\n",
    "        is the case for all the toy models we're constructing.\n",
    "\n",
    "    Args:\n",
    "        model (HookedTransformer): The trained autoregressive model.\n",
    "        data_loader (torch.utils.data.DataLoader): DataLoader for the test dataset.\n",
    "        tokenizer (tokenizer_utils.NaiveTokenizer): The tokenizer used for encoding/decoding.\n",
    "        separator_token_id (int): The token ID for the separator '|'.\n",
    "        max_batches (Optional[int], optional): Maximum number of batches to evaluate.\n",
    "            If None, evaluates all batches. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: The average sequence-level accuracy across the evaluated batches.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    device = next(model.parameters()).device  # Ensure we're using the correct device\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch_idx, (x, y) in enumerate(data_loader):\n",
    "            if max_batches is not None and batch_idx >= max_batches:\n",
    "                break\n",
    "\n",
    "            # Move tensors to the appropriate device\n",
    "            x = x.to(device)  # Shape: [batch_size, seq_length - 1]\n",
    "            y = y.to(device)  # Shape: [batch_size, seq_length - 1]\n",
    "\n",
    "            batch_size, seq_length_minus_one = y.size()\n",
    "\n",
    "            # Convert token IDs to lists for easier manipulation\n",
    "            x_tokens = x.tolist()\n",
    "            y_tokens = y.tolist()\n",
    "\n",
    "            for i in range(batch_size):\n",
    "                # Reconstruct the full input and target sequences\n",
    "                # Since x is tokens[:-1] and y is tokens[1:], the full sequence is x + [y[-1]]\n",
    "                full_sequence = x_tokens[i] + [y_tokens[i][-1]]\n",
    "\n",
    "                # Find the separator token position in the full sequence\n",
    "                try:\n",
    "                    separator_idx = full_sequence.index(separator_token_id)\n",
    "                except ValueError:\n",
    "                    # Separator not found; consider this sample incorrect\n",
    "                    continue\n",
    "\n",
    "                # Define the context up to and including the separator\n",
    "                context = full_sequence[: separator_idx + 1]  # Include separator\n",
    "\n",
    "                # Define the target suffix (tokens after the separator)\n",
    "                target_suffix = full_sequence[separator_idx + 1 :]\n",
    "                target_suffix_length = len(target_suffix)\n",
    "\n",
    "                if target_suffix_length == 0:\n",
    "                    # Nothing to generate; consider this sample correct\n",
    "                    total_correct += 1\n",
    "                    total_samples += 1\n",
    "                    continue\n",
    "\n",
    "                # Initialize generated sequence with the context\n",
    "                #\n",
    "                # Shape: [1, context_length]\n",
    "                generated = torch.tensor(context, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "                # Generate tokens step-by-step\n",
    "                for _ in range(target_suffix_length):\n",
    "                    # Get model logits for the current sequences\n",
    "                    logits: Float32[torch.Tensor, \"batch seq d_vocab\"] = model.forward(generated)\n",
    "\n",
    "                    # Get logits for the last token\n",
    "                    final_logits: Float32[torch.Tensor, \"batch d_vocab\"] = logits[:, -1, :]\n",
    "\n",
    "                    # Predict the next token (greedy decoding)\n",
    "                    next_token = final_logits.argmax(dim=-1)  # Shape: [batch_size]\n",
    "\n",
    "                    # Append the predicted token to the generated sequence\n",
    "                    #\n",
    "                    # Shape: [1, seq_length + 1]\n",
    "                    generated = torch.cat([generated, next_token.unsqueeze(-1)], dim=-1)\n",
    "\n",
    "                # Extract the generated suffix\n",
    "                generated_suffix = generated[0, separator_idx + 1 :].tolist()\n",
    "\n",
    "                # Compare the entire generated suffix with the target suffix\n",
    "                if generated_suffix == target_suffix:\n",
    "                    total_correct += 1\n",
    "                total_samples += 1\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Compute average accuracy\n",
    "    average_accuracy = total_correct / total_samples if total_samples > 0 else 0.0\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6152a119",
   "metadata": {},
   "source": [
    "### Setup Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "268db8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(logits, target):\n",
    "    # standard cross entropy loss\n",
    "    return torch.nn.functional.cross_entropy(\n",
    "        logits.view(-1, logits.size(-1)),\n",
    "        target.view(-1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f67052",
   "metadata": {},
   "source": [
    "### Evaluate On Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e610984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_loss_on_test_batches(\n",
    "    model: transformer_lens.HookedTransformer,\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    max_batches: int,\n",
    ") -> float:\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "\n",
    "        for batch_index, batch in enumerate(data_loader):\n",
    "\n",
    "            if batch_index > max_batches:\n",
    "                break\n",
    "\n",
    "            x, y = batch\n",
    "\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "\n",
    "            loss = loss_fn(logits, y)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # Set the model back to training mode\n",
    "    model.train()\n",
    "\n",
    "    return sum(losses) / len(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084c7b6f",
   "metadata": {},
   "source": [
    "### Setup Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43250038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoregressiveDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples: list[str], tokenizer: NaiveTokenizer) -> None:\n",
    "        self.samples = samples\n",
    "        self.tokenizer = tokenizer  # Assuming tokenizer is defined in the global scope\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        tokens = self.tokenizer.encode(sample)\n",
    "\n",
    "        # Convert to tensor and add batch dimension\n",
    "        x = torch.tensor(tokens[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(tokens[1:], dtype=torch.long)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def make_batch_dataloader(\n",
    "    samples: list[str],\n",
    "    tokenizer: NaiveTokenizer,\n",
    "    batch_size: int,\n",
    ") -> tuple[torch.utils.data.Dataset, torch.utils.data.DataLoader]:\n",
    "\n",
    "    dataset = AutoregressiveDataset(samples=samples, tokenizer=tokenizer)\n",
    "\n",
    "    # Create DataLoader\n",
    "    dataloader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        # drop the last batch if it's incomplete\n",
    "        drop_last=True,\n",
    "    )\n",
    "\n",
    "    return dataset, dataloader\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# batch_generator = make_batch_generator(tokenizer, batch_size=4)\n",
    "# for x, y in batch_generator:\n",
    "#     # x is input, y is target (x shifted by 1)\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7cdd9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "456976 samples\n",
      "len(train_samples)=365581\n",
      "len(test_samples)=91395\n",
      "10: 91395\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# split into test and train\n",
    "all_samples = list(generate_sample())\n",
    "\n",
    "# note: 4394 batches = (26 * 26 * 26) / 4\n",
    "print(f\"{len(all_samples)} samples\")\n",
    "\n",
    "# Randomly shuffle all_samples\n",
    "random.shuffle(all_samples)  # In-place shuffling of the list\n",
    "\n",
    "# Inline comment explaining the motivation\n",
    "# We shuffle the samples to ensure a random distribution of data points\n",
    "# between the training and test sets, reducing potential bias\n",
    "\n",
    "\n",
    "# max_samples = 10\n",
    "# print(f'Capping at {max_samples} batches first to make sure we can overfit')\n",
    "# all_samples = all_samples[:max_samples]\n",
    "\n",
    "test_train_ratio = 0.2\n",
    "\n",
    "test_size = int(test_train_ratio * len(all_samples))\n",
    "\n",
    "# put remaining ones into train\n",
    "train_size = len(all_samples) - test_size\n",
    "\n",
    "train_samples = all_samples[:train_size]\n",
    "test_samples = all_samples[train_size:]\n",
    "\n",
    "print(f\"{len(train_samples)=}\")\n",
    "print(f\"{len(test_samples)=}\")\n",
    "\n",
    "# now we can finally construct dataloaders\n",
    "# batch_size = 128\n",
    "batch_size = 512\n",
    "\n",
    "train_dataset, train_loader = make_batch_dataloader(\n",
    "    samples=train_samples,\n",
    "    tokenizer=tokenizer,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "# Split test_samples based on the number of '>' characters\n",
    "test_samples_by_difficulty = {}\n",
    "for sample in test_samples:\n",
    "    difficulty = len(sample) - sample.count(\">\")\n",
    "    if difficulty not in test_samples_by_difficulty:\n",
    "        test_samples_by_difficulty[difficulty] = []\n",
    "    test_samples_by_difficulty[difficulty].append(sample)\n",
    "\n",
    "# Sort the dictionary by difficulty (number of '>' characters)\n",
    "test_samples_by_difficulty = dict(sorted(test_samples_by_difficulty.items(), reverse=True))\n",
    "\n",
    "# Inline comment explaining the motivation\n",
    "# We sort the dictionary by difficulty to ensure a consistent order\n",
    "# when iterating through the difficulty levels, making it easier to\n",
    "# analyze and compare model performance across increasing complexities\n",
    "\n",
    "for difficulty, samples in test_samples_by_difficulty.items():\n",
    "    print(f\"{difficulty}: {len(samples)}\")\n",
    "\n",
    "# Create dataloaders for each difficulty level\n",
    "test_datasets = {}\n",
    "test_loaders = {}\n",
    "for difficulty, samples in test_samples_by_difficulty.items():\n",
    "    test_datasets[difficulty], test_loaders[difficulty] = make_batch_dataloader(\n",
    "        samples=samples,\n",
    "        tokenizer=tokenizer,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "\n",
    "# Inline comment explaining the motivation\n",
    "# We split the test samples based on the number of '>' characters to create\n",
    "# separate datasets for different difficulty levels. This allows us to evaluate\n",
    "# the model's performance across varying complexities of input sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf7e574",
   "metadata": {},
   "source": [
    "### Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19115680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we know our vocab size from our sample generation\n",
    "def make_hooked_transformer_config(\n",
    "    n_layers: int,\n",
    "    d_model: int,\n",
    "    n_heads: int,\n",
    ") -> transformer_lens.HookedTransformerConfig:\n",
    "\n",
    "    for sample in generate_sample():\n",
    "        n_ctx = len(sample)\n",
    "        break\n",
    "\n",
    "    cfg = transformer_lens.HookedTransformerConfig(\n",
    "        n_layers=n_layers,\n",
    "        d_model=d_model,\n",
    "        d_head=d_model // n_heads,\n",
    "        # The number of attention heads.\n",
    "        # If not specified, will be set to d_in // d_head.\n",
    "        # (This is represented by a default value of -1)\n",
    "        n_heads=n_heads,\n",
    "        # The dimensionality of the feedforward mlp network.\n",
    "        # Defaults to 4 * d_in, and in an attn-only model is None.\n",
    "        # TODO(bschoen): Need to try out also setting `attn_only`\n",
    "        # d_mlp=None,\n",
    "        # note: transformerlens does the same thing if this is not set\n",
    "        d_vocab=len(tokenizer.byte_to_token_dict),\n",
    "        # length of the longest sample is our context length\n",
    "        n_ctx=n_ctx,\n",
    "        act_fn=\"relu\",\n",
    "        # normalization_type=\"LN\",\n",
    "        normalization_type=None,\n",
    "        # note: must be set, otherwise tries to default to cuda / cpu (not mps)\n",
    "        device=device.type,\n",
    "    )\n",
    "\n",
    "    print(f\"Num params: {cfg.n_params}\")\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a131f",
   "metadata": {},
   "source": [
    "## Setup Image Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f4d3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert matplotlib figure to PNG for wandb upload\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "from jaxtyping import Float\n",
    "\n",
    "\n",
    "def fig_to_wandb_image(fig) -> Image:\n",
    "    \"\"\"\n",
    "    Convert a matplotlib figure to a PNG image that can be uploaded to wandb.\n",
    "\n",
    "    Args:\n",
    "        fig (matplotlib.figure.Figure): The matplotlib figure to convert\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The figure as a PIL Image object\n",
    "    \"\"\"\n",
    "    # Save the figure to a byte buffer\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format=\"png\", dpi=300, bbox_inches=\"tight\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Convert the buffer to a PIL Image\n",
    "    image = Image.open(buf)\n",
    "    return image\n",
    "\n",
    "\n",
    "# note: `title` is passed in for telling them apart in gifs etc\n",
    "def generate_image_for_attention_patterns(\n",
    "    input_token_str_to_cache_dict: dict[str, transformer_lens.ActivationCache],\n",
    "    title: str,\n",
    ") -> Image:\n",
    "    \"\"\"\n",
    "    Visualize attention patterns for all layers and heads in the model for multiple caches.\n",
    "\n",
    "    Args:\n",
    "        caches (List[Dict[str, Any]]): List of caches containing attention patterns from model forward passes.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: A matplotlib figure containing the visualized attention patterns.\n",
    "    \"\"\"\n",
    "    input_token_strings = list(input_token_str_to_cache_dict.keys())\n",
    "    caches = list(input_token_str_to_cache_dict.values())\n",
    "\n",
    "    # Find all attention pattern tensors in the first cache (assuming all caches have the same structure)\n",
    "    pattern_keys = [key for key in caches[0].keys() if key.endswith(\".attn.hook_pattern\")]\n",
    "\n",
    "    n_layers = len(pattern_keys)\n",
    "    n_heads = caches[0][pattern_keys[0]].shape[1]\n",
    "    n_caches = len(caches)\n",
    "\n",
    "    # Calculate total number of subplots\n",
    "    total_subplots = n_layers * n_heads\n",
    "\n",
    "    # Create a figure with subplots stacked vertically for each cache\n",
    "    fig, axes = plt.subplots(n_caches, total_subplots, figsize=(4 * total_subplots, 4 * n_caches))\n",
    "\n",
    "    # Set overall figure title\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    # Color maps for alternating heads\n",
    "    cmaps = [\"Blues\", \"Reds\"]\n",
    "\n",
    "    for cache_idx, cache in enumerate(caches):\n",
    "        input_token_string = input_token_strings[cache_idx]\n",
    "        for layer, key in enumerate(pattern_keys):\n",
    "            attention_pattern = cache[key]\n",
    "\n",
    "            # Remove batch dimension and move to CPU\n",
    "            reshaped_pattern = attention_pattern.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "            for head in range(n_heads):\n",
    "                subplot_index = layer * n_heads + head\n",
    "                ax = axes[cache_idx, subplot_index] if n_caches > 1 else axes[subplot_index]\n",
    "\n",
    "                # Plot the attention pattern\n",
    "                im = ax.imshow(reshaped_pattern[head], cmap=cmaps[head % len(cmaps)])\n",
    "\n",
    "                # Set title for each subplot\n",
    "                ax.set_title(f\"L{layer}-H{head}\", fontsize=8)\n",
    "\n",
    "                # Set column labels as individual characters from input_token_string at the top\n",
    "                ax.xaxis.tick_top()\n",
    "                ax.set_xticks(range(len(input_token_string)))\n",
    "                ax.set_xticklabels(list(input_token_string), fontsize=6, ha=\"right\")\n",
    "\n",
    "                ax.set_yticks([])  # Remove y-axis ticks\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    image = fig_to_wandb_image(fig)\n",
    "\n",
    "    # close figure so doesn't keep taking up memory\n",
    "    plt.close(fig)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58e3c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def convert_pngs_in_directory_to_gif(output_dir: pathlib.Path) -> pathlib.Path:\n",
    "\n",
    "    # Get a list of all PNG files in the output directory\n",
    "    # Use rglob for recursive search of PNG files\n",
    "    png_files = list(output_dir.rglob(\"*.png\"))\n",
    "\n",
    "    # sort by step\n",
    "    #\n",
    "    # files have format\n",
    "    #\n",
    "    # - `.../<key>_<step>_<hash-identifier-thing>.png`\n",
    "    # - ex: `.../attention_100_d8bda3455ffb06855d88.png`\n",
    "    #\n",
    "    png_files = sorted(png_files, key=lambda x: int(x.name.split(\"_\")[1]))\n",
    "\n",
    "    # Create a list to store the image frames\n",
    "    frames = []\n",
    "\n",
    "    # Load each PNG file and append it to the frames list\n",
    "    print(f\"Generating gif from {len(png_files)} images...\")\n",
    "    for png_file in png_files:\n",
    "        # Open the image and convert it to RGB mode (required for GIF)\n",
    "        img = Image.open(str(png_file)).convert(\"RGB\")\n",
    "        frames.append(img)\n",
    "\n",
    "    # Define the output GIF filename\n",
    "    gif_filename = output_dir / \"attention_pattern_evolution.gif\"\n",
    "\n",
    "    # Save the frames as an animated GIF\n",
    "    print(f\"Saving gif from {len(frames)} frames to {gif_filename}...\")\n",
    "    frames[0].save(\n",
    "        gif_filename,\n",
    "        save_all=True,\n",
    "        append_images=frames[1:],\n",
    "        optimize=False,\n",
    "        duration=200,  # Duration between frames in milliseconds\n",
    "        loop=0,  # 0 means loop indefinitely\n",
    "    )\n",
    "\n",
    "    print(f\"GIF created and saved as: {gif_filename}\")\n",
    "\n",
    "    # Optionally, log the GIF to wandb\n",
    "    # wandb.log({\"attention_pattern_evolution\": wandb.Image(str(gif_filename))})\n",
    "\n",
    "    return gif_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0438238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WandbConstants:\n",
    "    ENTITY = \"bronsonschoen-personal-use\"\n",
    "    PROJECT = \"toy-problem-hooked-transformer-v6\"\n",
    "    NAME = \"toy-sequence\"\n",
    "    ATTENTION_PATTERN_IMAGES = \"attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65fc8dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LossValue = float\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class TrainModelResult:\n",
    "    model: transformer_lens.HookedTransformer\n",
    "\n",
    "    # returned because optuna needs it\n",
    "    # TODO(bschoen): Is this usually val loss?\n",
    "    train_loss: LossValue\n",
    "\n",
    "    # useful to retrieve files\n",
    "    wandb_run_name: str\n",
    "    wandb_run_id: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54530e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pathlib\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def download_images_from_run(result: TrainModelResult) -> pathlib.Path:\n",
    "\n",
    "    # write things to run specific directory\n",
    "    output_dir = pathlib.Path(f\"wandb_artifacts/{result.wandb_run_id}\")\n",
    "\n",
    "    # create output dir if not exists\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    api = wandb.Api()\n",
    "\n",
    "    identifier = \"/\".join(\n",
    "        [\n",
    "            WandbConstants.ENTITY,\n",
    "            WandbConstants.PROJECT,\n",
    "            result.wandb_run_id,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(f\"Downloading {identifier}...\")\n",
    "    run = api.run(identifier)\n",
    "\n",
    "    # filter down to just attention pattern images\n",
    "    files = [\n",
    "        x\n",
    "        for x in run.files()\n",
    "        if x.name.startswith(f\"media/images/{WandbConstants.ATTENTION_PATTERN_IMAGES}\")\n",
    "    ]\n",
    "\n",
    "    for file in tqdm.tqdm(desc=\"Downloading images...\", iterable=files):\n",
    "\n",
    "        print(f\"Downloading {file.name}\")\n",
    "        file.download(\n",
    "            root=str(output_dir),\n",
    "            replace=False,\n",
    "            exist_ok=True,\n",
    "            api=api,\n",
    "        )\n",
    "\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003ea31",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f5081e3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7533cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(bschoen): Holdout set of n+1 length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac160424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params: 6144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbronsonschoen\u001b[0m (\u001b[33mbronsonschoen-personal-use\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bronsonschoen/gpt_from_scratch/wandb/run-20240923_161125-plmn7eu9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6/runs/plmn7eu9' target=\"_blank\">toy-sequence</a></strong> to <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6/runs/plmn7eu9' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6/runs/plmn7eu9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name toy-sequence - plmn7eu9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.0\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "998it [00:21, 86.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.4375\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1996it [00:38, 95.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.880859375\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2992it [00:54, 97.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.94921875\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3994it [01:10, 87.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.970703125\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4993it [01:26, 86.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.98828125\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5992it [01:43, 88.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.986328125\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6992it [01:59, 89.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.9921875\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7998it [02:16, 91.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.99609375\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8996it [02:32, 95.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating test loss...\n",
      "Evaluating accuracy...\n",
      "Accuracy: 0.9921875\n",
      "Computing attention pattern visualization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [02:48, 59.28it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce77f40a8884a969db97e9e908dbaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.413 MB of 0.413 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>test_accuracy_difficulty_10</td><td></td></tr><tr><td>test_loss_difficulty_10</td><td></td></tr><tr><td>train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9000</td></tr><tr><td>test_accuracy_difficulty_10</td><td>0.99219</td></tr><tr><td>test_loss_difficulty_10</td><td>1.30711</td></tr><tr><td>train_loss</td><td>1.30645</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toy-sequence</strong> at: <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6/runs/plmn7eu9' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6/runs/plmn7eu9</a><br/> View project at: <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-v6</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 10 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240923_161125-plmn7eu9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train loss: 1.305617\n",
      "Num params: 6144\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "import torch.optim\n",
    "\n",
    "import wandb\n",
    "\n",
    "import dataclasses\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def print_json(value):\n",
    "    print(json.dumps(value, indent=2))\n",
    "\n",
    "\n",
    "# everything customizable via optuna\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class ModelAndTrainingConfig:\n",
    "\n",
    "    # input\n",
    "    train_loader: torch.utils.data.DataLoader\n",
    "    test_loaders: dict[int, torch.utils.data.DataLoader]\n",
    "\n",
    "    # training\n",
    "    num_epochs: int = 10000\n",
    "    eval_test_every_n: int = 500\n",
    "    wait_between_eval_s: int | None = None\n",
    "\n",
    "    # model\n",
    "    n_layers: int = 2\n",
    "    d_model: int = 16\n",
    "    n_heads: int = 2\n",
    "\n",
    "    # optimizers\n",
    "    betas: tuple[float, float] = (0.9, 0.999)\n",
    "    learning_rate: float = 1e-3\n",
    "    max_grad_norm: float = 1.0\n",
    "    weight_decay: float = 0.1\n",
    "\n",
    "    def get_hooked_transformer_config(self) -> transformer_lens.HookedTransformerConfig:\n",
    "        return make_hooked_transformer_config(\n",
    "            n_layers=self.n_layers,\n",
    "            d_model=self.d_model,\n",
    "            n_heads=self.n_heads,\n",
    "        )\n",
    "\n",
    "    def to_dict(self) -> dict[str, str | int]:\n",
    "        dict_repr = dataclasses.asdict(self)\n",
    "        dict_repr.pop(\"train_loader\")\n",
    "        dict_repr.pop(\"test_loaders\")\n",
    "        return dict_repr\n",
    "\n",
    "\n",
    "def train_model(cfg: ModelAndTrainingConfig) -> TrainModelResult:\n",
    "\n",
    "    # create new model instance\n",
    "    ht_cfg = cfg.get_hooked_transformer_config()\n",
    "    model = transformer_lens.HookedTransformer(ht_cfg)\n",
    "\n",
    "    # setup optimizers\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=cfg.learning_rate,\n",
    "        betas=cfg.betas,\n",
    "        weight_decay=cfg.weight_decay,\n",
    "    )\n",
    "    # scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    #    optimizer, lambda i: min(i / 100, 1.0)\n",
    "    # )\n",
    "\n",
    "    num_epochs = cfg.num_epochs\n",
    "\n",
    "    # setup wandb\n",
    "    wandb.init(\n",
    "        project=WandbConstants.PROJECT,\n",
    "        name=WandbConstants.NAME,\n",
    "        config=cfg.to_dict(),\n",
    "    )\n",
    "\n",
    "    print(f\"Run name {wandb.run.name} - {wandb.run.id}\")\n",
    "\n",
    "    # create a small (fixed) training set of each difficulty to use for visualization\n",
    "    test_example_per_difficulty = {}\n",
    "    for difficulty, test_loader in cfg.test_loaders.items():\n",
    "        # grab something from the test batch\n",
    "        x, _ = next(iter(test_loader))\n",
    "        input_tokens = x[0].to(device)\n",
    "        test_example_per_difficulty[difficulty] = input_tokens\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch, batch in tqdm.tqdm(\n",
    "        zip(\n",
    "            range(num_epochs),\n",
    "            itertools.cycle(train_loader),\n",
    "        )\n",
    "    ):\n",
    "\n",
    "        tokens, target = batch\n",
    "\n",
    "        tokens, target = tokens.to(device), target.to(device)\n",
    "\n",
    "        # ex: torch.Size([4, 9, 29])\n",
    "        logits: Float32[torch.Tensor, \"b t c\"] = model(tokens)\n",
    "\n",
    "        # print(f\"Logits:\\n{logits.shape}\")\n",
    "        loss = loss_fn(logits, target)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if cfg.max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # scheduler.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # more frequently than eval, print out train loss\n",
    "        # if (epoch % (cfg.eval_test_every_n // 10)) == 0:\n",
    "        #\n",
    "        #    print(f\"Epoch {epoch}, \" f\"Train loss: {loss.item():.6f}\")\n",
    "\n",
    "        # TODO(bschoen): Shouldn't you actually divide loss by batch size?\n",
    "        # TODO(bschoen): Do we want like an `is trial` (for example logging last one)\n",
    "        if (epoch % cfg.eval_test_every_n) == 0:\n",
    "\n",
    "            # skip evaluating test loss if we just started training\n",
    "            # if epoch == 0:\n",
    "            #    continue\n",
    "\n",
    "            print(\"Evaluating test loss...\")\n",
    "\n",
    "            # compute loss at each difficulty\n",
    "            test_loss_by_difficulty = {}\n",
    "            test_accuracy_by_difficulty = {}\n",
    "\n",
    "            for difficulty, test_loader in cfg.test_loaders.items():\n",
    "\n",
    "                test_loss = evaluate_loss_on_test_batches(\n",
    "                    model,\n",
    "                    test_loader,\n",
    "                    max_batches=100,\n",
    "                )\n",
    "\n",
    "                accuracy = evaluate_sequence_accuracy_on_test_batches(\n",
    "                    model,\n",
    "                    test_loader,\n",
    "                    separator_token_id=tokenizer.encode(\"|\")[0],\n",
    "                    max_batches=1,\n",
    "                )\n",
    "\n",
    "                test_loss_by_difficulty[difficulty] = test_loss\n",
    "                test_accuracy_by_difficulty[difficulty] = accuracy\n",
    "\n",
    "            wandb_log_dict = {\"epoch\": epoch, \"train_loss\": loss.item()}\n",
    "\n",
    "            for difficulty, test_loss in test_loss_by_difficulty.items():\n",
    "\n",
    "                wandb_log_dict[f\"test_loss_difficulty_{difficulty}\"] = test_loss\n",
    "\n",
    "            for difficulty, accuracy in test_accuracy_by_difficulty.items():\n",
    "\n",
    "                wandb_log_dict[f\"test_accuracy_difficulty_{difficulty}\"] = accuracy\n",
    "\n",
    "            # evaluate accuracy\n",
    "            print(\"Evaluating accuracy...\")\n",
    "\n",
    "            print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "            # print_json(wandb_log_dict)\n",
    "\n",
    "            # Log metrics\n",
    "            wandb.log(wandb_log_dict, step=epoch)\n",
    "\n",
    "            # Compute attention pattern visualization\n",
    "            print(\"Computing attention pattern visualization...\")\n",
    "            model.eval()\n",
    "            test_example_string_to_cache = {}\n",
    "\n",
    "            for difficulty, input_tokens in test_example_per_difficulty.items():\n",
    "\n",
    "                logits, cache = model.run_with_cache(input_tokens)\n",
    "\n",
    "                # store example by using the actual text string as key\n",
    "                input_tokens_str = \"\".join([tokenizer.decode([x.item()]) for x in input_tokens])\n",
    "\n",
    "                test_example_string_to_cache[input_tokens_str] = cache\n",
    "\n",
    "            image = generate_image_for_attention_patterns(\n",
    "                test_example_string_to_cache,\n",
    "                title=f\"Step: {epoch}\",\n",
    "            )\n",
    "\n",
    "            wandb.log(\n",
    "                {WandbConstants.ATTENTION_PATTERN_IMAGES: wandb.Image(image)},\n",
    "                step=epoch,\n",
    "            )\n",
    "\n",
    "            if cfg.wait_between_eval_s and cfg.wait_between_eval_s is not None:\n",
    "                print(f\"Sleeping for {cfg.wait_between_eval_s} to avoid wandb rate limiting\")\n",
    "                time.sleep(cfg.wait_between_eval_s)\n",
    "\n",
    "    # capture run name and id before `finish`\n",
    "    wandb_run_name = wandb.run.name\n",
    "    wandb_run_id = wandb.run.id\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    # log locally to sanity check\n",
    "    # px.line(losses, labels={\"x\": \"Epoch\", \"y\": \"Train Loss\"})\n",
    "\n",
    "    print(f\"Final train loss: {loss.item():.6f}\")\n",
    "\n",
    "    # take model out of train\n",
    "    model.eval()\n",
    "\n",
    "    return TrainModelResult(\n",
    "        model=model,\n",
    "        train_loss=loss.item(),\n",
    "        wandb_run_name=wandb_run_name,\n",
    "        wandb_run_id=wandb_run_id,\n",
    "    )\n",
    "\n",
    "\n",
    "# note: There's a floor to our loss here, which is the first N digits before `|`\n",
    "\n",
    "# TODO(bschoen): Generate attention pattern for heads that have to handle different arrangements\n",
    "#                in case it's more clear what they're doing\n",
    "#\n",
    "# TODO(bschoen): There's only a finite number of permutations, can just generate the flow for each\n",
    "\n",
    "# train brief run to test code\n",
    "training_config = ModelAndTrainingConfig(\n",
    "    num_epochs=10000,\n",
    "    eval_test_every_n=1000,\n",
    "    weight_decay=0.1,\n",
    "    wait_between_eval_s=None,\n",
    "    train_loader=train_loader,\n",
    "    test_loaders=test_loaders,\n",
    ")\n",
    "\n",
    "result = train_model(training_config)\n",
    "\n",
    "# for compatibility with code later\n",
    "model = result.model\n",
    "cfg = training_config.get_hooked_transformer_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb1d023",
   "metadata": {},
   "source": [
    "## Save Output Image To Gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37ad4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = download_images_from_run(result=result)\n",
    "\n",
    "gif_filepath = convert_pngs_in_directory_to_gif(output_dir=output_dir)\n",
    "\n",
    "print(gif_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2def906c",
   "metadata": {},
   "source": [
    "## Looking At Embedding For Sorted Order\n",
    "\n",
    "Actually assuming positional embedding these get different values anyway, was worth it to check that they aren't just learned in the embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b91203",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a16a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from jaxtyping import Float\n",
    "\n",
    "# Assuming 'model' is your HookedTransformer instance\n",
    "embeddings: Float[torch.Tensor, \"vocab_size d_model\"] = model.embed.W_E.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings: Float[torch.Tensor, \"vocab_size 2\"] = pca.fit_transform(embeddings)\n",
    "\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i, label in enumerate(vocab):\n",
    "    x, y = reduced_embeddings[i]\n",
    "    plt.scatter(x, y)\n",
    "    plt.text(x + 0.01, y + 0.01, label, fontsize=9)\n",
    "\n",
    "# Print the total variance explained\n",
    "\n",
    "# Calculate explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "total_variance_explained = sum(explained_variance_ratio)\n",
    "print(f\"Total variance explained by 2 principal components: {total_variance_explained:.2%}\")\n",
    "\n",
    "plt.title(\n",
    "    \"2D Visualization of Character Embeddings\"\n",
    "    f\"\\nTotal Variance Explained: {total_variance_explained:.2%}\"\n",
    ")\n",
    "plt.xlabel(f\"PC1 ({explained_variance_ratio[0]:.2%} variance explained)\")\n",
    "plt.ylabel(f\"PC2 ({explained_variance_ratio[1]:.2%} variance explained)\")\n",
    "plt.ylim(-1, 1)  # Set y-axis range to -1 to 1\n",
    "plt.xlim(-1, 1)  # Set x-axis range to -1 to 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d569a",
   "metadata": {},
   "source": [
    "### Examine Embedding Dimensions Individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from jaxtyping import Float\n",
    "\n",
    "embeddings: Float[torch.Tensor, \"vocab_size embedding_dim\"] = model.embed.W_E.detach().cpu().numpy()\n",
    "\n",
    "# Assuming 'embeddings' is of shape (vocab_size, embedding_dim)\n",
    "# Transpose embeddings to have dimensions on the rows and tokens on the columns\n",
    "embeddings_transposed = embeddings.T  # Shape: (embedding_dim, vocab_size)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(embeddings_transposed, aspect=\"auto\", cmap=\"RdBu_r\", interpolation=\"none\")\n",
    "\n",
    "plt.colorbar(label=\"Embedding Value\")\n",
    "plt.title(\"Embedding Heatmap\")\n",
    "plt.xlabel(\"Token\")\n",
    "plt.ylabel(\"Embedding Dimension\")\n",
    "\n",
    "# Set x-axis ticks to tokens\n",
    "plt.xticks(ticks=np.arange(len(vocab)), labels=vocab, rotation=\"vertical\", fontsize=8)\n",
    "# Set y-axis ticks to embedding dimensions\n",
    "embedding_dim = embeddings.shape[1]\n",
    "plt.yticks(ticks=np.arange(embedding_dim), labels=np.arange(embedding_dim))\n",
    "\n",
    "# Optionally, set color limits to be symmetric around zero\n",
    "plt.clim(-1, 1)  # Adjust based on the range of your embeddings\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a56df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "import rich.table\n",
    "import scipy.stats\n",
    "\n",
    "# A high positive or negative correlation in a dimension suggests that\n",
    "# the dimension encodes character order.\n",
    "\n",
    "char_indices = np.arange(len(vocab))\n",
    "\n",
    "# Create a rich table to display correlation coefficients and p-values\n",
    "table = rich.table.Table(\"Dimension\", \"Corr Coef\", \"p-value\")\n",
    "\n",
    "for dim in range(embedding_dim):\n",
    "\n",
    "    corr_coef, p_value = scipy.stats.pearsonr(embeddings[:, dim], char_indices)\n",
    "\n",
    "    table.add_row(f\"{dim}\", f\"{corr_coef:.3f}\", f\"{p_value:.3}\")\n",
    "\n",
    "rich.print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4e05a",
   "metadata": {},
   "source": [
    "### Compute Pairwise Distances Between Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19286c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "import seaborn as sns\n",
    "\n",
    "for metric in [\"euclidean\", \"cosine\"]:\n",
    "    # Compute the distance matrix\n",
    "    distance_matrix = squareform(pdist(embeddings, metric=metric))\n",
    "\n",
    "    # Zero out the upper triangular part of the matrix\n",
    "    # distance_matrix = np.tril(distance_matrix)  # Keep only lower triangular part\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(distance_matrix, xticklabels=vocab, yticklabels=vocab, cmap=\"RdBu\")\n",
    "    plt.title(f\"Pairwise {metric} Distances Between Embeddings (Lower Triangle)\")\n",
    "    plt.xlabel(\"Character\")\n",
    "    plt.ylabel(\"Character\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad8226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "511d3636",
   "metadata": {},
   "source": [
    "### Visualize Embeddings Using Nonlinear Dimensionality Reduction\n",
    "\n",
    "ex: Sequential Arrangement: Characters may arrange in a curve or line reflecting their order.\n",
    "\n",
    "This is just PCA in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa9a1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Calculate the number of samples\n",
    "n_samples = embeddings.shape[0]\n",
    "\n",
    "# Set perplexity to be less than n_samples (e.g., half of n_samples or 30, whichever is smaller)\n",
    "perplexity = min(30, n_samples // 2)\n",
    "\n",
    "tsne_embeddings = TSNE(n_components=2, random_state=42, perplexity=perplexity).fit_transform(\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(tsne_embeddings[:, 0], tsne_embeddings[:, 1])\n",
    "\n",
    "for i, label in enumerate(vocab):\n",
    "    x, y = tsne_embeddings[i]\n",
    "    plt.text(x + 0.01, y + 0.01, label, fontsize=9)\n",
    "\n",
    "plt.title(\"t-SNE Visualization of Token Embeddings\")\n",
    "plt.xlabel(\"Component 1\")\n",
    "plt.ylabel(\"Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc394f",
   "metadata": {},
   "source": [
    "### Analyze Principal Components in Detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3372ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=embedding_dim)\n",
    "pca_embeddings = pca.fit_transform(embeddings)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# plot the explained variance for each principal component\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(range(1, embedding_dim + 1), explained_variance * 100)\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Explained Variance (%)\")\n",
    "plt.title(\"PCA Explained Variance\")\n",
    "plt.show()\n",
    "\n",
    "# plot irst few principal components\n",
    "for i in range(5):\n",
    "\n",
    "    corr_coef, p_value = scipy.stats.pearsonr(pca_embeddings[:, i], char_indices)\n",
    "    print(\n",
    "        f\"{i}-th Principal Component vs Character Index: \"\n",
    "        f\"Correlation Coefficient = {corr_coef:.3f}, p-value = {p_value:.3}\"\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(char_indices, pca_embeddings[:, i], marker=\"o\")\n",
    "    plt.title(f\"{i}-th Principal Component of Embeddings\")\n",
    "    plt.xlabel(\"Character Index\")\n",
    "    plt.ylabel(f\"PCA Component {i}\")\n",
    "    plt.xticks(char_indices, vocab)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca327de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04155a2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e8b42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "368b70a9",
   "metadata": {},
   "source": [
    "## Indirect Object Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07efb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import circuitsvis as cv\n",
    "\n",
    "\n",
    "def add_batch_dimension(x: Float32[torch.Tensor, \"...\"]) -> Float32[torch.Tensor, \"batch ...\"]:\n",
    "    return einops.rearrange(x, \"... -> 1 ...\")\n",
    "\n",
    "\n",
    "def tokenize_string(input_string: str) -> Float32[torch.Tensor, \"seq\"]:\n",
    "\n",
    "    tokens = tokenizer.encode(input_string)\n",
    "\n",
    "    return torch.tensor(tokens, dtype=torch.long).to(device)\n",
    "\n",
    "\n",
    "def tokenize_string_as_batch(input_string: str) -> Float32[torch.Tensor, \"batch seq\"]:\n",
    "\n",
    "    return add_batch_dimension(tokenize_string(input_string))\n",
    "\n",
    "\n",
    "def get_first_mismatched_pair(\n",
    "    tokens_a: Float32[torch.Tensor, \"batch=1 seq\"],\n",
    "    tokens_b: Float32[torch.Tensor, \"batch=1 seq\"],\n",
    ") -> Float32[torch.Tensor, \"batch=1 2\"]:\n",
    "\n",
    "    assert tokens_a.shape == tokens_b.shape\n",
    "\n",
    "    for index in range(tokens_a.shape[-1]):\n",
    "\n",
    "        if tokens_a[0, index] != tokens_b[0, index]:\n",
    "\n",
    "            mismatch: Float32[torch.Tensor, \"2\"] = torch.tensor(\n",
    "                [\n",
    "                    tokens_a[0, index],\n",
    "                    tokens_b[0, index],\n",
    "                ]\n",
    "            ).to(device)\n",
    "\n",
    "            return add_batch_dimension(mismatch)\n",
    "\n",
    "\n",
    "# create a custom to_string function since using our own tokenizer\n",
    "def token_to_string(token: int) -> str:\n",
    "    return tokenizer.decode([token])\n",
    "\n",
    "\n",
    "# TODO(bschoen): Vary along things besides reversal\n",
    "\n",
    "# take an example, modify the first part of the sequence reversal to be wrong\n",
    "input_string = \"<bacd|ab\"\n",
    "correct_string = f\"{input_string}c\"\n",
    "incorrect_string = f\"{input_string}d\"\n",
    "\n",
    "input_string_tokens = tokenize_string_as_batch(input_string)\n",
    "correct_string_tokens = tokenize_string_as_batch(correct_string)\n",
    "incorrect_string_tokens = tokenize_string_as_batch(incorrect_string)\n",
    "\n",
    "logits, cache = model.run_with_cache(input_string_tokens)\n",
    "correct_logits, correct_cache = model.run_with_cache(correct_string_tokens)\n",
    "incorrect_logits, incorrect_cache = model.run_with_cache(incorrect_string_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89497e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    cv.logits.token_log_probs(\n",
    "        token_indices=correct_string_tokens,\n",
    "        log_probs=correct_logits.log_softmax(dim=-1),\n",
    "        to_string=token_to_string,\n",
    "    )\n",
    ")\n",
    "\n",
    "display(\n",
    "    cv.logits.token_log_probs(\n",
    "        token_indices=incorrect_string_tokens,\n",
    "        log_probs=incorrect_logits.log_softmax(dim=-1),\n",
    "        to_string=token_to_string,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a02553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# position where we changed the sequence\n",
    "if False:\n",
    "    mismatch_position_index = 4\n",
    "\n",
    "    correct_token = correct_string_tokens[0, mismatch_position_index].item()\n",
    "    incorrect_token = incorrect_string_tokens[0, mismatch_position_index].item()\n",
    "\n",
    "    print(f\"correct_token: {correct_token} ({tokenizer.decode([correct_token])})\")\n",
    "    print(f\"incorrect_token: {incorrect_token} ({tokenizer.decode([incorrect_token])})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8153f90",
   "metadata": {},
   "source": [
    "### Logit Difference In Accumulated Residual Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66789ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get diff in format expected by `model.tokens_to_residual_directions`\n",
    "answer_tokens = get_first_mismatched_pair(\n",
    "    correct_string_tokens,\n",
    "    incorrect_string_tokens,\n",
    ")\n",
    "\n",
    "print(f\"{answer_tokens.shape=}\")\n",
    "\n",
    "# Float32[torch.Tensor, \"batch 2 d_model\"]\n",
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens)\n",
    "\n",
    "print(\"Answer residual directions shape:\", answer_residual_directions.shape)\n",
    "\n",
    "# Float32[torch.Tensor, \"batch d_model\"]\n",
    "# Float32[torch.Tensor, \"batch d_model\"]\n",
    "correct_residual_directions, incorrect_residual_directions = answer_residual_directions.unbind(\n",
    "    dim=1\n",
    ")\n",
    "\n",
    "# Float32[torch.Tensor, \"batch d_model\"]\n",
    "logit_diff_directions = correct_residual_directions - incorrect_residual_directions\n",
    "\n",
    "print(f\"Logit difference directions shape:\", logit_diff_directions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f609ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch import transformer_lens_utils\n",
    "\n",
    "import transformer_lens.patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf3365d",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_per_prompt_diff = transformer_lens_utils.logits_to_ave_logit_diff(\n",
    "    logits,\n",
    "    answer_tokens,\n",
    "    per_prompt=True,\n",
    ")\n",
    "print(\"Per prompt logit difference:\", original_per_prompt_diff)\n",
    "\n",
    "original_average_logit_diff = transformer_lens_utils.logits_to_ave_logit_diff(\n",
    "    logits,\n",
    "    answer_tokens,\n",
    ")\n",
    "print(\"Average logit difference:\", original_average_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7032a402",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in cache.items():\n",
    "    print(f\"{k} {v.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# approximate layernorms as constants when propagating feature vectors backward\n",
    "# for theoretical motivation, see the LayerNorm section of\n",
    "# \thttps://www.neelnanda.io/mechanistic-interpretability/attribution-patching\n",
    "@torch.no_grad()\n",
    "def get_ln_constant(model, cache, vector, layer, token, is_ln2=False, recip=False):\n",
    "    x_act_name = (\n",
    "        transformer_lens.utils.get_act_name(\"resid_mid\", layer)\n",
    "        if is_ln2\n",
    "        else transformer_lens.utils.get_act_name(\"resid_pre\", layer)\n",
    "    )\n",
    "    x = cache[x_act_name][0, token]\n",
    "\n",
    "    y_act_name = get_act_name(\"normalized\", layer, \"ln2\" if is_ln2 else \"ln1\")\n",
    "    y = cache[y_act_name][0, token]\n",
    "\n",
    "    if torch.dot(vector, x) == 0:\n",
    "        return torch.tensor(0.0)\n",
    "    return (\n",
    "        torch.dot(vector, y) / torch.dot(vector, x)\n",
    "        if not recip\n",
    "        else torch.dot(vector, x) / torch.dot(vector, y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack_to_logit_diff(\n",
    "    residual_stack: Float32[torch.Tensor, \"... batch d_model\"],\n",
    "    cache: transformer_lens.ActivationCache,\n",
    "    logit_diff_directions: Float[torch.Tensor, \"batch d_model\"],\n",
    ") -> Float32[torch.Tensor, \"...\"]:\n",
    "    \"\"\"\n",
    "    Gets the avg logit difference between the correct and incorrect answer for a given\n",
    "    stack of components in the residual stream.\n",
    "    \"\"\"\n",
    "    # SOLUTION\n",
    "    batch_size = residual_stack.size(-2)\n",
    "    \"\"\"scaled_residual_stack = cache.apply_ln_to_stack(\n",
    "        residual_stack,\n",
    "        layer=-1,\n",
    "        pos_slice=-1,\n",
    "    )\"\"\"\n",
    "    return (\n",
    "        einops.einsum(\n",
    "            residual_stack,\n",
    "            logit_diff_directions,\n",
    "            \"... batch d_model, batch d_model -> ...\",\n",
    "        )\n",
    "        / batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44018d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we expected residual stream patching near the final layer to work near perfectly,\n",
    "# since it was logit focused and thus basically linear, but turns out that\n",
    "# LayerNorm completely breaks things.\n",
    "\n",
    "# note: the fact that we had to use `ln_final.hook_normalized` instead of `resid_post`\n",
    "#       means that center_writing_weights is needed\n",
    "\n",
    "final_residual_stream = cache[\"resid_post\", -1]  # [batch seq d_model]\n",
    "# final_residual_stream = cache[\"ln_final.hook_normalized\"]  # [batch seq d_model]\n",
    "print(f\"Final residual stream shape: {final_residual_stream.shape}\")\n",
    "final_token_residual_stream = final_residual_stream[:, -1, :]  # [batch d_model]\n",
    "\n",
    "# Apply LayerNorm scaling (to just the final sequence position)\n",
    "# pos_slice is the subset of the positions we take - here the final token of each prompt\n",
    "# scaled_final_token_residual_stream = cache.apply_ln_to_stack(\n",
    "#     final_token_residual_stream,\n",
    "#     layer=-1,\n",
    "#     pos_slice=-1,\n",
    "# )\n",
    "scaled_final_token_residual_stream = final_token_residual_stream\n",
    "\n",
    "batch_size = input_string_tokens.shape[0]\n",
    "\n",
    "average_logit_diff = (\n",
    "    einops.einsum(\n",
    "        scaled_final_token_residual_stream,\n",
    "        logit_diff_directions,\n",
    "        \"batch d_model, batch d_model ->\",\n",
    "    )\n",
    "    / batch_size\n",
    ")\n",
    "\n",
    "print(\"Note: These should be close!\")\n",
    "print(f\"Calculated average logit diff: {average_logit_diff:.10f}\")\n",
    "print(f\"Original logit difference:     {original_average_logit_diff:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd8acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = residual_stack_to_logit_diff(\n",
    "    final_token_residual_stream,\n",
    "    cache,\n",
    "    logit_diff_directions,\n",
    ")\n",
    "\n",
    "print(\"Note: These should be close!\")\n",
    "print(f\"Calculated average logit diff: {result:.10f}\")\n",
    "print(f\"Original logit difference:     {original_average_logit_diff:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ba3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "accum_resid, labels = cache.accumulated_resid(return_labels=True, apply_ln=True)\n",
    "last_token_accum = accum_resid[:, 0, -1, :]  # layer, batch, pos, d_model\n",
    "print(f\"{last_token_accum.shape=}\")  # layer, batch, d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89edabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "print(f\"{W_U.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_unembedded = einops.einsum(\n",
    "    last_token_accum,\n",
    "    W_U,\n",
    "    \"layer d_model, d_model d_vocab -> layer d_vocab\",\n",
    ")\n",
    "\n",
    "print(f\"{layers_unembedded.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bebb1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens_logit_diffs: Float32[torch.Tensor, \"...\"] = residual_stack_to_logit_diff(\n",
    "    accum_resid,\n",
    "    cache,\n",
    "    logit_diff_directions,\n",
    ")  # [component]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.cfg)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a21fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc02eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch import plotly_utils\n",
    "\n",
    "\n",
    "accumulated_residual, labels = cache.accumulated_resid(\n",
    "    layer=-1,\n",
    "    incl_mid=True,\n",
    "    pos_slice=-1,\n",
    "    return_labels=True,\n",
    ")\n",
    "# accumulated_residual has shape (component, batch, d_model)\n",
    "\n",
    "logit_lens_logit_diffs: Float32[torch.Tensor, \"...\"] = residual_stack_to_logit_diff(\n",
    "    accumulated_residual,\n",
    "    cache,\n",
    "    logit_diff_directions,\n",
    ")  # [component]\n",
    "\n",
    "plotly_utils.line(\n",
    "    logit_lens_logit_diffs,\n",
    "    hovermode=\"x unified\",\n",
    "    title=\"Logit Difference From Accumulated Residual Stream\",\n",
    "    labels={\"x\": \"Layer\", \"y\": \"Logit Diff\"},\n",
    "    xaxis_tickvals=labels,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d73f1e",
   "metadata": {},
   "source": [
    "### Logit Difference From Each Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f3ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_layer_residual, labels = cache.decompose_resid(\n",
    "    layer=-1,\n",
    "    pos_slice=-1,\n",
    "    return_labels=True,\n",
    ")\n",
    "per_layer_logit_diffs = residual_stack_to_logit_diff(\n",
    "    per_layer_residual,\n",
    "    cache,\n",
    "    logit_diff_directions,\n",
    ")\n",
    "\n",
    "plotly_utils.line(\n",
    "    per_layer_logit_diffs,\n",
    "    hovermode=\"x unified\",\n",
    "    title=\"Logit Difference From Each Layer\",\n",
    "    labels={\"x\": \"Layer\", \"y\": \"Logit Diff\"},\n",
    "    xaxis_tickvals=labels,\n",
    "    width=800,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2515dba",
   "metadata": {},
   "source": [
    "### Logit Difference From Each Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c53ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(layer=-1, pos_slice=-1, return_labels=True)\n",
    "per_head_residual = einops.rearrange(\n",
    "    per_head_residual,\n",
    "    \"(layer head) ... -> layer head ...\",\n",
    "    layer=model.cfg.n_layers,\n",
    ")\n",
    "per_head_logit_diffs = residual_stack_to_logit_diff(\n",
    "    per_head_residual,\n",
    "    cache,\n",
    "    logit_diff_directions,\n",
    ")\n",
    "\n",
    "plotly_utils.imshow(\n",
    "    per_head_logit_diffs,\n",
    "    labels={\"x\": \"Head\", \"y\": \"Layer\"},\n",
    "    title=\"Logit Difference From Each Head\",\n",
    "    width=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9eec6d",
   "metadata": {},
   "source": [
    "### Highest Value Attention Heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c42392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.core.display\n",
    "import IPython.display\n",
    "\n",
    "\n",
    "def topk_of_Nd_tensor(\n",
    "    tensor: Float[torch.Tensor, \"rows cols\"],\n",
    "    k: int,\n",
    ") -> list[tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Helper function: does same as tensor.topk(k).indices, but works over 2D tensors.\n",
    "    Returns a list of indices, i.e. shape [k, tensor.ndim].\n",
    "\n",
    "    Example: if tensor is 2D array of values for each head in each layer, this will\n",
    "    return a list of heads.\n",
    "    \"\"\"\n",
    "    i = torch.topk(tensor.flatten(), k).indices\n",
    "    return np.array(\n",
    "        np.unravel_index(\n",
    "            transformer_lens.utils.to_numpy(i),\n",
    "            tensor.shape,\n",
    "        )\n",
    "    ).T.tolist()\n",
    "\n",
    "\n",
    "k = 3\n",
    "\n",
    "for head_type in [\"Positive\", \"Negative\"]:\n",
    "\n",
    "    # Get the heads with largest (or smallest) contribution to the logit difference\n",
    "    top_heads = topk_of_Nd_tensor(\n",
    "        per_head_logit_diffs.cpu() * (1 if head_type == \"Positive\" else -1), k\n",
    "    )\n",
    "\n",
    "    # ex: [[0, 1], [1, 0], [0, 0]]\n",
    "    print(top_heads)\n",
    "\n",
    "    # Get all their attention patterns\n",
    "    attn_patterns_for_important_heads: Float[torch.Tensor, \"head q k\"] = torch.stack(\n",
    "        [cache[\"pattern\", layer][:, head][0] for layer, head in top_heads]\n",
    "    )\n",
    "\n",
    "    print(f\"{attn_patterns_for_important_heads.shape=}\")\n",
    "\n",
    "    # Display results\n",
    "    display(\n",
    "        cv.attention.attention_heads(\n",
    "            attention=attn_patterns_for_important_heads,\n",
    "            tokens=[x for x in input_string],\n",
    "            attention_head_names=[f\"{layer}.{head}\" for layer, head in top_heads],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de5552",
   "metadata": {},
   "source": [
    "### Activation Patching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170dd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch import transformer_lens_utils\n",
    "\n",
    "# TODO(bschoen): Clean and corrupted should actually switch first, should do this for search\n",
    "clean_logit_diff = transformer_lens_utils.logits_to_ave_logit_diff(\n",
    "    correct_logits,\n",
    "    answer_tokens,\n",
    ")\n",
    "print(f\"Clean logit diff: {clean_logit_diff:.4f}\")\n",
    "\n",
    "corrupted_logit_diff = transformer_lens_utils.logits_to_ave_logit_diff(\n",
    "    incorrect_logits,\n",
    "    answer_tokens,\n",
    ")\n",
    "print(f\"Corrupted logit diff: {corrupted_logit_diff:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebf797",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.attention.attention_heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a63158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ioi_metric(\n",
    "    logits: Float[torch.Tensor, \"batch seq d_vocab\"],\n",
    "    answer_tokens: Float[torch.Tensor, \"batch 2\"] = answer_tokens,\n",
    "    corrupted_logit_diff: float = corrupted_logit_diff,\n",
    "    clean_logit_diff: float = clean_logit_diff,\n",
    ") -> Float[torch.Tensor, \"\"]:\n",
    "    \"\"\"\n",
    "    Linear function of logit diff, calibrated so that it equals 0 when performance is\n",
    "    same as on corrupted input, and 1 when performance is same as on clean input.\n",
    "    \"\"\"\n",
    "    # SOLUTION\n",
    "    patched_logit_diff = transformer_lens_utils.logits_to_ave_logit_diff(logits, answer_tokens)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f76f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_patch_resid_pre = transformer_lens.patching.get_act_patch_resid_pre(\n",
    "    model=model,\n",
    "    corrupted_tokens=incorrect_string_tokens,\n",
    "    clean_cache=correct_cache,\n",
    "    patching_metric=ioi_metric,\n",
    ")\n",
    "\n",
    "labels = [f\"{tok} {i}\" for i, tok in enumerate(correct_string)]\n",
    "\n",
    "imshow(\n",
    "    act_patch_resid_pre,\n",
    "    labels={\"x\": \"Position\", \"y\": \"Layer\"},\n",
    "    x=labels,\n",
    "    title=\"resid_pre Activation Patching\",\n",
    "    width=600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c26324",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_patch_block_every = transformer_lens.patching.get_act_patch_block_every(\n",
    "    model,\n",
    "    incorrect_string_tokens,\n",
    "    correct_cache,\n",
    "    ioi_metric,\n",
    ")\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=3, cols=1, subplot_titles=[\"Residual Stream\", \"Attn Output\", \"MLP Output\"])\n",
    "\n",
    "# Add heatmaps for each component\n",
    "for i in range(3):\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=act_patch_block_every[i].cpu().numpy(),\n",
    "            x=labels,\n",
    "            colorscale=\"RdBu\",\n",
    "            zmid=0,\n",
    "            zmin=-1,\n",
    "            zmax=1,\n",
    "        ),\n",
    "        row=i + 1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Logit Difference From Patched Components\",\n",
    "    height=800,\n",
    "    width=1000,\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "for i in range(3):\n",
    "    fig.update_xaxes(title_text=\"Sequence Position\", row=i + 1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Layer\", row=i + 1, col=1)\n",
    "\n",
    "# Update colorbar\n",
    "fig.update_layout(coloraxis_colorbar=dict(title=\"Logit Difference\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e64364",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_patch_attn_head_out_all_pos = transformer_lens.patching.get_act_patch_attn_head_out_all_pos(\n",
    "    model,\n",
    "    incorrect_string_tokens,\n",
    "    correct_cache,\n",
    "    ioi_metric,\n",
    ")\n",
    "# Create a figure using plotly.graph_objects\n",
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=act_patch_attn_head_out_all_pos.cpu().numpy(),\n",
    "        colorscale=\"RdBu\",\n",
    "        zmid=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update the layout\n",
    "fig.update_layout(\n",
    "    title=\"attn_head_out Activation Patching (All Pos)\",\n",
    "    xaxis_title=\"Head\",\n",
    "    yaxis_title=\"Layer\",\n",
    "    width=600,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022f27a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_lens.patching.get_act_patch_mlp_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3339a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def visualize_act_patch_attn_head_by_pos_every(\n",
    "    act_patch_attn_head_by_pos_every: torch.Tensor,\n",
    "    patch_types: list = None,\n",
    "    layer_labels: list = None,\n",
    "    head_labels: list = None,\n",
    "    figsize: tuple = (15, 10),\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize the activation patch attention head by position tensor.\n",
    "\n",
    "    Args:\n",
    "        act_patch_attn_head_by_pos_every (torch.Tensor): Tensor of shape [patch_type, layer, pos, head]\n",
    "        patch_types (list of str, optional): List of patch type names.\n",
    "            Defaults to ['Output', 'Query', 'Key', 'Value', 'Pattern'].\n",
    "        layer_labels (list of str, optional): List of layer names.\n",
    "            If None, defaults to ['Layer 1', 'Layer 2', ...].\n",
    "        head_labels (list of str, optional): List of head names.\n",
    "            If None, defaults to ['Head 1', 'Head 2', ...].\n",
    "        figsize (tuple, optional): Size of the figure. Defaults to (15, 10).\n",
    "    \"\"\"\n",
    "    # Ensure the tensor is on CPU and convert to NumPy\n",
    "    data = act_patch_attn_head_by_pos_every.detach().cpu().numpy()\n",
    "\n",
    "    num_patch_types, num_layers, num_positions, num_heads = data.shape\n",
    "\n",
    "    # Set default patch types if not provided\n",
    "    if patch_types is None:\n",
    "        if num_patch_types == 5:\n",
    "            patch_types = [\"Output\", \"Query\", \"Key\", \"Value\", \"Pattern\"]\n",
    "        else:\n",
    "            patch_types = [f\"Type {i+1}\" for i in range(num_patch_types)]\n",
    "    else:\n",
    "        assert (\n",
    "            len(patch_types) == num_patch_types\n",
    "        ), f\"Expected {num_patch_types} patch types, but got {len(patch_types)}.\"\n",
    "\n",
    "    # Set default layer labels if not provided\n",
    "    if layer_labels is None:\n",
    "        layer_labels = [f\"Layer {i+1}\" for i in range(num_layers)]\n",
    "    else:\n",
    "        assert (\n",
    "            len(layer_labels) == num_layers\n",
    "        ), f\"Expected {num_layers} layers, but got {len(layer_labels)}.\"\n",
    "\n",
    "    # Set default head labels if not provided\n",
    "    if head_labels is None:\n",
    "        head_labels = [f\"Head {i+1}\" for i in range(num_heads)]\n",
    "    else:\n",
    "        assert (\n",
    "            len(head_labels) == num_heads\n",
    "        ), f\"Expected {num_heads} heads, but got {len(head_labels)}.\"\n",
    "\n",
    "    # Aggregate data over positions (e.g., by averaging)\n",
    "    data_avg = data.mean(axis=2)  # Shape: [patch_type, layer, head]\n",
    "\n",
    "    # Determine subplot grid size\n",
    "    n_cols = 2  # You can adjust this based on the number of patch types\n",
    "    n_rows = int(np.ceil(num_patch_types / n_cols))\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize, constrained_layout=True)\n",
    "\n",
    "    # Flatten axes for easy iteration\n",
    "    if n_rows > 1 or n_cols > 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = [axes]\n",
    "\n",
    "    for idx in range(num_patch_types):\n",
    "        ax = axes[idx]\n",
    "        sns.heatmap(\n",
    "            data_avg[idx],\n",
    "            annot=True,\n",
    "            fmt=\".2f\",\n",
    "            xticklabels=head_labels,\n",
    "            yticklabels=layer_labels,\n",
    "            cmap=\"viridis\",\n",
    "            ax=ax,\n",
    "        )\n",
    "        ax.set_title(f\"Patch Type: {patch_types[idx]}\")\n",
    "        ax.set_xlabel(\"Head\")\n",
    "        ax.set_ylabel(\"Layer\")\n",
    "\n",
    "    # Remove any unused subplots\n",
    "    for idx in range(num_patch_types, len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "\n",
    "    plt.suptitle(\"Activation Patch Attention by Head and Layer\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch import plotly_utils\n",
    "\n",
    "act_patch_attn_head_by_pos_every = transformer_lens.patching.get_act_patch_attn_head_by_pos_every(\n",
    "    model,\n",
    "    incorrect_string_tokens,\n",
    "    correct_cache,\n",
    "    ioi_metric,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd83e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom labels (optional)\n",
    "# Since we have 5 patch types, we'll default to ['Output', 'Query', 'Key', 'Value', 'Pattern']\n",
    "# If your tensor's first dimension is not 5, provide your own list\n",
    "patch_types = [\"Output\", \"Query\", \"Key\", \"Value\", \"Pattern\"]\n",
    "\n",
    "# Define layer and head labels based on your model's specifics\n",
    "layer_labels = [\"Layer 1\", \"Layer 2\"]  # Adjust based on num_layers\n",
    "head_labels = [\"Head 1\", \"Head 2\"]  # Adjust based on num_heads\n",
    "\n",
    "# Visualize\n",
    "visualize_act_patch_attn_head_by_pos_every(\n",
    "    act_patch_attn_head_by_pos_every,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4000f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{act_patch_attn_head_by_pos_every.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef794ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get activation patching results for the output of each MLP layer (by position). Returns a tensor of shape [n_layers, pos]\n",
    "act_patch_mlp_out = transformer_lens.patching.get_act_patch_mlp_out(\n",
    "    model,\n",
    "    incorrect_string_tokens,\n",
    "    correct_cache,\n",
    "    ioi_metric,\n",
    ")\n",
    "\n",
    "# act_patch_mlp_out.shape=torch.Size([2, 7])\n",
    "print(f\"{act_patch_mlp_out.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbdba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming act_patch_mlp_out is the tensor obtained from your previous code\n",
    "# For demonstration, here's a dummy tensor (remove this line in your actual code)\n",
    "# act_patch_mlp_out = torch.rand(2, 7)\n",
    "\n",
    "# Ensure the tensor is detached from the computation graph and moved to CPU\n",
    "act_patch_mlp_out = act_patch_mlp_out.detach().cpu()\n",
    "\n",
    "n_layers, n_positions = act_patch_mlp_out.shape\n",
    "\n",
    "# Create a line plot for each layer\n",
    "positions = np.arange(n_positions)\n",
    "plt.figure(figsize=(10, 6))\n",
    "for layer in range(n_layers):\n",
    "    plt.plot(positions, act_patch_mlp_out[layer], marker=\"o\", label=f\"Layer {layer}\")\n",
    "plt.xlabel(\"Position in Sequence\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.title(\"Activation Patching MLP Output per Layer and Position\")\n",
    "plt.xticks(positions)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Create a heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(act_patch_mlp_out, aspect=\"auto\", cmap=\"RdBu\", vmin=-1, vmax=1)\n",
    "\n",
    "# Set ticks and labels\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels([f\"Pos {i}\" for i in positions])\n",
    "ax.set_yticks(np.arange(n_layers))\n",
    "ax.set_yticklabels([f\"Layer {i}\" for i in range(n_layers)])\n",
    "\n",
    "# Add color bar\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "cbar.ax.set_ylabel(\"Metric Value\", rotation=-90, va=\"bottom\")\n",
    "\n",
    "ax.set_title(\"Activation Patching MLP Output Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae182f9",
   "metadata": {},
   "source": [
    "## Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4780ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we'll look for some expected features with linear probes\n",
    "\n",
    "# ex: first character in sorted order\n",
    "# ex: position 1 bigger than position 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28590652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to look at each part along the residual stream\n",
    "residual_stream_hook_names = [c for c in cache if \"resid\" in c]\n",
    "\n",
    "print(residual_stream_hook_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold activations and targets for each residual stream hook\n",
    "activations_dict = {hook_name: [] for hook_name in residual_stream_hook_names}\n",
    "\n",
    "# keep track of corresponding inputs (because shuffling)\n",
    "inputs_per_activation_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for batch_index, batch in tqdm.tqdm(enumerate(train_loader)):\n",
    "\n",
    "    tokens, target = batch\n",
    "\n",
    "    tokens, target = tokens.to(device), target.to(device)\n",
    "\n",
    "    # ex: torch.Size([4, 9, 29])\n",
    "    _, cache = model.run_with_cache(tokens)\n",
    "\n",
    "    # store the residual stream at each hook point\n",
    "    for hook_name in residual_stream_hook_names:\n",
    "        hook_value = cache[hook_name].detach().cpu()\n",
    "        activations_dict[hook_name].append(hook_value)\n",
    "\n",
    "    # store inputs\n",
    "    inputs_per_activation_list.append(tokens.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0ad8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the lists into single tensor\n",
    "activations_per_residual_stream_hook = {k: torch.stack(v) for k, v in activations_dict.items()}\n",
    "\n",
    "inputs_per_activation = torch.stack(inputs_per_activation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold the `num_batches` into the `batch` dimension\n",
    "activations_per_residual_stream_hook = {\n",
    "    k: einops.rearrange(v, \"batch_size batch seq d_model -> (batch_size batch) seq d_model\")\n",
    "    for k, v in activations_per_residual_stream_hook.items()\n",
    "}\n",
    "\n",
    "inputs_per_activation = einops.rearrange(\n",
    "    inputs_per_activation,\n",
    "    \"batch_size batch seq -> (batch_size batch) seq\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992cf9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hook_name in residual_stream_hook_names:\n",
    "    activations = activations_per_residual_stream_hook[hook_name]\n",
    "    print(f\"{hook_name} - {activations.shape=}\")\n",
    "\n",
    "print(f\"{inputs_per_activation.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fed70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Char = str\n",
    "TokenInt = int\n",
    "\n",
    "\n",
    "def get_sorted_char_label_at_seq_pos(\n",
    "    inputs: Int64[torch.Tensor, \"seq\"],\n",
    "    char_sequence_position: int,\n",
    ") -> Char:\n",
    "\n",
    "    tokens_as_string = tokenizer.decode(inputs.tolist())\n",
    "\n",
    "    # <abdc|abcd> -> <abdc -> abdc -> abcd\n",
    "    sorted_tokens_as_string = sorted(tokens_as_string.split(\"|\")[0][1:])\n",
    "\n",
    "    return sorted_tokens_as_string[char_sequence_position]\n",
    "\n",
    "\n",
    "def get_sorted_token_at_seq_pos(\n",
    "    inputs: Int64[torch.Tensor, \"seq\"],\n",
    "    char_sequence_position: int,\n",
    ") -> TokenInt:\n",
    "    token_char = get_sorted_char_label_at_seq_pos(inputs, char_sequence_position)\n",
    "    return torch.tensor(tokenizer.encode(token_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7474ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_as_string = \"<adcb|abcd>\"\n",
    "tokens_as_ints = torch.tensor(tokenizer.encode(tokens_as_string))\n",
    "\n",
    "assert get_sorted_char_label_at_seq_pos(tokens_as_ints, 0) == \"a\"\n",
    "assert get_sorted_char_label_at_seq_pos(tokens_as_ints, 1) == \"b\"\n",
    "assert get_sorted_char_label_at_seq_pos(tokens_as_ints, 2) == \"c\"\n",
    "assert get_sorted_char_label_at_seq_pos(tokens_as_ints, 3) == \"d\"\n",
    "\n",
    "\n",
    "assert tokenizer.decode(get_sorted_token_at_seq_pos(tokens_as_ints, 0).tolist()) == \"a\"\n",
    "assert tokenizer.decode(get_sorted_token_at_seq_pos(tokens_as_ints, 1).tolist()) == \"b\"\n",
    "assert tokenizer.decode(get_sorted_token_at_seq_pos(tokens_as_ints, 2).tolist()) == \"c\"\n",
    "assert tokenizer.decode(get_sorted_token_at_seq_pos(tokens_as_ints, 3).tolist()) == \"d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a12a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728eddab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd45e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "from jaxtyping import Int, jaxtyped\n",
    "from typeguard import typechecked as typechecker\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class LinearProbeDataset:\n",
    "    activations: Float[torch.Tensor, \"batch d_model\"]\n",
    "    labels: Float[torch.Tensor, \"batch\"]\n",
    "\n",
    "\n",
    "@jaxtyped(typechecker=typechecker)\n",
    "def prepare_dataset(\n",
    "    activations: dict[str, Float[torch.Tensor, \"batch seq d_model\"]],\n",
    "    inputs: Int64[torch.Tensor, \"batch seq\"],\n",
    "    hook_name: str,\n",
    "    position: int,\n",
    "    char_sequence_position: int = 0,\n",
    ") -> LinearProbeDataset:\n",
    "\n",
    "    labels_list = []\n",
    "\n",
    "    for batch_index in range(inputs.shape[0]):\n",
    "\n",
    "        tokens: Int64[torch.Tensor, \"seq\"] = inputs[batch_index]\n",
    "\n",
    "        label = get_sorted_token_at_seq_pos(\n",
    "            tokens,\n",
    "            char_sequence_position,\n",
    "        )\n",
    "\n",
    "        labels_list.append(label)\n",
    "\n",
    "    labels: Int[torch.Tensor, \"batch\"] = torch.stack(labels_list)\n",
    "\n",
    "    activations_for_hook: Float[torch.Tensor, \"batch seq d_model\"] = activations[hook_name]\n",
    "\n",
    "    # slice at position\n",
    "    activations_for_hook_at_position: Float[torch.Tensor, \"batch d_model\"] = activations_for_hook[\n",
    "        :, position, :\n",
    "    ]\n",
    "    return LinearProbeDataset(activations_for_hook_at_position, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceed47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded to iterate over all char_sequence_positions\n",
    "\n",
    "HookName = str\n",
    "SeqPosition = int\n",
    "CharSeqPosition = int\n",
    "\n",
    "linear_probe_dataset_per_position_per_hook_name: dict[\n",
    "    HookName, dict[SeqPosition, dict[CharSeqPosition, LinearProbeDataset]]\n",
    "] = {}\n",
    "\n",
    "for hook_name in tqdm.tqdm(activations_per_residual_stream_hook.keys()):\n",
    "    linear_probe_dataset_per_position_per_hook_name[hook_name] = {}\n",
    "\n",
    "    for position_index in range(inputs_per_activation.shape[-1]):\n",
    "        linear_probe_dataset_per_position_per_hook_name[hook_name][position_index] = {}\n",
    "\n",
    "        for char_sequence_position in range(4):  # Assuming 4 char_sequence_positions\n",
    "            linear_probe_dataset = prepare_dataset(\n",
    "                activations=activations_per_residual_stream_hook,\n",
    "                inputs=inputs_per_activation,\n",
    "                hook_name=hook_name,\n",
    "                position=position_index,\n",
    "                char_sequence_position=char_sequence_position,\n",
    "            )\n",
    "\n",
    "            linear_probe_dataset_per_position_per_hook_name[hook_name][position_index][\n",
    "                char_sequence_position\n",
    "            ] = linear_probe_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeaa531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from jaxtyping import Float, Int\n",
    "\n",
    "# Assuming you have the following:\n",
    "# linear_probe_dataset_per_position_per_hook_name: dict[HookName, dict[SeqPosition, dict[CharSeqPosition, LinearProbeDataset]]]\n",
    "\n",
    "# Initialize a dictionary to store accuracies\n",
    "accuracy_dict: dict[tuple[HookName, SeqPosition, CharSeqPosition], float] = (\n",
    "    {}\n",
    ")  # {(hook_name, position, char_seq_position): accuracy}\n",
    "\n",
    "# We'll also store the linear_probes\n",
    "linear_probe_dict: dict[tuple[HookName, SeqPosition, CharSeqPosition], nn.Linear] = (\n",
    "    {}\n",
    ")  # {(hook_name, position, char_seq_position): linear_probe}\n",
    "\n",
    "# Iterate over each hook (layer), position, and char_sequence_position\n",
    "for hook_name in tqdm.tqdm(\n",
    "    linear_probe_dataset_per_position_per_hook_name.keys(),\n",
    "    desc=\"Processing hoooks...\",\n",
    "):\n",
    "    print(f\"Training linear probes for hook: {hook_name}\")\n",
    "\n",
    "    for position in tqdm.tqdm(\n",
    "        linear_probe_dataset_per_position_per_hook_name[hook_name],\n",
    "        desc=f\"Hook: {hook_name} Processing positions...\",\n",
    "    ):\n",
    "        print(f\"Training linear probes for hook: {hook_name} position: {position}\")\n",
    "\n",
    "        for char_seq_position in linear_probe_dataset_per_position_per_hook_name[hook_name][\n",
    "            position\n",
    "        ]:\n",
    "            print(\n",
    "                f\"Training linear probes for hook: {hook_name} \"\n",
    "                f\"position: {position} char_seq_position: {char_seq_position}\"\n",
    "            )\n",
    "\n",
    "            dataset = linear_probe_dataset_per_position_per_hook_name[hook_name][position][\n",
    "                char_seq_position\n",
    "            ]\n",
    "            activations: Float[torch.Tensor, \"batch d_model\"] = dataset.activations\n",
    "            labels: Int[torch.Tensor, \"batch\"] = dataset.labels\n",
    "\n",
    "            # Ensure activations and labels are on the same device\n",
    "            activations = activations.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Assuming labels are integer class labels (e.g., tokens)\n",
    "            num_classes = labels.max().item() + 1  # Number of classes\n",
    "\n",
    "            # Define the linear probe (a simple linear layer)\n",
    "            linear_probe: nn.Linear = nn.Linear(activations.size(-1), num_classes).to(device)\n",
    "\n",
    "            # Define loss function and optimizer\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.AdamW(linear_probe.parameters(), lr=1e-3)\n",
    "            # Training settings\n",
    "            num_epochs = 10\n",
    "            batch_size = 2048\n",
    "            num_samples = activations.size(0)\n",
    "\n",
    "            # Shuffle the data\n",
    "            indices = torch.randperm(num_samples)\n",
    "            activations_shuffled = activations[indices]\n",
    "            labels_shuffled = labels[indices]\n",
    "\n",
    "            # Training loop\n",
    "            for epoch in range(num_epochs):\n",
    "                epoch_loss = 0.0\n",
    "                batch_count = 0\n",
    "\n",
    "                for i in range(0, num_samples, batch_size):\n",
    "                    batch_count += 1\n",
    "\n",
    "                    # (batch_size, d_model)\n",
    "                    batch_activations = activations_shuffled[i : i + batch_size]\n",
    "                    batch_labels = labels_shuffled[i : i + batch_size]  # (batch_size)\n",
    "\n",
    "                    # Forward pass\n",
    "                    outputs: Float[torch.Tensor, \"batch num_classes\"] = linear_probe(\n",
    "                        batch_activations\n",
    "                    )\n",
    "\n",
    "                    loss = loss_fn(outputs, batch_labels)\n",
    "\n",
    "                    # Backward and optimize\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    epoch_loss += loss.item()\n",
    "\n",
    "                    # if batch_count % 100 == 0:\n",
    "                    #     print(\n",
    "                    #         f\"[{hook_name}@{position}@{char_seq_position}] \"\n",
    "                    #         f\"Loss for epoch {epoch} \"\n",
    "                    #         f\"batch {batch_count}: {loss.item():.6f}\"\n",
    "                    #     )\n",
    "\n",
    "                avg_loss = epoch_loss / (num_samples // batch_size)\n",
    "                print(\n",
    "                    f\"[{hook_name}@{position}@{char_seq_position}] \"\n",
    "                    f\"Average loss for epoch {epoch}: {avg_loss:.6f}\"\n",
    "                )\n",
    "\n",
    "            print(\n",
    "                f\"[{hook_name}@{position}@{char_seq_position}] \" f\"Finished training linear probe\"\n",
    "            )\n",
    "\n",
    "            # Move back to CPU and store the linear probe\n",
    "            linear_probe_dict[(hook_name, position, char_seq_position)] = linear_probe.to(\n",
    "                torch.device(\"cpu\")\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca79f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d66d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probe_accuracy(\n",
    "    linear_probe: nn.Linear,\n",
    "    dataset: LinearProbeDataset,\n",
    "    batch_size: int = 1024,\n",
    ") -> float:\n",
    "    linear_probe.eval()\n",
    "\n",
    "    linear_probe = linear_probe.to(device)\n",
    "\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        num_samples = dataset.activations.size(0)\n",
    "\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_activations = dataset.activations[i : i + batch_size].to(device)\n",
    "            batch_labels = dataset.labels[i : i + batch_size].to(device)\n",
    "            batch_labels = batch_labels.view(-1)\n",
    "\n",
    "            outputs = linear_probe(batch_activations)\n",
    "            predictions = outputs.argmax(dim=-1)\n",
    "\n",
    "            total_correct += (predictions == batch_labels).sum().item()\n",
    "            total_samples += batch_labels.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def compute_all_probe_accuracies(\n",
    "    linear_probe_dict: dict[tuple[HookName, SeqPosition, CharSeqPosition], nn.Linear],\n",
    "    dataset_dict: dict[HookName, dict[SeqPosition, dict[CharSeqPosition, LinearProbeDataset]]],\n",
    ") -> dict[tuple[HookName, SeqPosition, CharSeqPosition], float]:\n",
    "\n",
    "    accuracy_dict: dict[tuple[HookName, SeqPosition, CharSeqPosition], float] = {}\n",
    "\n",
    "    for (hook_name, position, char_seq_position), linear_probe in tqdm.tqdm(\n",
    "        linear_probe_dict.items()\n",
    "    ):\n",
    "\n",
    "        dataset = dataset_dict[hook_name][position][char_seq_position]\n",
    "\n",
    "        accuracy = compute_probe_accuracy(linear_probe, dataset)\n",
    "\n",
    "        accuracy_dict[(hook_name, position, char_seq_position)] = accuracy\n",
    "\n",
    "    return accuracy_dict\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "accuracy_dict = compute_all_probe_accuracies(\n",
    "    linear_probe_dict,\n",
    "    linear_probe_dataset_per_position_per_hook_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aaf020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probe_accuracies_lineplot(\n",
    "    accuracy_dict: dict[tuple[HookName, SeqPosition, CharSeqPosition], float]\n",
    ") -> None:\n",
    "    # Prepare data for plotting\n",
    "    data = []\n",
    "    for (hook_name, position, char_seq_position), accuracy in accuracy_dict.items():\n",
    "        data.append(\n",
    "            {\n",
    "                \"Hook Name\": hook_name,\n",
    "                \"Position\": position,\n",
    "                \"Char Seq Position\": char_seq_position,\n",
    "                \"Accuracy\": accuracy,\n",
    "            }\n",
    "        )\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Get unique char_seq_positions and sort them\n",
    "    char_seq_positions = sorted(df[\"Char Seq Position\"].unique())\n",
    "\n",
    "    # Create a subplot for each char_seq_position\n",
    "    fig, axes = plt.subplots(\n",
    "        len(char_seq_positions),\n",
    "        1,\n",
    "        figsize=(8, 2 * len(char_seq_positions)),\n",
    "        sharex=True,\n",
    "    )\n",
    "    fig.suptitle(\"Linear Probe Accuracy vs Position\", fontsize=14)\n",
    "\n",
    "    for idx, char_seq_position in enumerate(char_seq_positions):\n",
    "        df_subset = df[df[\"Char Seq Position\"] == char_seq_position]\n",
    "\n",
    "        sns.lineplot(\n",
    "            data=df_subset,\n",
    "            x=\"Position\",\n",
    "            y=\"Accuracy\",\n",
    "            hue=\"Hook Name\",\n",
    "            marker=\"o\",\n",
    "            alpha=0.5,\n",
    "            ax=axes[idx],\n",
    "        )\n",
    "        axes[idx].set_title(f\"Sorted Char: {char_seq_position}\")\n",
    "        axes[idx].set_xlabel(\"Sequence Position\")\n",
    "        axes[idx].set_ylabel(\"Accuracy\")\n",
    "        axes[idx].legend(title=\"Hook Name\", bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_probe_accuracies_heatmap(\n",
    "    accuracy_dict: dict[tuple[HookName, SeqPosition, CharSeqPosition], float]\n",
    ") -> None:\n",
    "    # Prepare data for plotting\n",
    "    data = []\n",
    "    for (hook_name, position, char_seq_position), accuracy in accuracy_dict.items():\n",
    "        data.append(\n",
    "            {\n",
    "                \"Hook Name\": hook_name,\n",
    "                \"Position\": position,\n",
    "                \"Char Seq Position\": char_seq_position,\n",
    "                \"Accuracy\": accuracy,\n",
    "            }\n",
    "        )\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Get unique hook_names, positions, and char_seq_positions and sort them\n",
    "    hook_names = sorted(df[\"Hook Name\"].unique())\n",
    "    positions = sorted(df[\"Position\"].unique())\n",
    "    char_seq_positions = sorted(df[\"Char Seq Position\"].unique())\n",
    "\n",
    "    # Create a figure for the heatmap\n",
    "    fig, axes = plt.subplots(\n",
    "        len(char_seq_positions),\n",
    "        1,\n",
    "        figsize=(8, 2 * len(char_seq_positions)),\n",
    "        sharex=True,\n",
    "    )\n",
    "    fig.suptitle(\"Linear Probe Accuracy Heatmap\", fontsize=14)\n",
    "\n",
    "    for idx, char_seq_position in enumerate(char_seq_positions):\n",
    "        df_subset = df[df[\"Char Seq Position\"] == char_seq_position]\n",
    "\n",
    "        # Pivot the data to create a 2D matrix for the heatmap\n",
    "        pivot_df = df_subset.pivot(index=\"Hook Name\", columns=\"Position\", values=\"Accuracy\")\n",
    "\n",
    "        # Create the heatmap\n",
    "        sns.heatmap(\n",
    "            pivot_df,\n",
    "            ax=axes[idx] if len(char_seq_positions) > 1 else axes,\n",
    "            cmap=\"Blues\",\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            cbar_kws={\"label\": \"Accuracy\"},\n",
    "        )\n",
    "\n",
    "        axes[idx].set_title(f\"Sorted Char: {char_seq_position}\")\n",
    "        axes[idx].set_xlabel(\"Sequence Position\")\n",
    "        axes[idx].set_ylabel(\"Hook Name\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_probe_accuracies_lineplot(accuracy_dict)\n",
    "plot_probe_accuracies_heatmap(accuracy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192c0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_probe_confusion_matrices(\n",
    "    linear_probe_dict: dict[tuple[HookName, SeqPosition], nn.Linear],\n",
    "    dataset_dict: dict[HookName, dict[SeqPosition, LinearProbeDataset]],\n",
    ") -> None:\n",
    "    # Get unique hook names and positions\n",
    "    hook_names = sorted(set(hook_name for hook_name, _ in linear_probe_dict.keys()))\n",
    "    positions = sorted(set(position for _, position in linear_probe_dict.keys()))\n",
    "\n",
    "    # Create a grid of subplots\n",
    "    fig, axes = plt.subplots(\n",
    "        len(hook_names), len(positions), figsize=(5 * len(positions), 4 * len(hook_names))\n",
    "    )\n",
    "    fig.suptitle(\"Confusion Matrices for Linear Probes\", fontsize=16)\n",
    "\n",
    "    for i, hook_name in enumerate(hook_names):\n",
    "        for j, position in enumerate(positions):\n",
    "            if (hook_name, position) in linear_probe_dict:\n",
    "                linear_probe = linear_probe_dict[(hook_name, position)]\n",
    "                dataset = dataset_dict[hook_name][position]\n",
    "\n",
    "                linear_probe.eval()\n",
    "                with torch.no_grad():\n",
    "                    activations = dataset.activations.to(device)\n",
    "                    labels = dataset.labels.to(device)\n",
    "                    labels = labels.view(-1)\n",
    "                    outputs = linear_probe(activations)\n",
    "                    predictions = outputs.argmax(dim=-1)\n",
    "\n",
    "                cm = confusion_matrix(labels.cpu(), predictions.cpu())\n",
    "\n",
    "                sns.heatmap(cm, cmap=\"Blues\", ax=axes[i, j], cbar=False)\n",
    "                if i == 0:\n",
    "                    axes[i, j].set_title(f\"{hook_name}\\nPosition {position}\")\n",
    "                axes[i, j].set_xlabel(\"Predicted\")\n",
    "                axes[i, j].set_ylabel(\"Actual\")\n",
    "            else:\n",
    "                axes[i, j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "plot_probe_confusion_matrices(linear_probe_dict, linear_probe_dataset_per_position_per_hook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33405e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def visualize_linear_probe_weights(linear_probe: nn.Linear, num_components: int = 2) -> None:\n",
    "    weights = linear_probe.weight.data.cpu().numpy()\n",
    "    num_classes = weights.shape[0]\n",
    "\n",
    "    pca = PCA(n_components=num_components)\n",
    "    weights_pca = pca.fit_transform(weights)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(num_classes):\n",
    "        plt.scatter(weights_pca[i, 0], weights_pca[i, 1], label=f\"Class {i}\")\n",
    "    plt.legend()\n",
    "    plt.title(\"PCA of Linear Probe Weights\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "visualize_linear_probe_weights(linear_probe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_activations_with_labels(\n",
    "    dataset: LinearProbeDataset,\n",
    "    num_components: int = 2,\n",
    "    sample_size: int | None = None,\n",
    ") -> None:\n",
    "    activations = dataset.activations\n",
    "    labels = dataset.labels\n",
    "    if sample_size and activations.size(0) > sample_size:\n",
    "        indices = torch.randperm(activations.size(0))[:sample_size]\n",
    "        activations = activations[indices]\n",
    "        labels = labels[indices]\n",
    "    activations_np = activations.cpu().numpy()\n",
    "    labels_np = labels.view(-1).cpu().numpy()\n",
    "\n",
    "    pca = PCA(n_components=num_components)\n",
    "    activations_pca = pca.fit_transform(activations_np)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(\n",
    "        activations_pca[:, 0], activations_pca[:, 1], c=labels_np, cmap=\"viridis\", alpha=0.5\n",
    "    )\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(\"PCA of Activations Colored by Labels\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "visualize_activations_with_labels(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_weights(\n",
    "    linear_probes_by_hook_and_position: dict[tuple[HookName, SeqPosition], nn.Linear],\n",
    "    hook_name_to_visualize: HookName,\n",
    "    position_to_visualize: SeqPosition,\n",
    "    num_classes: int,\n",
    ") -> None:\n",
    "    linear_probe = linear_probes_by_hook_and_position[\n",
    "        (hook_name_to_visualize, position_to_visualize)\n",
    "    ]\n",
    "\n",
    "    weight_matrix = linear_probe.weight.detach().cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(weight_matrix, cmap=\"coolwarm\")\n",
    "    plt.title(\n",
    "        f\"Weights of Linear Probe at Hook: {hook_name_to_visualize}, Position: {position_to_visualize}\"\n",
    "    )\n",
    "    plt.xlabel(\"Model Hidden Dimension\")\n",
    "    plt.ylabel(\"Output Classes\")\n",
    "    plt.show()\n",
    "\n",
    "    # PCA visualization\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    weight_vectors = weight_matrix\n",
    "    pca = PCA(n_components=2)\n",
    "    weight_vectors_2d = pca.fit_transform(weight_vectors)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(weight_vectors_2d[:, 0], weight_vectors_2d[:, 1])\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        plt.text(weight_vectors_2d[i, 0], weight_vectors_2d[i, 1], str(i))\n",
    "\n",
    "    plt.title(\n",
    "        f\"PCA of Linear Probe Weights at Hook: {hook_name_to_visualize}, Position: {position_to_visualize}\"\n",
    "    )\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def interpret_probes(\n",
    "    linear_probes_by_hook_and_position: dict[tuple[HookName, SeqPosition], nn.Linear],\n",
    "    num_top_features: int = 5,\n",
    ") -> None:\n",
    "\n",
    "    weights_dict = {\n",
    "        k: v.weight.detach().cpu().numpy() for k, v in linear_probes_by_hook_and_position.items()\n",
    "    }\n",
    "\n",
    "    for (hook_name, position), weight_matrix in weights_dict.items():\n",
    "        print(f\"Hook: {hook_name}, Position: {position}\")\n",
    "        num_classes = weight_matrix.shape[0]\n",
    "        for class_index in range(num_classes):\n",
    "            class_weights = weight_matrix[class_index]\n",
    "            top_features = np.argsort(np.abs(class_weights))[-num_top_features:][::-1]\n",
    "            print(f\"  Top features for class {class_index}: {top_features}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "accuracy_dict, weights_dict = train_linear_probes(linear_probe_dataset_per_position_per_hook_name)\n",
    "visualize_accuracies(accuracy_dict)\n",
    "hook_name_to_visualize = hook_names[0]\n",
    "position_to_visualize = positions[0]\n",
    "num_classes = labels.max().item() + 1\n",
    "visualize_weights(weights_dict, hook_name_to_visualize, position_to_visualize, num_classes)\n",
    "interpret_probes(weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aed855",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc6a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Order:\n",
    "    LESS_THAN = -1\n",
    "    EQUAL = 0\n",
    "    GREATER_THAN = 1\n",
    "\n",
    "\n",
    "def create_order_tensor(input_string: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Creates a PyTorch tensor representing the lexicographical order of characters in the input string.\n",
    "\n",
    "    Args:\n",
    "    input_string (str): The input string to analyze.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: A tensor of shape (len(input_string), len(input_string)) where tensor[i][j] is:\n",
    "        1 if input_string[i] comes before input_string[j] in lexicographical order\n",
    "        0 if input_string[i] is the same as input_string[j]\n",
    "        -1 if input_string[i] comes after input_string[j] in lexicographical order\n",
    "    \"\"\"\n",
    "    # Get the length of the input string\n",
    "    n = len(input_string)\n",
    "\n",
    "    # Create a tensor of zeros with shape (n, n)\n",
    "    order_tensor = torch.zeros((n, n), dtype=torch.int)\n",
    "\n",
    "    # Fill the tensor based on lexicographical order\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                # Same character, set to 0\n",
    "                order_tensor[i, j] = Order.EQUAL\n",
    "            elif input_string[i] < input_string[j]:\n",
    "                # Character at i comes before character at j\n",
    "                order_tensor[i, j] = Order.GREATER_THAN\n",
    "            else:\n",
    "                # Character at i comes after character at j\n",
    "                order_tensor[i, j] = Order.LESS_THAN\n",
    "\n",
    "    return order_tensor\n",
    "\n",
    "\n",
    "# Example usage\n",
    "input_string = \"adbc\"\n",
    "order_tensor = create_order_tensor(input_string)\n",
    "print(order_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a382102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e7415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09e3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "class SampleInfo:\n",
    "\n",
    "    sorted_string_tokens: list[str]\n",
    "\n",
    "\n",
    "sample_to_sample_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab73b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2008789b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952337bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c952317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191cc310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "706d8828",
   "metadata": {},
   "source": [
    "## SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12bd9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch import sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b482277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import rich\n",
    "import rich.table\n",
    "\n",
    "\n",
    "def print_summary_of_sparsifier_wandb_log_dicts(metrics_dict: dict[str, float]) -> None:\n",
    "    \"\"\"\n",
    "    Summarizes metrics by their top-level identifiers ('tc_*' or 'sae_*').\n",
    "\n",
    "    Args:\n",
    "        metrics_dict (dict): Dictionary containing metric names and their values.\n",
    "\n",
    "    Prints:\n",
    "        One-line summary for each top-level identifier.\n",
    "    \"\"\"\n",
    "    summaries = collections.defaultdict(dict)\n",
    "\n",
    "    # Group metrics by their top-level key\n",
    "    for key, value in metrics_dict.items():\n",
    "        try:\n",
    "            top_level, metric = key.split(\"/\", 1)\n",
    "        except ValueError:\n",
    "            # Handle keys without a '/'\n",
    "            top_level, metric = key, \"\"\n",
    "        summaries[top_level][metric] = value\n",
    "\n",
    "    # Define which metrics to include in the summary\n",
    "    summary_metrics = [\n",
    "        \"total_loss\",\n",
    "        \"mse_loss\",\n",
    "        \"reconstruction_loss\",  # Depending on 'tc' or 'sae'\n",
    "        \"activations_sparsity\",\n",
    "        \"activations_mean\",\n",
    "        # Add more metrics here if needed\n",
    "    ]\n",
    "\n",
    "    # Initialize the Rich console and table\n",
    "    table = rich.table.Table(title=\"Summary of Sparsifier WandB Metrics\")\n",
    "\n",
    "    # Define table columns\n",
    "    table.add_column(\"Identifier\", style=\"cyan\", no_wrap=True)\n",
    "    for metric in summary_metrics:\n",
    "        table.add_column(metric.replace(\"_\", \" \").title(), justify=\"right\")\n",
    "\n",
    "    # Populate the table with data\n",
    "    for top, metrics in summaries.items():\n",
    "        row = [top]\n",
    "        for metric in summary_metrics:\n",
    "            value = metrics.get(metric, None)\n",
    "            if value is not None:\n",
    "                row.append(f\"{value:.6f}\")\n",
    "            else:\n",
    "                row.append(\"N/A\")\n",
    "        table.add_row(*row)\n",
    "\n",
    "    # Render the table\n",
    "    rich.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5b1a14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Hook Name                      </span><span style=\"font-weight: bold\"> Shape                      </span>\n",
       "\n",
       " hook_embed                      torch.Size([1, 11, 16])    \n",
       " hook_pos_embed                  torch.Size([1, 11, 16])    \n",
       " blocks.0.hook_resid_pre         torch.Size([1, 11, 16])    \n",
       " blocks.0.attn.hook_q            torch.Size([1, 11, 2, 8])  \n",
       " blocks.0.attn.hook_k            torch.Size([1, 11, 2, 8])  \n",
       " blocks.0.attn.hook_v            torch.Size([1, 11, 2, 8])  \n",
       " blocks.0.attn.hook_attn_scores  torch.Size([1, 2, 11, 11]) \n",
       " blocks.0.attn.hook_pattern      torch.Size([1, 2, 11, 11]) \n",
       " blocks.0.attn.hook_z            torch.Size([1, 11, 2, 8])  \n",
       " blocks.0.hook_attn_out          torch.Size([1, 11, 16])    \n",
       " blocks.0.hook_resid_mid         torch.Size([1, 11, 16])    \n",
       " blocks.0.mlp.hook_pre           torch.Size([1, 11, 64])    \n",
       " blocks.0.mlp.hook_post          torch.Size([1, 11, 64])    \n",
       " blocks.0.hook_mlp_out           torch.Size([1, 11, 16])    \n",
       " blocks.0.hook_resid_post        torch.Size([1, 11, 16])    \n",
       " blocks.1.hook_resid_pre         torch.Size([1, 11, 16])    \n",
       " blocks.1.attn.hook_q            torch.Size([1, 11, 2, 8])  \n",
       " blocks.1.attn.hook_k            torch.Size([1, 11, 2, 8])  \n",
       " blocks.1.attn.hook_v            torch.Size([1, 11, 2, 8])  \n",
       " blocks.1.attn.hook_attn_scores  torch.Size([1, 2, 11, 11]) \n",
       " blocks.1.attn.hook_pattern      torch.Size([1, 2, 11, 11]) \n",
       " blocks.1.attn.hook_z            torch.Size([1, 11, 2, 8])  \n",
       " blocks.1.hook_attn_out          torch.Size([1, 11, 16])    \n",
       " blocks.1.hook_resid_mid         torch.Size([1, 11, 16])    \n",
       " blocks.1.mlp.hook_pre           torch.Size([1, 11, 64])    \n",
       " blocks.1.mlp.hook_post          torch.Size([1, 11, 64])    \n",
       " blocks.1.hook_mlp_out           torch.Size([1, 11, 16])    \n",
       " blocks.1.hook_resid_post        torch.Size([1, 11, 16])    \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mHook Name                     \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mShape                     \u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " hook_embed                      torch.Size([1, 11, 16])    \n",
       " hook_pos_embed                  torch.Size([1, 11, 16])    \n",
       " blocks.0.hook_resid_pre         torch.Size([1, 11, 16])    \n",
       " blocks.0.attn.hook_q            torch.Size([1, 11, 2, 8])  \n",
       " blocks.0.attn.hook_k            torch.Size([1, 11, 2, 8])  \n",
       " blocks.0.attn.hook_v            torch.Size([1, 11, 2, 8])  \n",
       " blocks.0.attn.hook_attn_scores  torch.Size([1, 2, 11, 11]) \n",
       " blocks.0.attn.hook_pattern      torch.Size([1, 2, 11, 11]) \n",
       " blocks.0.attn.hook_z            torch.Size([1, 11, 2, 8])  \n",
       " blocks.0.hook_attn_out          torch.Size([1, 11, 16])    \n",
       " blocks.0.hook_resid_mid         torch.Size([1, 11, 16])    \n",
       " blocks.0.mlp.hook_pre           torch.Size([1, 11, 64])    \n",
       " blocks.0.mlp.hook_post          torch.Size([1, 11, 64])    \n",
       " blocks.0.hook_mlp_out           torch.Size([1, 11, 16])    \n",
       " blocks.0.hook_resid_post        torch.Size([1, 11, 16])    \n",
       " blocks.1.hook_resid_pre         torch.Size([1, 11, 16])    \n",
       " blocks.1.attn.hook_q            torch.Size([1, 11, 2, 8])  \n",
       " blocks.1.attn.hook_k            torch.Size([1, 11, 2, 8])  \n",
       " blocks.1.attn.hook_v            torch.Size([1, 11, 2, 8])  \n",
       " blocks.1.attn.hook_attn_scores  torch.Size([1, 2, 11, 11]) \n",
       " blocks.1.attn.hook_pattern      torch.Size([1, 2, 11, 11]) \n",
       " blocks.1.attn.hook_z            torch.Size([1, 11, 2, 8])  \n",
       " blocks.1.hook_attn_out          torch.Size([1, 11, 16])    \n",
       " blocks.1.hook_resid_mid         torch.Size([1, 11, 16])    \n",
       " blocks.1.mlp.hook_pre           torch.Size([1, 11, 64])    \n",
       " blocks.1.mlp.hook_post          torch.Size([1, 11, 64])    \n",
       " blocks.1.hook_mlp_out           torch.Size([1, 11, 16])    \n",
       " blocks.1.hook_resid_post        torch.Size([1, 11, 16])    \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run on an example to inspect\n",
    "input_string = \"<bacd|abcd>\"\n",
    "input_string_tokens = tokenize_string_as_batch(tokenizer, input_string)\n",
    "logits, cache = model.run_with_cache(input_string_tokens)\n",
    "\n",
    "show_cache(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0263d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blocks.0.hook_resid_pre',\n",
       " 'blocks.0.hook_attn_out',\n",
       " 'blocks.0.hook_resid_mid',\n",
       " 'blocks.0.hook_mlp_out',\n",
       " 'blocks.0.hook_resid_post',\n",
       " 'blocks.1.hook_resid_pre',\n",
       " 'blocks.1.hook_attn_out',\n",
       " 'blocks.1.hook_resid_mid',\n",
       " 'blocks.1.hook_mlp_out',\n",
       " 'blocks.1.hook_resid_post']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# anything with last dimension `d_model` is in the residual stream (not just `resid` layers)\n",
    "#\n",
    "# NOTE: We're fine excluding `hook_embed` and `hook_pos_embed` because those get added together to\n",
    "#       form `hook_resid_pre`\n",
    "#\n",
    "residual_stream_hook_names = [\n",
    "    k\n",
    "    for k in cache.keys()\n",
    "    if cache[k].shape[-1] == model.cfg.d_model and k not in [\"hook_embed\", \"hook_pos_embed\"]\n",
    "]\n",
    "\n",
    "residual_stream_hook_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da553153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sae_trainer_per_hook(\n",
    "    residual_stream_hook_names: list[str],\n",
    "    model: tl.HookedTransformer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    ") -> dict[str, sae.SAETrainer]:\n",
    "\n",
    "    # create an SAE trainer per residual stream hook\n",
    "    sae_trainer_per_hook: dict[str, sae.SAETrainer] = {}\n",
    "\n",
    "    # chosen arbitrarily (should be closer to 4)\n",
    "    sae_expansion_factor = 4\n",
    "\n",
    "    for hook_name in residual_stream_hook_names:\n",
    "\n",
    "        sae_trainer_per_hook[hook_name] = sae.SAETrainer(\n",
    "            sae_cfg=sae.SAEConfig(\n",
    "                input_size=model.cfg.d_model,\n",
    "                n_dict_components=model.cfg.d_model * sae_expansion_factor,\n",
    "            ),\n",
    "            sae_trainer_cfg=sae.SAETrainerConfig(\n",
    "                hook_point=hook_name,\n",
    "                num_epochs=num_epochs,\n",
    "                lr=5e-3,\n",
    "                loss_config=sae.SAELossConfig(l1_coefficient=1e-6),\n",
    "            ),\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    return sae_trainer_per_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b71f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f3a5d91",
   "metadata": {},
   "source": [
    "## Transcoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab01dc5",
   "metadata": {},
   "source": [
    "## Training Sparsifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ef70012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we've got a reasonable setup, let's train the transcoder (\n",
    "# for sorting a fixed size list, we can see 100% of the activation comes\n",
    "# from the final layer MLP)\n",
    "from gpt_from_scratch import transcoder\n",
    "\n",
    "\n",
    "def create_transcoder_trainer_per_hook(\n",
    "    model: tl.HookedTransformer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    ") -> dict[str, transcoder.TranscoderTrainer]:\n",
    "\n",
    "    # create a transcoder trainer per MLP\n",
    "    transcoder_trainer_per_hook: dict[str, transcoder.TranscoderTrainer] = {}\n",
    "\n",
    "    for block_index, _ in enumerate(model.blocks):\n",
    "\n",
    "        # get the MLP input and output hook names\n",
    "        mlp_in_hook_name = f\"blocks.{block_index}.hook_resid_mid\"\n",
    "        mlp_out_hook_name = f\"blocks.{block_index}.hook_mlp_out\"\n",
    "\n",
    "        transcoder_cfg = transcoder.TranscoderConfig.from_model(model=model, device=device)\n",
    "\n",
    "        transcoder_training_cfg = transcoder.TranscoderTrainingConfig(\n",
    "            hook_point=mlp_in_hook_name,\n",
    "            out_hook_point=mlp_out_hook_name,\n",
    "            num_epochs=num_epochs,\n",
    "            learning_rate=1e-3,\n",
    "            l1_coefficient=1e-6,\n",
    "        )\n",
    "\n",
    "        # create a transcoder trainer\n",
    "        transcoder_trainer_per_hook[mlp_in_hook_name] = transcoder.TranscoderTrainer(\n",
    "            transcoder_cfg=transcoder_cfg,\n",
    "            transcoder_training_cfg=transcoder_training_cfg,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    return transcoder_trainer_per_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26eb2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hook_names_to_cache_for_trainers(\n",
    "    transcoder_trainer_per_hook: dict[str, transcoder.TranscoderTrainer],\n",
    "    sae_trainer_per_hook: dict[str, sae.SAETrainer],\n",
    ") -> set[str]:\n",
    "\n",
    "    # determine which layers we need to cache for the transcoder and saes, since\n",
    "    # we don't need things like q / k\n",
    "    hook_names_to_cache = []\n",
    "\n",
    "    for trainer in transcoder_trainer_per_hook.values():\n",
    "        hook_names_to_cache.extend([trainer.cfg.hook_point, trainer.cfg.out_hook_point])\n",
    "\n",
    "    for trainer in sae_trainer_per_hook.values():\n",
    "        hook_names_to_cache.append(trainer.cfg.hook_point)\n",
    "\n",
    "    # removes duplicates and makes it clear we're checking this for membership\n",
    "    hook_names_to_cache = set(hook_names_to_cache)\n",
    "\n",
    "    return hook_names_to_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3ffcd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bronsonschoen/gpt_from_scratch/wandb/run-20240923_165953-jwd4f4bg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2/runs/jwd4f4bg' target=\"_blank\">sweet-sea-48</a></strong> to <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2/runs/jwd4f4bg' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2/runs/jwd4f4bg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                        Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\">                        </span><span style=\"font-weight: bold\">            </span><span style=\"font-weight: bold\">            </span><span style=\"font-weight: bold\">                     </span><span style=\"font-weight: bold\">         Activations </span><span style=\"font-weight: bold\">                  </span>\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\">   Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\">            Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   4.144760    3.807050                  N/A                  N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span> 379.958160  376.947998                  N/A                  N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.360534         N/A             0.323986             0.498517          0.111536 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.416192         N/A             0.376285             0.506174          0.121787 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   1.148339         N/A             1.088098             0.476801          0.183840 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   7.007102         N/A             6.849910             0.503879          0.479710 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>  11.505895         N/A            11.297691             0.534671          0.635386 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>  15.137506         N/A            14.928329             0.512659          0.638359 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>  75.451599         N/A            75.013710             0.528336          1.336320 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span> 108.981941         N/A           108.485100             0.522861          1.516241 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span> 624.451843         N/A           623.398376             0.512436          3.214996 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span> 558.552124         N/A           557.256165             0.535599          3.954955 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                        Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m                        \u001b[0m\u001b[1m            \u001b[0m\u001b[1m            \u001b[0m\u001b[1m                     \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Activations\u001b[0m\u001b[1m \u001b[0m\u001b[1m                  \u001b[0m\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m  Mse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m           Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   4.144760    3.807050                  N/A                  N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m 379.958160  376.947998                  N/A                  N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.360534         N/A             0.323986             0.498517          0.111536 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.416192         N/A             0.376285             0.506174          0.121787 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   1.148339         N/A             1.088098             0.476801          0.183840 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   7.007102         N/A             6.849910             0.503879          0.479710 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m  11.505895         N/A            11.297691             0.534671          0.635386 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m  15.137506         N/A            14.928329             0.512659          0.638359 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m  75.451599         N/A            75.013710             0.528336          1.336320 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m 108.981941         N/A           108.485100             0.522861          1.516241 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m 624.451843         N/A           623.398376             0.512436          3.214996 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m 558.552124         N/A           557.256165             0.535599          3.954955 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:39, 26.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.037567  0.004805                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   1.037443  0.094164                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.012327       N/A             0.000961              0.863367          0.034688 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.012124       N/A             0.001207              0.812036          0.033316 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.025762       N/A             0.004081              0.734677          0.066167 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.069136       N/A             0.010233              0.700412          0.179757 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.093297       N/A             0.013720              0.673257          0.242850 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.098369       N/A             0.016209              0.697876          0.250732 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.191771       N/A             0.020454              0.729837          0.522817 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.309577       N/A             0.050776              0.581610          0.789798 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.984931       N/A             0.249862              0.547504          2.243253 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   1.205523       N/A             0.287906              0.556839          2.800344 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.037567  0.004805                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   1.037443  0.094164                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.012327       N/A             0.000961              0.863367          0.034688 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.012124       N/A             0.001207              0.812036          0.033316 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.025762       N/A             0.004081              0.734677          0.066167 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.069136       N/A             0.010233              0.700412          0.179757 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.093297       N/A             0.013720              0.673257          0.242850 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.098369       N/A             0.016209              0.697876          0.250732 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.191771       N/A             0.020454              0.729837          0.522817 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.309577       N/A             0.050776              0.581610          0.789798 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.984931       N/A             0.249862              0.547504          2.243253 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   1.205523       N/A             0.287906              0.556839          2.800344 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1999it [01:17, 25.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.021078  0.003068                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.509518  0.064961                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.010762       N/A             0.000551              0.901636          0.031163 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011635       N/A             0.001021              0.816666          0.032391 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.023108       N/A             0.002991              0.767346          0.061392 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.057869       N/A             0.006255              0.722989          0.157513 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.078103       N/A             0.008023              0.697888          0.213868 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.082017       N/A             0.009019              0.705606          0.222772 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.150234       N/A             0.010606              0.765726          0.426111 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.236838       N/A             0.029585              0.633536          0.632484 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.665960       N/A             0.113473              0.572641          1.686058 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.819534       N/A             0.125363              0.584457          2.118439 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.021078  0.003068                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.509518  0.064961                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.010762       N/A             0.000551              0.901636          0.031163 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011635       N/A             0.001021              0.816666          0.032391 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.023108       N/A             0.002991              0.767346          0.061392 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.057869       N/A             0.006255              0.722989          0.157513 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.078103       N/A             0.008023              0.697888          0.213868 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.082017       N/A             0.009019              0.705606          0.222772 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.150234       N/A             0.010606              0.765726          0.426111 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.236838       N/A             0.029585              0.633536          0.632484 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.665960       N/A             0.113473              0.572641          1.686058 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.819534       N/A             0.125363              0.584457          2.118439 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2999it [01:54, 27.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.016075  0.002301                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.331529  0.050697                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.010271       N/A             0.000383              0.927045          0.030176 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011571       N/A             0.000983              0.819479          0.032313 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.022097       N/A             0.002658              0.784900          0.059323 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.053230       N/A             0.004885              0.734390          0.147535 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.072072       N/A             0.006217              0.704980          0.200973 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.075697       N/A             0.007219              0.718210          0.208978 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.140589       N/A             0.007165              0.766763          0.407180 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.217028       N/A             0.022049              0.645142          0.595028 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.560215       N/A             0.069918              0.584943          1.496269 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.678263       N/A             0.071657              0.593933          1.851215 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.016075  0.002301                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.331529  0.050697                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.010271       N/A             0.000383              0.927045          0.030176 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011571       N/A             0.000983              0.819479          0.032313 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.022097       N/A             0.002658              0.784900          0.059323 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.053230       N/A             0.004885              0.734390          0.147535 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.072072       N/A             0.006217              0.704980          0.200973 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.075697       N/A             0.007219              0.718210          0.208978 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.140589       N/A             0.007165              0.766763          0.407180 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.217028       N/A             0.022049              0.645142          0.595028 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.560215       N/A             0.069918              0.584943          1.496269 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.678263       N/A             0.071657              0.593933          1.851215 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3998it [02:34, 22.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.013411  0.001917                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.260546  0.038344                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.010082       N/A             0.000325              0.932867          0.029775 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011530       N/A             0.001037              0.816043          0.032021 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.021681       N/A             0.002595              0.802087          0.058246 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.051316       N/A             0.004191              0.739902          0.143814 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.069065       N/A             0.005060              0.710522          0.195327 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.070514       N/A             0.005365              0.714468          0.198818 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.136003       N/A             0.005184              0.779849          0.399226 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.204785       N/A             0.015640              0.651572          0.577224 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.508001       N/A             0.044285              0.599222          1.415149 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.610069       N/A             0.046470              0.595288          1.719968 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.013411  0.001917                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.260546  0.038344                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.010082       N/A             0.000325              0.932867          0.029775 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011530       N/A             0.001037              0.816043          0.032021 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.021681       N/A             0.002595              0.802087          0.058246 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.051316       N/A             0.004191              0.739902          0.143814 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.069065       N/A             0.005060              0.710522          0.195327 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.070514       N/A             0.005365              0.714468          0.198818 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.136003       N/A             0.005184              0.779849          0.399226 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.204785       N/A             0.015640              0.651572          0.577224 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.508001       N/A             0.044285              0.599222          1.415149 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.610069       N/A             0.046470              0.595288          1.719968 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5000it [03:13, 26.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.011448  0.001640                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.221442  0.030515                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.009993       N/A             0.000330              0.937454          0.029487 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011366       N/A             0.001005              0.819525          0.031618 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.021084       N/A             0.002556              0.818893          0.056543 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.049782       N/A             0.004061              0.740723          0.139528 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.066755       N/A             0.004491              0.710303          0.190016 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.067090       N/A             0.004285              0.717123          0.191667 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.132559       N/A             0.004272              0.788992          0.391500 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.195373       N/A             0.012195              0.651740          0.559015 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.487739       N/A             0.046660              0.612302          1.346067 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.564143       N/A             0.029019              0.610522          1.633069 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.011448  0.001640                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.221442  0.030515                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.009993       N/A             0.000330              0.937454          0.029487 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011366       N/A             0.001005              0.819525          0.031618 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.021084       N/A             0.002556              0.818893          0.056543 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.049782       N/A             0.004061              0.740723          0.139528 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.066755       N/A             0.004491              0.710303          0.190016 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.067090       N/A             0.004285              0.717123          0.191667 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.132559       N/A             0.004272              0.788992          0.391500 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.195373       N/A             0.012195              0.651740          0.559015 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.487739       N/A             0.046660              0.612302          1.346067 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.564143       N/A             0.029019              0.610522          1.633069 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6000it [04:00,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.010190  0.001481                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.200137  0.025420                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.009895       N/A             0.000300              0.943353          0.029282 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011435       N/A             0.001004              0.814227          0.031834 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.020820       N/A             0.002540              0.828528          0.055786 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.049206       N/A             0.003656              0.742960          0.139008 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.065676       N/A             0.004442              0.713788          0.186869 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.065740       N/A             0.003762              0.723947          0.189140 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.129894       N/A             0.003755              0.786420          0.384943 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.191452       N/A             0.011226              0.657297          0.550007 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.477777       N/A             0.045938              0.623065          1.317869 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.557889       N/A             0.037463              0.621625          1.588216 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.010190  0.001481                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.200137  0.025420                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.009895       N/A             0.000300              0.943353          0.029282 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011435       N/A             0.001004              0.814227          0.031834 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.020820       N/A             0.002540              0.828528          0.055786 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.049206       N/A             0.003656              0.742960          0.139008 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.065676       N/A             0.004442              0.713788          0.186869 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.065740       N/A             0.003762              0.723947          0.189140 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.129894       N/A             0.003755              0.786420          0.384943 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.191452       N/A             0.011226              0.657297          0.550007 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.477777       N/A             0.045938              0.623065          1.317869 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.557889       N/A             0.037463              0.621625          1.588216 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6999it [05:02, 19.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.009113  0.001232                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.183926  0.022434                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.009839       N/A             0.000327              0.945502          0.029031 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011341       N/A             0.001089              0.814465          0.031284 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.020629       N/A             0.002409              0.831366          0.055604 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.048650       N/A             0.003455              0.740393          0.137923 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.064347       N/A             0.003885              0.723203          0.184514 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.064693       N/A             0.003443              0.723871          0.186922 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.129133       N/A             0.003514              0.795084          0.383359 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.188861       N/A             0.012820              0.648145          0.537237 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.443137       N/A             0.024472              0.643600          1.277665 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.568226       N/A             0.056562              0.625577          1.561474 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.009113  0.001232                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.183926  0.022434                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.009839       N/A             0.000327              0.945502          0.029031 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011341       N/A             0.001089              0.814465          0.031284 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.020629       N/A             0.002409              0.831366          0.055604 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.048650       N/A             0.003455              0.740393          0.137923 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.064347       N/A             0.003885              0.723203          0.184514 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.064693       N/A             0.003443              0.723871          0.186922 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.129133       N/A             0.003514              0.795084          0.383359 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.188861       N/A             0.012820              0.648145          0.537237 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.443137       N/A             0.024472              0.643600          1.277665 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.568226       N/A             0.056562              0.625577          1.561474 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7999it [05:46, 25.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.008351  0.001128                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.173318  0.018713                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.009779       N/A             0.000305              0.949847          0.028911 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011339       N/A             0.001033              0.822607          0.031452 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.020490       N/A             0.002454              0.838324          0.055041 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.048667       N/A             0.003580              0.746396          0.137594 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.063779       N/A             0.004113              0.722818          0.182089 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.064284       N/A             0.003630              0.728336          0.185103 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.129343       N/A             0.003305              0.800528          0.384638 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.186050       N/A             0.010732              0.656192          0.535027 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.434200       N/A             0.019366              0.655890          1.265972 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.538444       N/A             0.028541              0.629150          1.556101 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.008351  0.001128                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.173318  0.018713                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.009779       N/A             0.000305              0.949847          0.028911 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011339       N/A             0.001033              0.822607          0.031452 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.020490       N/A             0.002454              0.838324          0.055041 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.048667       N/A             0.003580              0.746396          0.137594 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.063779       N/A             0.004113              0.722818          0.182089 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.064284       N/A             0.003630              0.728336          0.185103 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.129343       N/A             0.003305              0.800528          0.384638 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.186050       N/A             0.010732              0.656192          0.535027 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.434200       N/A             0.019366              0.655890          1.265972 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.538444       N/A             0.028541              0.629150          1.556101 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8999it [06:26, 24.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9000/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.007756  0.001031                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.161779  0.017318                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.009726       N/A             0.000280              0.951590          0.028828 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011406       N/A             0.001047              0.814813          0.031613 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.020480       N/A             0.002377              0.837979          0.055247 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.048509       N/A             0.003501              0.751129          0.137353 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.063655       N/A             0.003873              0.728854          0.182442 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.063944       N/A             0.003534              0.725336          0.184359 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.128149       N/A             0.002622              0.798730          0.383080 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.179311       N/A             0.007210              0.657056          0.525211 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.427850       N/A             0.018905              0.665829          1.248001 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.516978       N/A             0.017563              0.620880          1.524095 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.007756  0.001031                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.161779  0.017318                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.009726       N/A             0.000280              0.951590          0.028828 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011406       N/A             0.001047              0.814813          0.031613 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.020480       N/A             0.002377              0.837979          0.055247 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.048509       N/A             0.003501              0.751129          0.137353 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.063655       N/A             0.003873              0.728854          0.182442 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.063944       N/A             0.003534              0.725336          0.184359 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.128149       N/A             0.002622              0.798730          0.383080 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.179311       N/A             0.007210              0.657056          0.525211 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.427850       N/A             0.018905              0.665829          1.248001 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.516978       N/A             0.017563              0.620880          1.524095 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9998it [07:07, 26.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9999/10000] Logging...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                       Summary of Sparsifier WandB Metrics                                        </span>\n",
       "\n",
       "<span style=\"font-weight: bold\"> Identifier             </span><span style=\"font-weight: bold\"> Total Loss </span><span style=\"font-weight: bold\"> Mse Loss </span><span style=\"font-weight: bold\"> Reconstruction Loss </span><span style=\"font-weight: bold\"> Activations Sparsity </span><span style=\"font-weight: bold\"> Activations Mean </span>\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L0                  </span>   0.007258  0.000939                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> tc_L1                  </span>   0.158150  0.019397                  N/A                   N/A               N/A \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_pre  </span>   0.009724       N/A             0.000289              0.951862          0.028792 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_attn_out   </span>   0.011408       N/A             0.001011              0.810632          0.031729 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_mid  </span>   0.020527       N/A             0.002456              0.839755          0.055148 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_mlp_out    </span>   0.048316       N/A             0.003464              0.751587          0.136879 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L0_hook_resid_post </span>   0.063353       N/A             0.004084              0.724097          0.180873 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_pre  </span>   0.063736       N/A             0.003755              0.723123          0.183046 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_attn_out   </span>   0.127955       N/A             0.002598              0.801685          0.382557 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_mid  </span>   0.178002       N/A             0.006557              0.656546          0.523206 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_mlp_out    </span>   0.421613       N/A             0.018637              0.671930          1.229785 \n",
       "<span style=\"color: #008080; text-decoration-color: #008080\"> sae_L1_hook_resid_post </span>   0.506364       N/A             0.015226              0.628891          1.498834 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                       Summary of Sparsifier WandB Metrics                                        \u001b[0m\n",
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mIdentifier            \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mTotal Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mMse Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mReconstruction Loss\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Sparsity\u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mActivations Mean\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L0                 \u001b[0m\u001b[36m \u001b[0m   0.007258  0.000939                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36mtc_L1                 \u001b[0m\u001b[36m \u001b[0m   0.158150  0.019397                  N/A                   N/A               N/A \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.009724       N/A             0.000289              0.951862          0.028792 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.011408       N/A             0.001011              0.810632          0.031729 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.020527       N/A             0.002456              0.839755          0.055148 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.048316       N/A             0.003464              0.751587          0.136879 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L0_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.063353       N/A             0.004084              0.724097          0.180873 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_pre \u001b[0m\u001b[36m \u001b[0m   0.063736       N/A             0.003755              0.723123          0.183046 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_attn_out  \u001b[0m\u001b[36m \u001b[0m   0.127955       N/A             0.002598              0.801685          0.382557 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_mid \u001b[0m\u001b[36m \u001b[0m   0.178002       N/A             0.006557              0.656546          0.523206 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_mlp_out   \u001b[0m\u001b[36m \u001b[0m   0.421613       N/A             0.018637              0.671930          1.229785 \n",
       "\u001b[36m \u001b[0m\u001b[36msae_L1_hook_resid_post\u001b[0m\u001b[36m \u001b[0m   0.506364       N/A             0.015226              0.628891          1.498834 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [07:07, 23.39it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35fa4e0c6804110aeac2e190b2369e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.013 MB of 0.013 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>sae_L0_hook_attn_out/activations_mean</td><td></td></tr><tr><td>sae_L0_hook_attn_out/activations_sparsity</td><td></td></tr><tr><td>sae_L0_hook_attn_out/activations_std</td><td></td></tr><tr><td>sae_L0_hook_attn_out/decoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_attn_out/encoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_attn_out/learning_rate</td><td></td></tr><tr><td>sae_L0_hook_attn_out/reconstruction_loss</td><td></td></tr><tr><td>sae_L0_hook_attn_out/sparsity_loss</td><td></td></tr><tr><td>sae_L0_hook_attn_out/total_loss</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/activations_mean</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/activations_sparsity</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/activations_std</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/decoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/encoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/learning_rate</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/reconstruction_loss</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/sparsity_loss</td><td></td></tr><tr><td>sae_L0_hook_mlp_out/total_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/activations_mean</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/activations_sparsity</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/activations_std</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/decoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/encoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/learning_rate</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/reconstruction_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/sparsity_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_mid/total_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_post/activations_mean</td><td></td></tr><tr><td>sae_L0_hook_resid_post/activations_sparsity</td><td></td></tr><tr><td>sae_L0_hook_resid_post/activations_std</td><td></td></tr><tr><td>sae_L0_hook_resid_post/decoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_resid_post/encoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_resid_post/learning_rate</td><td></td></tr><tr><td>sae_L0_hook_resid_post/reconstruction_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_post/sparsity_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_post/total_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/activations_mean</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/activations_sparsity</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/activations_std</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/decoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/encoder_weight_norm</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/learning_rate</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/reconstruction_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/sparsity_loss</td><td></td></tr><tr><td>sae_L0_hook_resid_pre/total_loss</td><td></td></tr><tr><td>sae_L1_hook_attn_out/activations_mean</td><td></td></tr><tr><td>sae_L1_hook_attn_out/activations_sparsity</td><td></td></tr><tr><td>sae_L1_hook_attn_out/activations_std</td><td></td></tr><tr><td>sae_L1_hook_attn_out/decoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_attn_out/encoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_attn_out/learning_rate</td><td></td></tr><tr><td>sae_L1_hook_attn_out/reconstruction_loss</td><td></td></tr><tr><td>sae_L1_hook_attn_out/sparsity_loss</td><td></td></tr><tr><td>sae_L1_hook_attn_out/total_loss</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/activations_mean</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/activations_sparsity</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/activations_std</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/decoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/encoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/learning_rate</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/reconstruction_loss</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/sparsity_loss</td><td></td></tr><tr><td>sae_L1_hook_mlp_out/total_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/activations_mean</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/activations_sparsity</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/activations_std</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/decoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/encoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/learning_rate</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/reconstruction_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/sparsity_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_mid/total_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_post/activations_mean</td><td></td></tr><tr><td>sae_L1_hook_resid_post/activations_sparsity</td><td></td></tr><tr><td>sae_L1_hook_resid_post/activations_std</td><td></td></tr><tr><td>sae_L1_hook_resid_post/decoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_resid_post/encoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_resid_post/learning_rate</td><td></td></tr><tr><td>sae_L1_hook_resid_post/reconstruction_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_post/sparsity_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_post/total_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/activations_mean</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/activations_sparsity</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/activations_std</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/decoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/encoder_weight_norm</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/learning_rate</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/reconstruction_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/sparsity_loss</td><td></td></tr><tr><td>sae_L1_hook_resid_pre/total_loss</td><td></td></tr><tr><td>tc_L0/W_dec_norm</td><td></td></tr><tr><td>tc_L0/W_enc_norm</td><td></td></tr><tr><td>tc_L0/hidden_activations_mean</td><td></td></tr><tr><td>tc_L0/hidden_activations_sparsity</td><td></td></tr><tr><td>tc_L0/hidden_activations_std</td><td></td></tr><tr><td>tc_L0/l1_loss</td><td></td></tr><tr><td>tc_L0/learning_rate</td><td></td></tr><tr><td>tc_L0/mse_loss</td><td></td></tr><tr><td>tc_L0/total_loss</td><td></td></tr><tr><td>tc_L1/W_dec_norm</td><td></td></tr><tr><td>tc_L1/W_enc_norm</td><td></td></tr><tr><td>tc_L1/hidden_activations_mean</td><td></td></tr><tr><td>tc_L1/hidden_activations_sparsity</td><td></td></tr><tr><td>tc_L1/hidden_activations_std</td><td></td></tr><tr><td>tc_L1/l1_loss</td><td></td></tr><tr><td>tc_L1/learning_rate</td><td></td></tr><tr><td>tc_L1/mse_loss</td><td></td></tr><tr><td>tc_L1/total_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>sae_L0_hook_attn_out/activations_mean</td><td>0.03173</td></tr><tr><td>sae_L0_hook_attn_out/activations_sparsity</td><td>0.81063</td></tr><tr><td>sae_L0_hook_attn_out/activations_std</td><td>0.11734</td></tr><tr><td>sae_L0_hook_attn_out/decoder_weight_norm</td><td>7.99991</td></tr><tr><td>sae_L0_hook_attn_out/encoder_weight_norm</td><td>8.38204</td></tr><tr><td>sae_L0_hook_attn_out/learning_rate</td><td>0.005</td></tr><tr><td>sae_L0_hook_attn_out/reconstruction_loss</td><td>0.00101</td></tr><tr><td>sae_L0_hook_attn_out/sparsity_loss</td><td>0.0104</td></tr><tr><td>sae_L0_hook_attn_out/total_loss</td><td>0.01141</td></tr><tr><td>sae_L0_hook_mlp_out/activations_mean</td><td>0.13688</td></tr><tr><td>sae_L0_hook_mlp_out/activations_sparsity</td><td>0.75159</td></tr><tr><td>sae_L0_hook_mlp_out/activations_std</td><td>0.51786</td></tr><tr><td>sae_L0_hook_mlp_out/decoder_weight_norm</td><td>7.99969</td></tr><tr><td>sae_L0_hook_mlp_out/encoder_weight_norm</td><td>8.16814</td></tr><tr><td>sae_L0_hook_mlp_out/learning_rate</td><td>0.005</td></tr><tr><td>sae_L0_hook_mlp_out/reconstruction_loss</td><td>0.00346</td></tr><tr><td>sae_L0_hook_mlp_out/sparsity_loss</td><td>0.04485</td></tr><tr><td>sae_L0_hook_mlp_out/total_loss</td><td>0.04832</td></tr><tr><td>sae_L0_hook_resid_mid/activations_mean</td><td>0.05515</td></tr><tr><td>sae_L0_hook_resid_mid/activations_sparsity</td><td>0.83976</td></tr><tr><td>sae_L0_hook_resid_mid/activations_std</td><td>0.2009</td></tr><tr><td>sae_L0_hook_resid_mid/decoder_weight_norm</td><td>8.0002</td></tr><tr><td>sae_L0_hook_resid_mid/encoder_weight_norm</td><td>11.78357</td></tr><tr><td>sae_L0_hook_resid_mid/learning_rate</td><td>0.005</td></tr><tr><td>sae_L0_hook_resid_mid/reconstruction_loss</td><td>0.00246</td></tr><tr><td>sae_L0_hook_resid_mid/sparsity_loss</td><td>0.01807</td></tr><tr><td>sae_L0_hook_resid_mid/total_loss</td><td>0.02053</td></tr><tr><td>sae_L0_hook_resid_post/activations_mean</td><td>0.18087</td></tr><tr><td>sae_L0_hook_resid_post/activations_sparsity</td><td>0.7241</td></tr><tr><td>sae_L0_hook_resid_post/activations_std</td><td>0.68999</td></tr><tr><td>sae_L0_hook_resid_post/decoder_weight_norm</td><td>7.99958</td></tr><tr><td>sae_L0_hook_resid_post/encoder_weight_norm</td><td>7.81591</td></tr><tr><td>sae_L0_hook_resid_post/learning_rate</td><td>0.005</td></tr><tr><td>sae_L0_hook_resid_post/reconstruction_loss</td><td>0.00408</td></tr><tr><td>sae_L0_hook_resid_post/sparsity_loss</td><td>0.05927</td></tr><tr><td>sae_L0_hook_resid_post/total_loss</td><td>0.06335</td></tr><tr><td>sae_L0_hook_resid_pre/activations_mean</td><td>0.02879</td></tr><tr><td>sae_L0_hook_resid_pre/activations_sparsity</td><td>0.95186</td></tr><tr><td>sae_L0_hook_resid_pre/activations_std</td><td>0.16155</td></tr><tr><td>sae_L0_hook_resid_pre/decoder_weight_norm</td><td>7.9999</td></tr><tr><td>sae_L0_hook_resid_pre/encoder_weight_norm</td><td>18.35226</td></tr><tr><td>sae_L0_hook_resid_pre/learning_rate</td><td>0.005</td></tr><tr><td>sae_L0_hook_resid_pre/reconstruction_loss</td><td>0.00029</td></tr><tr><td>sae_L0_hook_resid_pre/sparsity_loss</td><td>0.00943</td></tr><tr><td>sae_L0_hook_resid_pre/total_loss</td><td>0.00972</td></tr><tr><td>sae_L1_hook_attn_out/activations_mean</td><td>0.38256</td></tr><tr><td>sae_L1_hook_attn_out/activations_sparsity</td><td>0.80168</td></tr><tr><td>sae_L1_hook_attn_out/activations_std</td><td>1.56482</td></tr><tr><td>sae_L1_hook_attn_out/decoder_weight_norm</td><td>7.99964</td></tr><tr><td>sae_L1_hook_attn_out/encoder_weight_norm</td><td>5.94368</td></tr><tr><td>sae_L1_hook_attn_out/learning_rate</td><td>0.005</td></tr><tr><td>sae_L1_hook_attn_out/reconstruction_loss</td><td>0.0026</td></tr><tr><td>sae_L1_hook_attn_out/sparsity_loss</td><td>0.12536</td></tr><tr><td>sae_L1_hook_attn_out/total_loss</td><td>0.12795</td></tr><tr><td>sae_L1_hook_mlp_out/activations_mean</td><td>1.22978</td></tr><tr><td>sae_L1_hook_mlp_out/activations_sparsity</td><td>0.67193</td></tr><tr><td>sae_L1_hook_mlp_out/activations_std</td><td>5.52362</td></tr><tr><td>sae_L1_hook_mlp_out/decoder_weight_norm</td><td>7.99976</td></tr><tr><td>sae_L1_hook_mlp_out/encoder_weight_norm</td><td>5.50026</td></tr><tr><td>sae_L1_hook_mlp_out/learning_rate</td><td>0.005</td></tr><tr><td>sae_L1_hook_mlp_out/reconstruction_loss</td><td>0.01864</td></tr><tr><td>sae_L1_hook_mlp_out/sparsity_loss</td><td>0.40298</td></tr><tr><td>sae_L1_hook_mlp_out/total_loss</td><td>0.42161</td></tr><tr><td>sae_L1_hook_resid_mid/activations_mean</td><td>0.52321</td></tr><tr><td>sae_L1_hook_resid_mid/activations_sparsity</td><td>0.65655</td></tr><tr><td>sae_L1_hook_resid_mid/activations_std</td><td>1.71441</td></tr><tr><td>sae_L1_hook_resid_mid/decoder_weight_norm</td><td>7.99985</td></tr><tr><td>sae_L1_hook_resid_mid/encoder_weight_norm</td><td>6.6338</td></tr><tr><td>sae_L1_hook_resid_mid/learning_rate</td><td>0.005</td></tr><tr><td>sae_L1_hook_resid_mid/reconstruction_loss</td><td>0.00656</td></tr><tr><td>sae_L1_hook_resid_mid/sparsity_loss</td><td>0.17144</td></tr><tr><td>sae_L1_hook_resid_mid/total_loss</td><td>0.178</td></tr><tr><td>sae_L1_hook_resid_post/activations_mean</td><td>1.49883</td></tr><tr><td>sae_L1_hook_resid_post/activations_sparsity</td><td>0.62889</td></tr><tr><td>sae_L1_hook_resid_post/activations_std</td><td>5.48437</td></tr><tr><td>sae_L1_hook_resid_post/decoder_weight_norm</td><td>7.99964</td></tr><tr><td>sae_L1_hook_resid_post/encoder_weight_norm</td><td>5.34977</td></tr><tr><td>sae_L1_hook_resid_post/learning_rate</td><td>0.005</td></tr><tr><td>sae_L1_hook_resid_post/reconstruction_loss</td><td>0.01523</td></tr><tr><td>sae_L1_hook_resid_post/sparsity_loss</td><td>0.49114</td></tr><tr><td>sae_L1_hook_resid_post/total_loss</td><td>0.50636</td></tr><tr><td>sae_L1_hook_resid_pre/activations_mean</td><td>0.18305</td></tr><tr><td>sae_L1_hook_resid_pre/activations_sparsity</td><td>0.72312</td></tr><tr><td>sae_L1_hook_resid_pre/activations_std</td><td>0.68252</td></tr><tr><td>sae_L1_hook_resid_pre/decoder_weight_norm</td><td>7.99985</td></tr><tr><td>sae_L1_hook_resid_pre/encoder_weight_norm</td><td>7.19613</td></tr><tr><td>sae_L1_hook_resid_pre/learning_rate</td><td>0.005</td></tr><tr><td>sae_L1_hook_resid_pre/reconstruction_loss</td><td>0.00376</td></tr><tr><td>sae_L1_hook_resid_pre/sparsity_loss</td><td>0.05998</td></tr><tr><td>sae_L1_hook_resid_pre/total_loss</td><td>0.06374</td></tr><tr><td>tc_L0/W_dec_norm</td><td>102.52538</td></tr><tr><td>tc_L0/W_enc_norm</td><td>5.81078</td></tr><tr><td>tc_L0/hidden_activations_mean</td><td>0.0006</td></tr><tr><td>tc_L0/hidden_activations_sparsity</td><td>0.9879</td></tr><tr><td>tc_L0/hidden_activations_std</td><td>0.01005</td></tr><tr><td>tc_L0/l1_loss</td><td>0.00632</td></tr><tr><td>tc_L0/learning_rate</td><td>0.001</td></tr><tr><td>tc_L0/mse_loss</td><td>0.00094</td></tr><tr><td>tc_L0/total_loss</td><td>0.00726</td></tr><tr><td>tc_L1/W_dec_norm</td><td>64.08794</td></tr><tr><td>tc_L1/W_enc_norm</td><td>6.18897</td></tr><tr><td>tc_L1/hidden_activations_mean</td><td>0.01323</td></tr><tr><td>tc_L1/hidden_activations_sparsity</td><td>0.98216</td></tr><tr><td>tc_L1/hidden_activations_std</td><td>0.2296</td></tr><tr><td>tc_L1/l1_loss</td><td>0.13875</td></tr><tr><td>tc_L1/learning_rate</td><td>0.001</td></tr><tr><td>tc_L1/mse_loss</td><td>0.0194</td></tr><tr><td>tc_L1/total_loss</td><td>0.15815</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweet-sea-48</strong> at: <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2/runs/jwd4f4bg' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2/runs/jwd4f4bg</a><br/> View project at: <a href='https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2' target=\"_blank\">https://wandb.ai/bronsonschoen-personal-use/toy-problem-hooked-transformer-sae-and-transcoder-v2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240923_165953-jwd4f4bg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note: residual stream norm grows with the length of the residual stream, so we _should_ see\n",
    "#       MSE grow with the length of the residual stream\n",
    "\n",
    "import functools\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_epochs = 10000\n",
    "eval_every_n = 1000\n",
    "\n",
    "# create trainers to handle saes and transcoders\n",
    "transcoder_trainer_per_hook = create_transcoder_trainer_per_hook(model, device, num_epochs)\n",
    "sae_trainer_per_hook = create_sae_trainer_per_hook(\n",
    "    residual_stream_hook_names, model, device, num_epochs\n",
    ")\n",
    "\n",
    "# figure out hook names we need to cache\n",
    "hook_names_to_cache = get_hook_names_to_cache_for_trainers(\n",
    "    transcoder_trainer_per_hook,\n",
    "    sae_trainer_per_hook,\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"toy-problem-hooked-transformer-sae-and-transcoder-v2\",\n",
    ")\n",
    "\n",
    "# NOTE: Statistics are being computed over one particular batch, which is likely noisy\n",
    "#\n",
    "# TODO(bschoen): Add evaluation against the test set\n",
    "#\n",
    "# NOTE: Toy models by their very nature might violate the assumption that real world data is sparse?\n",
    "#\n",
    "# Okay literally when you overfit the shit out of it\n",
    "#  - expansion factor 4\n",
    "#  - lr=1e-3,\n",
    "#  - loss_config=sae.SAELossConfig(l1_coefficient=1e-9),\n",
    "# even `blocks.0.hook_resid_pre` FINALLY results in replacement layer getting 97% accuracy (same as model)\n",
    "# MLP worked well but had dropped down to about 92% (not sure if one vs other, in general should start saving best checkpoint)\n",
    "#\n",
    "# TODO(bschoen): Probably why you want to do resampling / ghost grads / etc\n",
    "#\n",
    "for epoch, batch in tqdm.tqdm(\n",
    "    zip(\n",
    "        range(num_epochs),\n",
    "        itertools.cycle(train_loader),\n",
    "    )\n",
    "):\n",
    "\n",
    "    tokens, target = batch\n",
    "\n",
    "    tokens, target = tokens.to(device), target.to(device)\n",
    "\n",
    "    # run the original model, cache the activations of the relevant hook points\n",
    "    _, cache = model.run_with_cache(\n",
    "        tokens,\n",
    "        names_filter=lambda x: x in hook_names_to_cache,\n",
    "    )\n",
    "\n",
    "    # log every `eval_every_n` epochs, and the last epoch\n",
    "    is_epoch_that_needs_to_log = (epoch % eval_every_n == 0) or (epoch == num_epochs - 1)\n",
    "    epoch_wandb_log_dict = {}\n",
    "\n",
    "    # step sae and transcoder trainers\n",
    "    for trainer in itertools.chain(\n",
    "        transcoder_trainer_per_hook.values(),\n",
    "        sae_trainer_per_hook.values(),\n",
    "    ):\n",
    "\n",
    "        # note: `train_on_cache` already takes care of backpropagation, this is just for logging\n",
    "        trainer_output = trainer.train_on_cache(cache)\n",
    "\n",
    "        if is_epoch_that_needs_to_log:\n",
    "\n",
    "            # print(f\"[{epoch}/{num_epochs}] Logging {trainer.name}...\")\n",
    "\n",
    "            wandb_log_dict = trainer.get_wandb_log_dict(trainer_output)\n",
    "\n",
    "            # collect in a single dict to log, so not spamming wandb with calls\n",
    "            epoch_wandb_log_dict.update(wandb_log_dict)\n",
    "\n",
    "    if is_epoch_that_needs_to_log:\n",
    "\n",
    "        print(f\"[{epoch}/{num_epochs}] Logging...\")\n",
    "        wandb.log(epoch_wandb_log_dict, step=epoch)\n",
    "\n",
    "        print_summary_of_sparsifier_wandb_log_dicts(epoch_wandb_log_dict)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e74b1081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set everything to `eval` mode\n",
    "for trainer in transcoder_trainer_per_hook.values():\n",
    "    trainer.transcoder.eval()\n",
    "\n",
    "for trainer in sae_trainer_per_hook.values():\n",
    "    trainer.sae.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db2999",
   "metadata": {},
   "source": [
    "## Augmented TransformerLens Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45cdb62",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38a3f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def plot_sae_activation_distributions(\n",
    "    original_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    reconstructed_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    sae_activations: Float[torch.Tensor, \"batch pos d_sae\"],\n",
    "    hook_name: str,\n",
    "    num_bins=50,\n",
    "):\n",
    "    original_act = original_act.detach().cpu().numpy().flatten()\n",
    "    reconstructed_act = reconstructed_act.detach().cpu().numpy().flatten()\n",
    "    sae_activations = sae_activations.detach().cpu().numpy().flatten()\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.histplot(original_act, bins=num_bins, color=\"blue\", kde=True, label=\"Original\")\n",
    "    plt.title(f\"{hook_name} - Original Activation Distribution\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.histplot(reconstructed_act, bins=num_bins, color=\"orange\", kde=True, label=\"Reconstructed\")\n",
    "    plt.title(f\"{hook_name} - Reconstructed Activation Distribution\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sns.histplot(sae_activations, bins=num_bins, color=\"green\", kde=True, label=\"SAE Activations\")\n",
    "    plt.title(f\"{hook_name} - SAE Activations Distribution\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sae_activation_differences(\n",
    "    original_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    reconstructed_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    hook_name: str,\n",
    "    sample_idx: int = 0,\n",
    ") -> None:\n",
    "    original = original_act[sample_idx].detach().cpu().numpy()\n",
    "    reconstructed = reconstructed_act[sample_idx].detach().cpu().numpy()\n",
    "    difference = reconstructed - original\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(original, label=\"Original\", color=\"blue\")\n",
    "    plt.title(f\"{hook_name}\\nOriginal Activation (Sample {sample_idx})\")\n",
    "    plt.ylim(-1.1, 1.1)  # Set y-axis range\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(reconstructed, label=\"Reconstructed\", color=\"orange\")\n",
    "    plt.title(f\"{hook_name}\\nReconstructed Activation (Sample {sample_idx})\")\n",
    "    plt.ylim(-1.1, 1.1)  # Set y-axis range\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(difference, label=\"Difference\", color=\"red\")\n",
    "    plt.title(f\"{hook_name}\\nActivation Difference (Sample {sample_idx})\")\n",
    "    plt.ylim(-1.1, 1.1)  # Set y-axis range\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sae_pca(\n",
    "    original_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    reconstructed_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    hook_name: str,\n",
    "    n_components: int = 2,\n",
    ") -> None:\n",
    "    original_flat = original_act.detach().cpu().numpy().reshape(-1, original_act.shape[-1])\n",
    "    reconstructed_flat = (\n",
    "        reconstructed_act.detach().cpu().numpy().reshape(-1, reconstructed_act.shape[-1])\n",
    "    )\n",
    "\n",
    "    pca = PCA(n_components=n_components)\n",
    "    combined = np.vstack((original_flat, reconstructed_flat))\n",
    "    pca.fit(combined)\n",
    "\n",
    "    original_pca = pca.transform(original_flat)\n",
    "    reconstructed_pca = pca.transform(reconstructed_flat)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(original_pca[:, 0], original_pca[:, 1], alpha=0.5, label=\"Original\", s=10)\n",
    "    plt.scatter(\n",
    "        reconstructed_pca[:, 0], reconstructed_pca[:, 1], alpha=0.5, label=\"Reconstructed\", s=10\n",
    "    )\n",
    "    plt.title(f\"{hook_name} - PCA of Activations\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sae_sparsity(\n",
    "    sae_activations: Float[torch.Tensor, \"batch pos d_sae\"],\n",
    "    hook_name: str,\n",
    "    threshold: float = 1e-3,\n",
    ") -> None:\n",
    "    sae_activations = sae_activations.detach().cpu().numpy()\n",
    "    sparsity = np.mean(np.abs(sae_activations) < threshold)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(sae_activations.flatten(), bins=50, color=\"green\", kde=True)\n",
    "    plt.axvline(x=threshold, color=\"red\", linestyle=\"--\", label=f\"Threshold={threshold}\")\n",
    "    plt.title(f\"{hook_name} - SAE Activations Sparsity\\nSparsity Level: {sparsity*100:.2f}%\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_sae_sample_activations(\n",
    "    original_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    reconstructed_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    sae_activations: Float[torch.Tensor, \"batch pos d_sae\"],\n",
    "    hook_name: str,\n",
    "    num_samples: int = 3,\n",
    ") -> None:\n",
    "    num_samples = min(num_samples, original_act.shape[0])\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(original_act[i].detach().cpu().numpy(), label=\"Original\", color=\"blue\")\n",
    "        plt.title(f\"{hook_name}\\nOriginal Activation (Sample {i})\")\n",
    "        # plt.legend()\n",
    "\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(reconstructed_act[i].detach().cpu().numpy(), label=\"Reconstructed\", color=\"orange\")\n",
    "        plt.title(f\"{hook_name}\\nReconstructed Activation (Sample {i})\")\n",
    "        # plt.legend()\n",
    "\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.plot(sae_activations[i].detach().cpu().numpy(), label=\"SAE Activations\", color=\"green\")\n",
    "        plt.title(f\"{hook_name}\\nSAE Activations (Sample {i})\")\n",
    "        # plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_sae_reconstruction_comparisons(\n",
    "    original_act: Float[torch.Tensor, \"batch pos d_model\"],\n",
    "    sae_outputs: sae.SAEOutput,\n",
    "    sae_hook_name: str,\n",
    ") -> None:\n",
    "    plot_sae_activation_distributions(\n",
    "        original_act, sae_outputs.x_reconstructed, sae_outputs.x_sae_activations, sae_hook_name\n",
    "    )\n",
    "    plot_sae_activation_differences(original_act, sae_outputs.x_reconstructed, sae_hook_name)\n",
    "    plot_sae_pca(original_act, sae_outputs.x_reconstructed, sae_hook_name)\n",
    "    plot_sae_sparsity(sae_outputs.x_sae_activations, sae_hook_name)\n",
    "    plot_sae_sample_activations(\n",
    "        original_act, sae_outputs.x_reconstructed, sae_outputs.x_sae_activations, sae_hook_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43f8fbd",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28012e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 0.994140625}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let's get a baseline\n",
    "def compute_accuracy_by_difficulty(\n",
    "    model: tl.HookedTransformer,\n",
    "    tokenizer: tokenizer_utils.Tokenizer,\n",
    "    test_loaders: dict[int, torch.utils.data.DataLoader],\n",
    ") -> dict[int, float]:\n",
    "\n",
    "    test_accuracy_by_difficulty = {}\n",
    "\n",
    "    for difficulty, test_loader in test_loaders.items():\n",
    "\n",
    "        accuracy = evaluate_sequence_accuracy_on_test_batches(\n",
    "            model,\n",
    "            test_loader,\n",
    "            separator_token_id=tokenizer.encode(\"|\")[0],\n",
    "            max_batches=1,\n",
    "        )\n",
    "\n",
    "        test_accuracy_by_difficulty[difficulty] = accuracy\n",
    "\n",
    "    return test_accuracy_by_difficulty\n",
    "\n",
    "\n",
    "# {10: 0.99609375}\n",
    "compute_accuracy_by_difficulty(model, tokenizer, test_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f0b0dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example string: <jmcd|cdjm\n"
     ]
    }
   ],
   "source": [
    "# for debugging, we'll also create example activations we can compare to\n",
    "\n",
    "# create a small (fixed) training set of each difficulty to use for visualization\n",
    "test_example_tokens_per_difficulty: dict[int, Int[torch.Tensor, \"seq\"]] = {}\n",
    "test_example_string_to_cache: dict[str, tl.ActivationCache] = {}\n",
    "\n",
    "for difficulty, test_loader in test_loaders.items():\n",
    "    # grab something from the test batch\n",
    "    x, _ = next(iter(test_loader))\n",
    "    input_tokens = x[0].to(device)\n",
    "\n",
    "    _, cache = model.run_with_cache(input_tokens)\n",
    "\n",
    "    input_tokens_str = tokens_to_string(tokenizer, input_tokens)\n",
    "\n",
    "    print(f\"Example string: {input_tokens_str}\")\n",
    "\n",
    "    test_example_tokens_per_difficulty[difficulty] = input_tokens\n",
    "    test_example_string_to_cache[input_tokens_str] = cache\n",
    "\n",
    "# we can now also use `cache` and `input_tokens_str`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2eabcce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# using `https://github.com/ApolloResearch/e2e_sae/blob/main/e2e_sae/models/transformers.py#L148` for reference\n",
    "\n",
    "# note: the activations are only needed to be stored if we're going to use them later\n",
    "\n",
    "# for now let's just worry about the actual replacement\n",
    "\n",
    "\n",
    "# wrap transcoder class so can easily inject it here\n",
    "class _TranscoderWrapper(nn.Module):\n",
    "    def __init__(self, mlp_transcoder: transcoder.Transcoder) -> None:\n",
    "        super().__init__()\n",
    "        self.mlp_transcoder = mlp_transcoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp_transcoder(x).transcoder_out\n",
    "\n",
    "\n",
    "# assert False, \"Replacing MLP like this makes it impossible to do any other training runs\"\n",
    "\n",
    "# actually go ahead and replace the transcoders\n",
    "#\n",
    "# TODO(bschoen): Hooking the transcoders would make that easier here, probably the SAEs too\n",
    "#\n",
    "for block_index, _ in enumerate(model.blocks):\n",
    "\n",
    "    # get the MLP input and output hook names\n",
    "    mlp_in_hook_name = f\"blocks.{block_index}.hook_resid_mid\"\n",
    "    mlp_out_hook_name = f\"blocks.{block_index}.hook_mlp_out\"\n",
    "\n",
    "    trainer = transcoder_trainer_per_hook[mlp_in_hook_name]\n",
    "\n",
    "    # replace the mlp with the transcoder\n",
    "    model.blocks[block_index].mlp = _TranscoderWrapper(trainer.transcoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d75f74cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 0.9921875}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {10: 0.994140625}\n",
    "compute_accuracy_by_difficulty(model, tokenizer, test_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "574aa01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blocks.0.hook_resid_pre', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post'])\n"
     ]
    }
   ],
   "source": [
    "def compute_reconstructed(x, hook, sae_model):\n",
    "    return sae_model(x).x_reconstructed\n",
    "\n",
    "\n",
    "# now add hooks for the saes\n",
    "sae_hook_fn_per_hook_name = {}\n",
    "\n",
    "for hook_name, trainer in sae_trainer_per_hook.items():\n",
    "\n",
    "    # are you fucking kidding me this was it??? lambdas binding in scope\n",
    "    sae_hook_fn_per_hook_name[hook_name] = functools.partial(\n",
    "        compute_reconstructed, sae_model=trainer.sae\n",
    "    )\n",
    "\n",
    "print(sae_hook_fn_per_hook_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7ee83e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy only replacing: blocks.0.hook_resid_pre: {10: 0.984375}\n",
      "Accuracy only replacing: blocks.0.hook_attn_out: {10: 0.865234375}\n",
      "Accuracy only replacing: blocks.0.hook_resid_mid: {10: 0.814453125}\n",
      "Accuracy only replacing: blocks.0.hook_mlp_out: {10: 0.982421875}\n",
      "Accuracy only replacing: blocks.0.hook_resid_post: {10: 0.9921875}\n",
      "Accuracy only replacing: blocks.1.hook_resid_pre: {10: 0.984375}\n",
      "Accuracy only replacing: blocks.1.hook_attn_out: {10: 0.998046875}\n",
      "Accuracy only replacing: blocks.1.hook_resid_mid: {10: 0.9921875}\n",
      "Accuracy only replacing: blocks.1.hook_mlp_out: {10: 0.994140625}\n",
      "Accuracy only replacing: blocks.1.hook_resid_post: {10: 0.994140625}\n"
     ]
    }
   ],
   "source": [
    "for hook_name, hook_fn in sae_hook_fn_per_hook_name.items():\n",
    "\n",
    "    with model.hooks(fwd_hooks=[(hook_name, hook_fn)]):\n",
    "\n",
    "        test_accuracy_by_difficulty = compute_accuracy_by_difficulty(model, tokenizer, test_loaders)\n",
    "\n",
    "        print(f\"Accuracy only replacing: {hook_name}: {test_accuracy_by_difficulty}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6c8b406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using input string: <jmcd|cdjm\n",
      "original_act: torch.Size([1, 10, 16])\n",
      "sae_outputs.x_reconstructed: torch.Size([1, 10, 16])\n",
      "sae_outputs.x_sae_activations: torch.Size([1, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "from gpt_from_scratch import sae\n",
    "\n",
    "for input_string, cache in test_example_string_to_cache.items():\n",
    "    print(f\"Using input string: {input_string}\")\n",
    "    break\n",
    "\n",
    "\n",
    "input_tokens = tokenize_string(tokenizer, input_string)\n",
    "\n",
    "# inject the SAE\n",
    "sae_hook_name = \"blocks.0.hook_resid_post\"\n",
    "\n",
    "original_act = cache[sae_hook_name]\n",
    "\n",
    "sae_model = sae_trainer_per_hook[sae_hook_name].sae\n",
    "\n",
    "sae_outputs = sae_model(original_act)\n",
    "\n",
    "print(f\"original_act: {original_act.shape}\")\n",
    "print(f\"sae_outputs.x_reconstructed: {sae_outputs.x_reconstructed.shape}\")\n",
    "print(f\"sae_outputs.x_sae_activations: {sae_outputs.x_sae_activations.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf58041",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sae_reconstruction_comparisons(original_act, sae_outputs, sae_hook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3193230b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd767af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d74a223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd3902e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d85270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ce608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b9327f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11458085",
   "metadata": {},
   "source": [
    "### Top Activating Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5ac5c74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll focus first on finding top activating examples for a specific feature\n",
    "\n",
    "# Okay so we don't have to story huge activation tensors, by definition these are sparse\n",
    "\n",
    "# Do we cutoff at top N?\n",
    "\n",
    "# Essentially we want:\n",
    "#   For each sample:\n",
    "#       For each SAE / transcoder\n",
    "#           Take top N feature scores (store their value and index)\n",
    "from gpt_from_scratch import sae\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class ActivationStore:\n",
    "    \"\"\"\n",
    "    Useful with `functools.partial` to store a value that is updated by a hook.\n",
    "\n",
    "    Note:\n",
    "        Note that we only store the `top_k` here. This avoids use having to store absolutely\n",
    "        massive tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    activation_indices: Float[torch.Tensor, \"batch seq top_k\"] | None = None\n",
    "    activation_values: Float[torch.Tensor, \"batch seq top_k\"] | None = None\n",
    "\n",
    "\n",
    "def compute_and_store_sae_activations_hook(\n",
    "    x: Float[torch.Tensor, \"batch seq d_model\"],\n",
    "    hook: tl.hook_points.HookPoint,\n",
    "    sae_model: sae.SAE,\n",
    "    activations_store: ActivationStore,\n",
    ") -> Float[torch.Tensor, \"batch seq d_model\"]:\n",
    "    \"\"\"\n",
    "    We structure the storage as a mutable reference, that way we can bind it in `partial`, and\n",
    "    have a hook function fill it out.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    sae_outputs = sae_model(x)\n",
    "\n",
    "    # compute and store the top k activations\n",
    "    values, indices = torch.topk(\n",
    "        sae_outputs.x_sae_activations,\n",
    "        k=5,\n",
    "        dim=-1,\n",
    "        largest=True,\n",
    "        sorted=True,\n",
    "    )\n",
    "\n",
    "    activations_store.activation_values = values\n",
    "    activations_store.activation_indices = indices\n",
    "\n",
    "    return sae_outputs.x_reconstructed\n",
    "\n",
    "\n",
    "activations_store = ActivationStore()\n",
    "\n",
    "# inject the SAE\n",
    "#\n",
    "# choosing this based on our investigation with logit diff direction showing it moves through here\n",
    "sae_hook_name = \"blocks.0.hook_resid_pre\"\n",
    "sae_model = sae_trainer_per_hook[sae_hook_name].sae\n",
    "\n",
    "input_string = \"<cbad|ab\"\n",
    "input_string_tokens = tokenize_string(tokenizer, input_string)\n",
    "\n",
    "model.run_with_hooks(\n",
    "    input_string_tokens,\n",
    "    fwd_hooks=[\n",
    "        (\n",
    "            sae_hook_name,\n",
    "            functools.partial(\n",
    "                compute_and_store_sae_activations_hook,\n",
    "                sae_model=sae_model,\n",
    "                activations_store=activations_store,\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "assert activations_store.activation_values is not None\n",
    "assert activations_store.activation_indices is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a9ebf137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_heatmap_sae_activations(\n",
    "    activation: Float[torch.Tensor, \"batch seq d_sae\"],\n",
    "    title: str = \"Heatmap of Sparse Autoencoder Activations\",\n",
    "    tokens: list[str] | None = None,\n",
    ") -> None:\n",
    "\n",
    "    activations_np = activation[0].detach().cpu().numpy().T\n",
    "\n",
    "    # Plotting with Seaborn\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    ax = sns.heatmap(\n",
    "        activations_np,\n",
    "        cmap=\"Reds\",\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"lightgrey\",\n",
    "        cbar_kws={\"label\": \"Activation Strength\"},\n",
    "        mask=np.abs(activations_np) < 1e-6,\n",
    "        square=False,\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Hidden Dimension\")\n",
    "    plt.xlabel(\"Sequence Step\")\n",
    "    plt.yticks(ticks=np.arange(0, 64, 8) + 0.5, labels=np.arange(0, 64, 8), rotation=45)\n",
    "    plt.xticks(ticks=np.arange(0, 9, 1) + 0.5, labels=np.arange(1, 10, 1), rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_heatmap_sae_activations(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8020fcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "714it [03:51,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# now let's go through and do this for all the batches in our SAE\n",
    "import collections\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class TopKActivations:\n",
    "    activation_indices: Float[torch.Tensor, \"seq top_k\"]\n",
    "    activation_values: Float[torch.Tensor, \"seq top_k\"]\n",
    "\n",
    "\n",
    "sae_hook_name = \"blocks.0.hook_resid_pre\"\n",
    "sae_model = sae_trainer_per_hook[sae_hook_name].sae\n",
    "\n",
    "# keep the separator token around\n",
    "separator_token_id = tokenizer.encode(\"|\")[0]\n",
    "\n",
    "# TODO(bschoen): Super space inefficient\n",
    "top_k_activations_by_token_string_and_hook_name: dict[str, dict[str, TopKActivations]] = (\n",
    "    collections.defaultdict(lambda: collections.defaultdict(TopKActivations))\n",
    ")\n",
    "\n",
    "for batch_index, batch in tqdm.tqdm(enumerate(train_loader)):\n",
    "\n",
    "    tokens, _ = batch\n",
    "\n",
    "    tokens: Float[torch.Tensor, \"batch seq\"] = tokens.to(device)\n",
    "\n",
    "    # note: all sequences in a batch are the same length, so we just take the first batch\n",
    "    #\n",
    "    # look at the last token, if it's the separator token, skip to the next batch\n",
    "    #\n",
    "    # NOTE: This doesn't yet support multiple separators\n",
    "    while tokens[0, -1] != separator_token_id:\n",
    "\n",
    "        # otherwise, slice off the last token and run on the shortened string\n",
    "        tokens = tokens[:, :-1]\n",
    "\n",
    "        activations_store = ActivationStore()\n",
    "\n",
    "        # run without gradient\n",
    "        # run without return type\n",
    "        with torch.no_grad():\n",
    "            model.run_with_hooks(\n",
    "                tokens,\n",
    "                fwd_hooks=[\n",
    "                    (\n",
    "                        sae_hook_name,\n",
    "                        functools.partial(\n",
    "                            compute_and_store_sae_activations_hook,\n",
    "                            sae_model=sae_model,\n",
    "                            activations_store=activations_store,\n",
    "                        ),\n",
    "                    )\n",
    "                ],\n",
    "                return_type=None,\n",
    "            )\n",
    "\n",
    "        # store everything nicely as strings, this not being vectorized is probably brutal\n",
    "        for i in range(tokens.shape[0]):\n",
    "            token_string = tokens_to_string(tokenizer, tokens[i])\n",
    "\n",
    "            topk_activations = TopKActivations(\n",
    "                activation_indices=activations_store.activation_indices[i],\n",
    "                activation_values=activations_store.activation_values[i],\n",
    "            )\n",
    "\n",
    "            top_k_activations_by_token_string_and_hook_name[token_string][\n",
    "                sae_hook_name\n",
    "            ] = topk_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d888d68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(top_k_activations_by_token_string_and_hook_name)=2048\n",
      "Token string: <kswh|hks\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <tuvc|ctu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <oosx|oos\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <emwd|dem\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lmke|ekl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xyep|epx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <eomm|emm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ugbq|bgq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <foxi|fio\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lqsh|hlq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <tbjy|bjt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fhfn|ffh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qsej|ejq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <phww|hpw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <duvh|dhu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <enez|een\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dgzz|dgz\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qugg|ggq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mplk|klm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xnyk|knx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dsir|dir\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xaqs|aqs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vwhe|ehv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ggnj|ggj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wqan|anq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <virm|imr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cbau|abc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fpql|flp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bjfz|bfj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <exrj|ejr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zgoz|goz\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hamd|adh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gmvs|gms\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rpno|nop\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nzzt|ntz\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bvkq|bkq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gdks|dgk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bwoj|bjo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <orly|lor\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <aodi|adi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uiwu|iuu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mxhz|hmx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wisc|cis\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xdas|ads\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <irtj|ijr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dooq|doo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qgzb|bgq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lavl|all\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <afpz|afp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kjbz|bjk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ftzt|ftt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lpkd|dkl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nbod|bdn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pbxv|bpv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <negl|egl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ooxh|hoo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <exdt|det\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vbia|abi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <llkn|kll\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uwek|eku\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ujbo|bjo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xllg|gll\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pkeq|ekp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nzhe|ehn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hekc|ceh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bvwx|bvw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lfyt|flt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dfrt|dfr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wvnb|bnv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fewy|efw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <niur|inr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ppnh|hnp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uhbp|bhp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jwur|jru\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vyqy|qvy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bkgi|bgi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bmww|bmw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <oyrz|ory\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lfvo|flo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <stwb|bst\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dxdq|ddq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lnnn|lnn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ffse|eff\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uxca|acu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cekr|cek\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <suyp|psu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <znnh|hnn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vstg|gst\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ydte|det\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cxzr|crx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rtyt|rtt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qtxj|jqt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kgci|cgi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <acki|aci\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gwfi|fgi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pdfj|dfj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mrxf|fmr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <esae|aee\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wdbb|bbd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <raao|aao\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <blao|abl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <iicl|cii\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lozy|loy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yrqs|qrs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ovsm|mos\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xzke|ekx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gdvg|dgg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jqxp|jpq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yewr|erw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qmkg|gkm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wkdc|cdk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <azra|aar\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zkod|dko\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fgrz|fgr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <izqa|aiq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <suen|ens\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <khxc|chk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pgcc|ccg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zjuj|jju\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <urzi|iru\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ooyo|ooo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <owfn|fno\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zael|ael\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <buxa|abu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zdwl|dlw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <knhd|dhk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ejti|eij\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rmhq|hmq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nmqa|amn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <opcn|cno\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <knjl|jkl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <weoi|eio\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <whfz|fhw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yztr|rty\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vyzs|svy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <sapp|app\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <irll|ill\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uadc|acd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pivw|ipv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jpxw|jpw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ffdg|dff\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gcqh|cgh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rpur|prr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qtlu|lqt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mkfo|fkm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hcsl|chl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jfvs|fjs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xgtn|gnt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yiwi|iiw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dljx|djl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ofmf|ffm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qnhl|hln\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nxjf|fjn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jqcf|cfj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cbcq|bcc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qwhn|hnq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <tcsj|cjs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mibb|bbi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yngt|gnt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lpyr|lpr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <glca|acg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <updc|cdp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <btqh|bhq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kbku|bkk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hskm|hkm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nvfn|fnn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qlkd|dkl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <htuo|hot\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <tkua|akt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <orpz|opr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xumg|gmu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fimx|fim\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bjdv|bdj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mfir|fim\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <knak|akk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zzur|ruz\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ksfm|fkm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mkmp|kmm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rmsm|mmr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <folb|bfl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mddw|ddm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dqrx|dqr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lvuv|luv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ixem|eim\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uoin|ino\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <irkf|fik\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <goqp|gop\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bktp|bkp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <djpw|djp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lrfy|flr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yuth|htu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dbso|bdo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mzkw|kmw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <tdzm|dmt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ivbr|bir\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uksh|hks\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gquu|gqu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <umsi|ims\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qinj|ijn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <slpx|lps\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ekyb|bek\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ffph|ffh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <godu|dgo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <heva|aeh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qlld|dll\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <anpk|akn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <snsy|nss\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vmbx|bmv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kgsb|bgk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pxcj|cjp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uovl|lou\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <oimu|imo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mkmx|kmm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <guga|agg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kcne|cek\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mtqs|mqs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dluc|cdl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rzow|orw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cjps|cjp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qnnp|nnp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ptpw|ppt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <oakq|ako\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pzjw|jpw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qvgt|gqt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nqvt|nqt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ssxf|fss\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dwlk|dkl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <quyc|cqu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bifg|bfg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wpzc|cpw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gyxa|agx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zwzc|cwz\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bdii|bdi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xhsg|ghs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ecoa|ace\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ygcd|cdg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vbnw|bnv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <iixc|cii\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ruqg|gqr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uckg|cgk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mnre|emn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dmvi|dim\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ookf|fko\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ylxe|elx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xsef|efs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dvse|des\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <btrl|blr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zmfj|fjm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <opnl|lno\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ufgm|fgm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nfnk|fkn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mcsk|ckm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fuag|afg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vlak|akl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bqho|bho\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <sxyt|stx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zkji|ijk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ccta|acc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fzcp|cfp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <sqkm|kmq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lfur|flr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jhbz|bhj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cevy|cev\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fmwz|fmw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <aote|aeo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hydv|dhv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hbkj|bhj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <sdcu|cds\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lzcw|clw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dgof|dfg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rzvu|ruv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ezyq|eqy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ygre|egr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bpxo|bop\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gabu|abg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hkmo|hkm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ehcf|cef\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jeng|egj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <iupr|ipr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ygbs|bgs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <onbt|bno\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mfka|afk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pund|dnp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ifab|abf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <awdb|abd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jgtq|gjq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kyrt|krt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wyrp|prw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <krlr|klr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <blww|blw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rcpr|cpr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <olvf|flo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ddeo|dde\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jqag|agj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lcfo|cfl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <aguu|agu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <igay|agi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <grmz|gmr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gssg|ggs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mczz|cmz\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <znfo|fno\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kzma|akm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hrml|hlm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <tnuf|fnt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vadi|adi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <iaga|aag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rxqe|eqr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ombn|bmn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nqku|knq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uaor|aor\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ijxz|ijx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qhsp|hpq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mdyy|dmy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xbia|abi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <feta|aef\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <whtp|hpt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zccr|ccr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jaiy|aij\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zzsc|csz\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fxzu|fux\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yiip|iip\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pfil|fil\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hvpu|hpu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pglr|glp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kvlh|hkl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mmfi|fim\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <aqfn|afn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zwjd|djw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ltwh|hlt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <scax|acs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nlra|aln\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jqds|djq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nzoz|noz\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mqhw|hmq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vgoy|gov\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mpvj|jmp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ecac|acc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qllk|kll\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uvsy|suv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wsmu|msu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pqdx|dpq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <upkf|fkp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mult|lmt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dmqc|cdm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <utkv|ktu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pcye|cep\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nlgd|dgl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lkbx|bkl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gdaw|adg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ivdm|dim\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cumw|cmu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jazp|ajp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hfjf|ffh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dbuj|bdj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <sdoa|ado\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ulwk|klu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kbba|abb\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <esmi|eim\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hmgn|ghm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cpxw|cpw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <sivg|gis\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <atvr|art\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qfxn|fnq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <janf|afj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cwfg|cfg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qkzf|fkq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <umgq|gmq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rotb|bor\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <phhj|hhj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xlhi|hil\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gnxt|gnt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vvhl|hlv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wmtu|mtu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <oitt|iot\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ujao|ajo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cjxa|acj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bnol|bln\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rgzx|grx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gbhi|bgh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yagd|adg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <maxs|ams\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nblr|bln\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <irgf|fgi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <garl|agl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <viot|iot\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yzbi|biy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ffcp|cff\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <onkj|jkn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <frgy|fgr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nyed|den\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qblu|blq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kkcw|ckk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lmts|lms\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ofgh|fgh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pppq|ppp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wzsf|fsw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nflb|bfl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jsvs|jss\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <drfc|cdf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <bjyy|bjy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ztuf|ftu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rjvl|jlr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qnjw|jnq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mlit|ilm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <awmf|afm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <dpwv|dpv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <clkd|cdk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pomj|jmo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ngri|gin\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yhto|hot\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cjvx|cjv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xzys|sxy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <byne|ben\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rcdo|cdo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <aiep|aei\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wewf|efw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vvkn|knv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xzdq|dqx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kudd|ddk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pgnf|fgn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qjtz|jqt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hiwt|hit\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ghbr|bgh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uwqq|qqu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mbfw|bfm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <uzmy|muy\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <znxn|nnx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jpbi|bij\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <aeye|aee\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gqwt|gqt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rgiz|gir\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <tkro|kor\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mmwe|emm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ghhs|ghh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <depz|dep\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <epwc|cep\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jrod|djo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <sxdi|dis\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jkup|jkp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ijng|gij\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lfzi|fil\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pcdm|cdm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xrfg|fgr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pfgv|fgp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rveo|eor\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ecgb|bce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <axgv|agv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zmts|mst\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <komj|jkm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <scjf|cfj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rpuw|pru\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <crnz|cnr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <txdt|dtt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yger|egr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jnly|jln\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hreo|eho\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gyps|gps\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <lfsj|fjl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <omsv|mos\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <aryl|alr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <mxmj|jmm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <omby|bmo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ttqa|aqt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <adqw|adq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ybmw|bmw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nenl|eln\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ogob|bgo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zvic|civ\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vtfg|fgt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ewwx|eww\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xkdm|dkm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <meqo|emo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yfbr|bfr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vdgm|dgm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kisn|ikn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zsdb|bds\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zrxd|drx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ugua|agu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rqgm|gmq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pthy|hpt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <vymd|dmv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <fynt|fnt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <zemt|emt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <njac|acj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ptgv|gpt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <brpi|bip\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <wyvi|ivw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hnww|hnw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <qgvu|gqu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nytp|npt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <ijce|cei\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rkpu|kpr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pwgp|gpp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <jtfd|dfj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <oqxc|coq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <eihe|eeh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <xjja|ajj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <curc|ccr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <gcsy|cgs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <rmjy|jmr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <cthh|chh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <djsw|djs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yzkh|hky\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <yjcr|cjr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <hkme|ehk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <aype|aep\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <naoc|acn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <eixs|eis\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <topx|opt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <nzmn|mnn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <tajf|afj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <pjdd|ddj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([9, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([9, 5])\n",
      "Token string: <kswh|hk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <tuvc|ct\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <oosx|oo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <emwd|de\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lmke|ek\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xyep|ep\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <eomm|em\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ugbq|bg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <foxi|fi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lqsh|hl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <tbjy|bj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fhfn|ff\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qsej|ej\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <phww|hp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <duvh|dh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <enez|ee\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dgzz|dg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qugg|gg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mplk|kl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xnyk|kn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dsir|di\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xaqs|aq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vwhe|eh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ggnj|gg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wqan|an\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <virm|im\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cbau|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fpql|fl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bjfz|bf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <exrj|ej\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zgoz|go\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hamd|ad\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gmvs|gm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rpno|no\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nzzt|nt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bvkq|bk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gdks|dg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bwoj|bj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <orly|lo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <aodi|ad\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uiwu|iu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mxhz|hm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wisc|ci\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xdas|ad\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <irtj|ij\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dooq|do\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qgzb|bg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lavl|al\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <afpz|af\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kjbz|bj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ftzt|ft\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lpkd|dk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nbod|bd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pbxv|bp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <negl|eg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ooxh|ho\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <exdt|de\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vbia|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <llkn|kl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uwek|ek\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ujbo|bj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xllg|gl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pkeq|ek\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nzhe|eh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hekc|ce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bvwx|bv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lfyt|fl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dfrt|df\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wvnb|bn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fewy|ef\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <niur|in\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ppnh|hn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uhbp|bh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jwur|jr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vyqy|qv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bkgi|bg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bmww|bm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <oyrz|or\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lfvo|fl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <stwb|bs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dxdq|dd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lnnn|ln\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ffse|ef\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uxca|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cekr|ce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <suyp|ps\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <znnh|hn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vstg|gs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ydte|de\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cxzr|cr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rtyt|rt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qtxj|jq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kgci|cg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <acki|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gwfi|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pdfj|df\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mrxf|fm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <esae|ae\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wdbb|bb\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <raao|aa\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <blao|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <iicl|ci\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lozy|lo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yrqs|qr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ovsm|mo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xzke|ek\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gdvg|dg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jqxp|jp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yewr|er\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qmkg|gk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wkdc|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <azra|aa\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zkod|dk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fgrz|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <izqa|ai\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <suen|en\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <khxc|ch\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pgcc|cc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zjuj|jj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <urzi|ir\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ooyo|oo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <owfn|fn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zael|ae\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <buxa|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zdwl|dl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <knhd|dh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ejti|ei\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rmhq|hm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nmqa|am\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <opcn|cn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <knjl|jk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <weoi|ei\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <whfz|fh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yztr|rt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vyzs|sv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <sapp|ap\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <irll|il\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uadc|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pivw|ip\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jpxw|jp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ffdg|df\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gcqh|cg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rpur|pr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qtlu|lq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mkfo|fk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hcsl|ch\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jfvs|fj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xgtn|gn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yiwi|ii\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dljx|dj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ofmf|ff\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qnhl|hl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nxjf|fj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jqcf|cf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cbcq|bc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qwhn|hn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <tcsj|cj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mibb|bb\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yngt|gn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lpyr|lp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <glca|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <updc|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <btqh|bh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kbku|bk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hskm|hk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nvfn|fn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qlkd|dk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <htuo|ho\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <tkua|ak\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <orpz|op\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xumg|gm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fimx|fi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bjdv|bd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mfir|fi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <knak|ak\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zzur|ru\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ksfm|fk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mkmp|km\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rmsm|mm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <folb|bf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mddw|dd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dqrx|dq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lvuv|lu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ixem|ei\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uoin|in\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <irkf|fi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <goqp|go\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bktp|bk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <djpw|dj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lrfy|fl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yuth|ht\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dbso|bd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mzkw|km\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <tdzm|dm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ivbr|bi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uksh|hk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gquu|gq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <umsi|im\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qinj|ij\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <slpx|lp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ekyb|be\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ffph|ff\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <godu|dg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <heva|ae\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qlld|dl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <anpk|ak\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <snsy|ns\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vmbx|bm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kgsb|bg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pxcj|cj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uovl|lo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <oimu|im\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mkmx|km\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <guga|ag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kcne|ce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mtqs|mq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dluc|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rzow|or\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cjps|cj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qnnp|nn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ptpw|pp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <oakq|ak\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pzjw|jp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qvgt|gq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nqvt|nq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ssxf|fs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dwlk|dk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <quyc|cq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bifg|bf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wpzc|cp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gyxa|ag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zwzc|cw\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bdii|bd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xhsg|gh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ecoa|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ygcd|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vbnw|bn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <iixc|ci\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ruqg|gq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uckg|cg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mnre|em\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dmvi|di\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ookf|fk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ylxe|el\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xsef|ef\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dvse|de\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <btrl|bl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zmfj|fj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <opnl|ln\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ufgm|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nfnk|fk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mcsk|ck\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fuag|af\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vlak|ak\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bqho|bh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <sxyt|st\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zkji|ij\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ccta|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fzcp|cf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <sqkm|km\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lfur|fl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jhbz|bh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cevy|ce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fmwz|fm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <aote|ae\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hydv|dh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hbkj|bh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <sdcu|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lzcw|cl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dgof|df\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rzvu|ru\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ezyq|eq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ygre|eg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bpxo|bo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gabu|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hkmo|hk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ehcf|ce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jeng|eg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <iupr|ip\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ygbs|bg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <onbt|bn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mfka|af\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pund|dn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ifab|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <awdb|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jgtq|gj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kyrt|kr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wyrp|pr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <krlr|kl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <blww|bl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rcpr|cp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <olvf|fl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ddeo|dd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jqag|ag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lcfo|cf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <aguu|ag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <igay|ag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <grmz|gm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gssg|gg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mczz|cm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <znfo|fn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kzma|ak\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hrml|hl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <tnuf|fn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vadi|ad\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <iaga|aa\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rxqe|eq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ombn|bm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nqku|kn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uaor|ao\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ijxz|ij\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qhsp|hp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mdyy|dm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xbia|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <feta|ae\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <whtp|hp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zccr|cc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jaiy|ai\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zzsc|cs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fxzu|fu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yiip|ii\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pfil|fi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hvpu|hp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pglr|gl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kvlh|hk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mmfi|fi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <aqfn|af\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zwjd|dj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ltwh|hl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <scax|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nlra|al\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jqds|dj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nzoz|no\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mqhw|hm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vgoy|go\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mpvj|jm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ecac|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qllk|kl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uvsy|su\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wsmu|ms\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pqdx|dp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <upkf|fk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mult|lm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dmqc|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <utkv|kt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pcye|ce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nlgd|dg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lkbx|bk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gdaw|ad\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ivdm|di\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cumw|cm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jazp|aj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hfjf|ff\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dbuj|bd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <sdoa|ad\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ulwk|kl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kbba|ab\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <esmi|ei\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hmgn|gh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cpxw|cp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <sivg|gi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <atvr|ar\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qfxn|fn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <janf|af\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cwfg|cf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qkzf|fk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <umgq|gm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rotb|bo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <phhj|hh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xlhi|hi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gnxt|gn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vvhl|hl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wmtu|mt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <oitt|io\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ujao|aj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cjxa|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bnol|bl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rgzx|gr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gbhi|bg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yagd|ad\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <maxs|am\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nblr|bl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <irgf|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <garl|ag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <viot|io\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yzbi|bi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ffcp|cf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <onkj|jk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <frgy|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nyed|de\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qblu|bl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kkcw|ck\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lmts|lm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ofgh|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pppq|pp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wzsf|fs\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nflb|bf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jsvs|js\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <drfc|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <bjyy|bj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ztuf|ft\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rjvl|jl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qnjw|jn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mlit|il\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <awmf|af\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <dpwv|dp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <clkd|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pomj|jm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ngri|gi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yhto|ho\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cjvx|cj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xzys|sx\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <byne|be\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rcdo|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <aiep|ae\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wewf|ef\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vvkn|kn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xzdq|dq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kudd|dd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pgnf|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qjtz|jq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hiwt|hi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ghbr|bg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uwqq|qq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mbfw|bf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <uzmy|mu\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <znxn|nn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jpbi|bi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <aeye|ae\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gqwt|gq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rgiz|gi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <tkro|ko\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mmwe|em\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ghhs|gh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <depz|de\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <epwc|ce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jrod|dj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <sxdi|di\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jkup|jk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ijng|gi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lfzi|fi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pcdm|cd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xrfg|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pfgv|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rveo|eo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ecgb|bc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <axgv|ag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zmts|ms\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <komj|jk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <scjf|cf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rpuw|pr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <crnz|cn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <txdt|dt\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yger|eg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jnly|jl\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hreo|eh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gyps|gp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <lfsj|fj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <omsv|mo\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <aryl|al\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <mxmj|jm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <omby|bm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ttqa|aq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <adqw|ad\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ybmw|bm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nenl|el\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ogob|bg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zvic|ci\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vtfg|fg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ewwx|ew\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xkdm|dk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <meqo|em\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yfbr|bf\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vdgm|dg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kisn|ik\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zsdb|bd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zrxd|dr\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ugua|ag\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rqgm|gm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pthy|hp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <vymd|dm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <fynt|fn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <zemt|em\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <njac|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ptgv|gp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <brpi|bi\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <wyvi|iv\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hnww|hn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <qgvu|gq\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nytp|np\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <ijce|ce\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rkpu|kp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pwgp|gp\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <jtfd|df\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <oqxc|co\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <eihe|ee\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <xjja|aj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <curc|cc\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <gcsy|cg\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <rmjy|jm\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <cthh|ch\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <djsw|dj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yzkh|hk\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <yjcr|cj\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <hkme|eh\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <aype|ae\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <naoc|ac\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <eixs|ei\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <topx|op\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <nzmn|mn\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <tajf|af\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <pjdd|dd\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([8, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([8, 5])\n",
      "Token string: <kswh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <tuvc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <oosx|o\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <emwd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lmke|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xyep|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <eomm|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ugbq|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <foxi|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lqsh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <tbjy|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fhfn|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qsej|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <phww|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <duvh|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <enez|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dgzz|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qugg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mplk|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xnyk|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dsir|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xaqs|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vwhe|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ggnj|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wqan|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <virm|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cbau|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fpql|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bjfz|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <exrj|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zgoz|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hamd|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gmvs|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rpno|n\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nzzt|n\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bvkq|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gdks|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bwoj|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <orly|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <aodi|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uiwu|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mxhz|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wisc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xdas|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <irtj|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dooq|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qgzb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lavl|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <afpz|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kjbz|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ftzt|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lpkd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nbod|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pbxv|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <negl|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ooxh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <exdt|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vbia|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <llkn|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uwek|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ujbo|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xllg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pkeq|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nzhe|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hekc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bvwx|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lfyt|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dfrt|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wvnb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fewy|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <niur|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ppnh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uhbp|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jwur|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vyqy|q\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bkgi|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bmww|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <oyrz|o\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lfvo|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <stwb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dxdq|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lnnn|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ffse|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uxca|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cekr|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <suyp|p\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <znnh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vstg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ydte|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cxzr|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rtyt|r\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qtxj|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kgci|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <acki|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gwfi|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pdfj|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mrxf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <esae|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wdbb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <raao|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <blao|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <iicl|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lozy|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yrqs|q\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ovsm|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xzke|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gdvg|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jqxp|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yewr|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qmkg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wkdc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <azra|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zkod|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fgrz|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <izqa|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <suen|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <khxc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pgcc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zjuj|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <urzi|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ooyo|o\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <owfn|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zael|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <buxa|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zdwl|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <knhd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ejti|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rmhq|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nmqa|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <opcn|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <knjl|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <weoi|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <whfz|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yztr|r\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vyzs|s\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <sapp|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <irll|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uadc|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pivw|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jpxw|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ffdg|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gcqh|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rpur|p\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qtlu|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mkfo|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hcsl|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jfvs|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xgtn|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yiwi|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dljx|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ofmf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qnhl|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nxjf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jqcf|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cbcq|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qwhn|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <tcsj|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mibb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yngt|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lpyr|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <glca|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <updc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <btqh|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kbku|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hskm|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nvfn|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qlkd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <htuo|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <tkua|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <orpz|o\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xumg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fimx|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bjdv|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mfir|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <knak|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zzur|r\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ksfm|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mkmp|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rmsm|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <folb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mddw|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dqrx|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lvuv|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ixem|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uoin|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <irkf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <goqp|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bktp|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <djpw|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lrfy|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yuth|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dbso|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mzkw|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <tdzm|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ivbr|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uksh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gquu|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <umsi|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qinj|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <slpx|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ekyb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ffph|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <godu|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <heva|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qlld|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <anpk|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <snsy|n\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vmbx|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kgsb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pxcj|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uovl|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <oimu|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mkmx|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <guga|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kcne|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mtqs|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dluc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rzow|o\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cjps|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qnnp|n\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ptpw|p\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <oakq|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pzjw|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qvgt|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nqvt|n\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ssxf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dwlk|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <quyc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bifg|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wpzc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gyxa|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zwzc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bdii|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xhsg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ecoa|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ygcd|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vbnw|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <iixc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ruqg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uckg|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mnre|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dmvi|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ookf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ylxe|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xsef|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dvse|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <btrl|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zmfj|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <opnl|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ufgm|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nfnk|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mcsk|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fuag|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vlak|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bqho|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <sxyt|s\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zkji|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ccta|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fzcp|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <sqkm|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lfur|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jhbz|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cevy|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fmwz|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <aote|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hydv|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hbkj|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <sdcu|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lzcw|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dgof|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rzvu|r\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ezyq|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ygre|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bpxo|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gabu|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hkmo|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ehcf|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jeng|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <iupr|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ygbs|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <onbt|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mfka|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pund|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ifab|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <awdb|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jgtq|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kyrt|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wyrp|p\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <krlr|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <blww|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rcpr|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <olvf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ddeo|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jqag|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lcfo|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <aguu|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <igay|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <grmz|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gssg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mczz|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <znfo|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kzma|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hrml|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <tnuf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vadi|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <iaga|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rxqe|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ombn|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nqku|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uaor|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ijxz|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qhsp|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mdyy|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xbia|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <feta|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <whtp|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zccr|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jaiy|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zzsc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fxzu|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yiip|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pfil|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hvpu|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pglr|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kvlh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mmfi|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <aqfn|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zwjd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ltwh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <scax|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nlra|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jqds|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nzoz|n\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mqhw|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vgoy|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mpvj|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ecac|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qllk|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uvsy|s\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wsmu|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pqdx|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <upkf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mult|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dmqc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <utkv|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pcye|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nlgd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lkbx|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gdaw|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ivdm|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cumw|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jazp|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hfjf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dbuj|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <sdoa|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ulwk|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kbba|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <esmi|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hmgn|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cpxw|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <sivg|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <atvr|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qfxn|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <janf|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cwfg|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qkzf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <umgq|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rotb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <phhj|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xlhi|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gnxt|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vvhl|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wmtu|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <oitt|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ujao|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cjxa|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bnol|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rgzx|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gbhi|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yagd|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <maxs|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nblr|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <irgf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <garl|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <viot|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yzbi|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ffcp|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <onkj|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <frgy|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nyed|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qblu|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kkcw|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lmts|l\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ofgh|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pppq|p\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wzsf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nflb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jsvs|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <drfc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <bjyy|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ztuf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rjvl|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qnjw|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mlit|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <awmf|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <dpwv|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <clkd|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pomj|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ngri|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yhto|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cjvx|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xzys|s\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <byne|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rcdo|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <aiep|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wewf|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vvkn|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xzdq|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kudd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pgnf|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qjtz|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hiwt|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ghbr|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uwqq|q\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mbfw|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <uzmy|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <znxn|n\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jpbi|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <aeye|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gqwt|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rgiz|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <tkro|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mmwe|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ghhs|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <depz|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <epwc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jrod|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <sxdi|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jkup|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ijng|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lfzi|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pcdm|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xrfg|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pfgv|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rveo|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ecgb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <axgv|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zmts|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <komj|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <scjf|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rpuw|p\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <crnz|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <txdt|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yger|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jnly|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hreo|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gyps|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <lfsj|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <omsv|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <aryl|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <mxmj|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <omby|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ttqa|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <adqw|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ybmw|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nenl|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ogob|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zvic|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vtfg|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ewwx|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xkdm|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <meqo|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yfbr|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vdgm|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kisn|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zsdb|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zrxd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ugua|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rqgm|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pthy|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <vymd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <fynt|f\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <zemt|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <njac|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ptgv|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <brpi|b\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <wyvi|i\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hnww|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <qgvu|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nytp|n\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <ijce|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rkpu|k\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pwgp|g\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <jtfd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <oqxc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <eihe|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <xjja|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <curc|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <gcsy|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <rmjy|j\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <cthh|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <djsw|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yzkh|h\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <yjcr|c\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <hkme|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <aype|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <naoc|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <eixs|e\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <topx|o\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <nzmn|m\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <tajf|a\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <pjdd|d\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([7, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([7, 5])\n",
      "Token string: <kswh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <tuvc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <oosx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <emwd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lmke|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xyep|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <eomm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ugbq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <foxi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lqsh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <tbjy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fhfn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qsej|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <phww|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <duvh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <enez|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dgzz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qugg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mplk|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xnyk|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dsir|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xaqs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vwhe|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ggnj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wqan|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <virm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cbau|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fpql|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bjfz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <exrj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zgoz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hamd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gmvs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rpno|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nzzt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bvkq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gdks|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bwoj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <orly|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <aodi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uiwu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mxhz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wisc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xdas|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <irtj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dooq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qgzb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lavl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <afpz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kjbz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ftzt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lpkd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nbod|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pbxv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <negl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ooxh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <exdt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vbia|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <llkn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uwek|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ujbo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xllg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pkeq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nzhe|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hekc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bvwx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lfyt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dfrt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wvnb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fewy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <niur|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ppnh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uhbp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jwur|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vyqy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bkgi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bmww|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <oyrz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lfvo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <stwb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dxdq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lnnn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ffse|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uxca|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cekr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <suyp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <znnh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vstg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ydte|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cxzr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rtyt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qtxj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kgci|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <acki|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gwfi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pdfj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mrxf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <esae|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wdbb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <raao|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <blao|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <iicl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lozy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yrqs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ovsm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xzke|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gdvg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jqxp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yewr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qmkg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wkdc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <azra|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zkod|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fgrz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <izqa|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <suen|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <khxc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pgcc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zjuj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <urzi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ooyo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <owfn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zael|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <buxa|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zdwl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <knhd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ejti|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rmhq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nmqa|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <opcn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <knjl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <weoi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <whfz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yztr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vyzs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <sapp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <irll|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uadc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pivw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jpxw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ffdg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gcqh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rpur|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qtlu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mkfo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hcsl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jfvs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xgtn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yiwi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dljx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ofmf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qnhl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nxjf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jqcf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cbcq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qwhn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <tcsj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mibb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yngt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lpyr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <glca|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <updc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <btqh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kbku|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hskm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nvfn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qlkd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <htuo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <tkua|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <orpz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xumg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fimx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bjdv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mfir|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <knak|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zzur|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ksfm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mkmp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rmsm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <folb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mddw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dqrx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lvuv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ixem|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uoin|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <irkf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <goqp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bktp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <djpw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lrfy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yuth|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dbso|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mzkw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <tdzm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ivbr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uksh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gquu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <umsi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qinj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <slpx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ekyb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ffph|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <godu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <heva|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qlld|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <anpk|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <snsy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vmbx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kgsb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pxcj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uovl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <oimu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mkmx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <guga|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kcne|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mtqs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dluc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rzow|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cjps|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qnnp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ptpw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <oakq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pzjw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qvgt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nqvt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ssxf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dwlk|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <quyc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bifg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wpzc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gyxa|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zwzc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bdii|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xhsg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ecoa|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ygcd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vbnw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <iixc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ruqg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uckg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mnre|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dmvi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ookf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ylxe|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xsef|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dvse|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <btrl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zmfj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <opnl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ufgm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nfnk|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mcsk|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fuag|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vlak|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bqho|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <sxyt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zkji|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ccta|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fzcp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <sqkm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lfur|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jhbz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cevy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fmwz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <aote|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hydv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hbkj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <sdcu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lzcw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dgof|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rzvu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ezyq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ygre|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bpxo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gabu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hkmo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ehcf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jeng|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <iupr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ygbs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <onbt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mfka|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pund|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ifab|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <awdb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jgtq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kyrt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wyrp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <krlr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <blww|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rcpr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <olvf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ddeo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jqag|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lcfo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <aguu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <igay|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <grmz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gssg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mczz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <znfo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kzma|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hrml|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <tnuf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vadi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <iaga|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rxqe|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ombn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nqku|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uaor|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ijxz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qhsp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mdyy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xbia|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <feta|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <whtp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zccr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jaiy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zzsc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fxzu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yiip|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pfil|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hvpu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pglr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kvlh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mmfi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <aqfn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zwjd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ltwh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <scax|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nlra|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jqds|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nzoz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mqhw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vgoy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mpvj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ecac|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qllk|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uvsy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wsmu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pqdx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <upkf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mult|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dmqc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <utkv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pcye|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nlgd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lkbx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gdaw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ivdm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cumw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jazp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hfjf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dbuj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <sdoa|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ulwk|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kbba|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <esmi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hmgn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cpxw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <sivg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <atvr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qfxn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <janf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cwfg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qkzf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <umgq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rotb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <phhj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xlhi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gnxt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vvhl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wmtu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <oitt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ujao|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cjxa|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bnol|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rgzx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gbhi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yagd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <maxs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nblr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <irgf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <garl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <viot|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yzbi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ffcp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <onkj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <frgy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nyed|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qblu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kkcw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lmts|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ofgh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pppq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wzsf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nflb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jsvs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <drfc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <bjyy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ztuf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rjvl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qnjw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mlit|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <awmf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <dpwv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <clkd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pomj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ngri|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yhto|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cjvx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xzys|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <byne|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rcdo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <aiep|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wewf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vvkn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xzdq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kudd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pgnf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qjtz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hiwt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ghbr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uwqq|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mbfw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <uzmy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <znxn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jpbi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <aeye|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gqwt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rgiz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <tkro|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mmwe|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ghhs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <depz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <epwc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jrod|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <sxdi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jkup|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ijng|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lfzi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pcdm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xrfg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pfgv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rveo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ecgb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <axgv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zmts|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <komj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <scjf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rpuw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <crnz|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <txdt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yger|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jnly|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hreo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gyps|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <lfsj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <omsv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <aryl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <mxmj|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <omby|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ttqa|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <adqw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ybmw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nenl|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ogob|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zvic|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vtfg|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ewwx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xkdm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <meqo|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yfbr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vdgm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <kisn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zsdb|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zrxd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ugua|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rqgm|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pthy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <vymd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <fynt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <zemt|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <njac|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ptgv|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <brpi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <wyvi|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hnww|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <qgvu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nytp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <ijce|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rkpu|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pwgp|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <jtfd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <oqxc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <eihe|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <xjja|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <curc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <gcsy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <rmjy|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <cthh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <djsw|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yzkh|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <yjcr|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <hkme|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <aype|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <naoc|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <eixs|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <topx|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <nzmn|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <tajf|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n",
      "Token string: <pjdd|\n",
      "    Hook name: blocks.0.hook_resid_post\n",
      "        Feature Indices: [sequence_position, top_k] torch.Size([6, 5])\n",
      "        Feature Values:  [sequence_position, top_k] torch.Size([6, 5])\n"
     ]
    }
   ],
   "source": [
    "# note: first break this down into two problems\n",
    "# 1. for a given token string, which features are activated\n",
    "# 2. for a given feature, what are the top activating examples\n",
    "#\n",
    "# we can do (2) first because we can do auto-interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "3a5333c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection complete.\n",
      "Number of unique token_strings: 1462272\n",
      "Number of unique hook_names: 1\n",
      "Total number of data entries collected: 54835200\n",
      "Concatenating data arrays...\n",
      "Data arrays concatenated.\n",
      "Total entries after concatenation: 54835200\n",
      "Feature indices shape: (54835200,)\n",
      "Activation values shape: (54835200,)\n",
      "Creating DataFrame...\n",
      "DataFrame created with 54835200 rows.\n",
      "Creating token_strings DataFrame...\n",
      "Creating hook_names DataFrame...\n",
      "Merging token_string indices back to strings...\n",
      "Merging hook_name indices back to strings...\n",
      "Merging complete.\n",
      "Dropping index columns...\n",
      "Index columns dropped.\n",
      "Final DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54835200 entries, 0 to 54835199\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   feature_index     int32  \n",
      " 1   activation_value  float32\n",
      " 2   position          int16  \n",
      " 3   k                 int8   \n",
      " 4   token_string      object \n",
      " 5   hook_name         object \n",
      "dtypes: float32(1), int16(1), int32(1), int8(1), object(2)\n",
      "memory usage: 1.4+ GB\n",
      "None\n",
      "First few rows of the DataFrame:\n",
      "   feature_index  activation_value  position  k token_string  \\\n",
      "0             19          0.709915         0  0    <qljk|jkl   \n",
      "1             29          0.263583         0  1    <qljk|jkl   \n",
      "2              0          0.000000         0  2    <qljk|jkl   \n",
      "3              1          0.000000         0  3    <qljk|jkl   \n",
      "4              2          0.000000         0  4    <qljk|jkl   \n",
      "\n",
      "                 hook_name  \n",
      "0  blocks.0.hook_resid_pre  \n",
      "1  blocks.0.hook_resid_pre  \n",
      "2  blocks.0.hook_resid_pre  \n",
      "3  blocks.0.hook_resid_pre  \n",
      "4  blocks.0.hook_resid_pre  \n",
      "Processed 54835200 data entries\n"
     ]
    }
   ],
   "source": [
    "# thank you o1-preview for this truly cursed function\n",
    "from typing import Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def process_activations(\n",
    "    top_k_activations_by_token_string_and_hook_name: dict[str, dict[str, TopKActivations]],\n",
    "    max_token_strings: int | None = None,  # useful for testing\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes activations data and returns a DataFrame with the results.\n",
    "\n",
    "    Parameters:\n",
    "    - top_k_activations_by_token_string_and_hook_name: A nested dictionary where the first key is the token string,\n",
    "      the second key is the hook name, and the value is an object containing activation indices and values.\n",
    "\n",
    "    Returns:\n",
    "    - all_data: A pandas DataFrame containing the processed data.\n",
    "    \"\"\"\n",
    "    # Initialize lists to collect data\n",
    "    feature_indices_list: list[np.ndarray] = []\n",
    "    activation_values_list: list[np.ndarray] = []\n",
    "    token_string_indices_list: list[np.ndarray] = []\n",
    "    positions_list: list[np.ndarray] = []\n",
    "    ks_list: list[np.ndarray] = []\n",
    "    hook_name_indices_list: list[np.ndarray] = []\n",
    "\n",
    "    # Dictionaries to map token_strings and hook_names to unique indices\n",
    "    token_string_to_index: dict[str, int] = {}\n",
    "    token_strings_list: list[str] = []\n",
    "\n",
    "    hook_name_to_index: dict[str, int] = {}\n",
    "    hook_names_list: list[str] = []\n",
    "\n",
    "    # Loop over your data\n",
    "    for token_string, hook_name_to_topk_activations in tqdm(\n",
    "        top_k_activations_by_token_string_and_hook_name.items(),\n",
    "        desc=\"Processing tokens\",\n",
    "        leave=False,\n",
    "    ):\n",
    "\n",
    "        if max_token_strings is not None and len(token_string_to_index) >= max_token_strings:\n",
    "            print(f\"Reached max_token_strings: {max_token_strings}\")\n",
    "            break\n",
    "\n",
    "        # Assign a unique index to each unique token_string\n",
    "        if token_string not in token_string_to_index:\n",
    "            token_string_index = len(token_strings_list)\n",
    "            token_strings_list.append(token_string)\n",
    "            token_string_to_index[token_string] = token_string_index\n",
    "        else:\n",
    "            token_string_index = token_string_to_index[token_string]\n",
    "\n",
    "        for hook_name, topk_activations in hook_name_to_topk_activations.items():\n",
    "            # Assign a unique index to each unique hook_name\n",
    "            if hook_name not in hook_name_to_index:\n",
    "                hook_name_index = len(hook_names_list)\n",
    "                hook_names_list.append(hook_name)\n",
    "                hook_name_to_index[hook_name] = hook_name_index\n",
    "            else:\n",
    "                hook_name_index = hook_name_to_index[hook_name]\n",
    "\n",
    "            # Extract activation indices and values\n",
    "            num_positions, top_k = topk_activations.activation_indices.shape\n",
    "\n",
    "            # Flatten tensors\n",
    "            feature_indices = (\n",
    "                topk_activations.activation_indices.reshape(-1).cpu().numpy().astype(np.int32)\n",
    "            )\n",
    "            activation_values = (\n",
    "                topk_activations.activation_values.reshape(-1).cpu().numpy().astype(np.float32)\n",
    "            )\n",
    "            positions = (\n",
    "                torch.arange(num_positions)\n",
    "                .unsqueeze(1)\n",
    "                .repeat(1, top_k)\n",
    "                .reshape(-1)\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "                .astype(np.int16)\n",
    "            )\n",
    "            ks = (\n",
    "                torch.arange(top_k)\n",
    "                .unsqueeze(0)\n",
    "                .repeat(num_positions, 1)\n",
    "                .reshape(-1)\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "                .astype(np.int8)\n",
    "            )\n",
    "\n",
    "            # Create arrays of indices\n",
    "            token_string_indices = np.full(len(feature_indices), token_string_index, dtype=np.int32)\n",
    "            hook_name_indices = np.full(len(feature_indices), hook_name_index, dtype=np.int16)\n",
    "\n",
    "            # Collect data into lists\n",
    "            feature_indices_list.append(feature_indices)\n",
    "            activation_values_list.append(activation_values)\n",
    "            token_string_indices_list.append(token_string_indices)\n",
    "            positions_list.append(positions)\n",
    "            ks_list.append(ks)\n",
    "            hook_name_indices_list.append(hook_name_indices)\n",
    "\n",
    "    # Debug prints after data collection\n",
    "    print(f\"Data collection complete.\")\n",
    "    print(f\"Number of unique token_strings: {len(token_strings_list)}\")\n",
    "    print(f\"Number of unique hook_names: {len(hook_names_list)}\")\n",
    "    total_entries = sum(len(arr) for arr in feature_indices_list)\n",
    "    print(f\"Total number of data entries collected: {total_entries}\")\n",
    "\n",
    "    # Concatenate lists into arrays\n",
    "    print(\"Concatenating data arrays...\")\n",
    "    feature_indices = np.concatenate(feature_indices_list)\n",
    "    activation_values = np.concatenate(activation_values_list)\n",
    "    token_string_indices = np.concatenate(token_string_indices_list)\n",
    "    positions = np.concatenate(positions_list)\n",
    "    ks = np.concatenate(ks_list)\n",
    "    hook_name_indices = np.concatenate(hook_name_indices_list)\n",
    "    print(\"Data arrays concatenated.\")\n",
    "\n",
    "    # Debug prints after concatenation\n",
    "    print(f\"Total entries after concatenation: {len(feature_indices)}\")\n",
    "    print(f\"Feature indices shape: {feature_indices.shape}\")\n",
    "    print(f\"Activation values shape: {activation_values.shape}\")\n",
    "\n",
    "    # Create the DataFrame using the indices\n",
    "    print(\"Creating DataFrame...\")\n",
    "    all_data = pd.DataFrame(\n",
    "        {\n",
    "            \"feature_index\": feature_indices,\n",
    "            \"activation_value\": activation_values,\n",
    "            \"token_string_index\": token_string_indices,\n",
    "            \"hook_name_index\": hook_name_indices,\n",
    "            \"position\": positions,\n",
    "            \"k\": ks,\n",
    "        }\n",
    "    )\n",
    "    print(f\"DataFrame created with {len(all_data)} rows.\")\n",
    "\n",
    "    # Map indices back to their respective strings\n",
    "    print(\"Creating token_strings DataFrame...\")\n",
    "    token_strings_df = pd.DataFrame(\n",
    "        {\"token_string_index\": range(len(token_strings_list)), \"token_string\": token_strings_list}\n",
    "    )\n",
    "    print(\"Creating hook_names DataFrame...\")\n",
    "    hook_names_df = pd.DataFrame(\n",
    "        {\"hook_name_index\": range(len(hook_names_list)), \"hook_name\": hook_names_list}\n",
    "    )\n",
    "\n",
    "    # Merge the mappings into your DataFrame\n",
    "    print(\"Merging token_string indices back to strings...\")\n",
    "    all_data = all_data.merge(token_strings_df, on=\"token_string_index\", how=\"left\")\n",
    "    print(\"Merging hook_name indices back to strings...\")\n",
    "    all_data = all_data.merge(hook_names_df, on=\"hook_name_index\", how=\"left\")\n",
    "    print(\"Merging complete.\")\n",
    "\n",
    "    # Optionally, drop the index columns if you no longer need them\n",
    "    print(\"Dropping index columns...\")\n",
    "    all_data.drop(columns=[\"token_string_index\", \"hook_name_index\"], inplace=True)\n",
    "    print(\"Index columns dropped.\")\n",
    "\n",
    "    # Final DataFrame info\n",
    "    print(\"Final DataFrame info:\")\n",
    "    print(all_data.info())\n",
    "\n",
    "    # Optionally, print the first few rows to inspect\n",
    "    print(\"First few rows of the DataFrame:\")\n",
    "    print(all_data.head())\n",
    "\n",
    "    print(f\"Processed {len(all_data)} data entries\")\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "all_data = process_activations(top_k_activations_by_token_string_and_hook_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "95163b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenating 1462272 dataframes...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g6/72q2lnk54yz_3sxkj9p0j6rc0000gn/T/ipykernel_80512/1523155959.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mdata_entries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Combine all data into a single DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mConcatenating \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m dataframes...\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_entries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mDone concatenating \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m dataframes\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpt_from_scratch/venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/gpt_from_scratch/venv/lib/python3.12/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gpt_from_scratch/venv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, mgr, axes)\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def process_topk_activations(top_k_activations_by_token_string_and_hook_name):\n",
    "    \"\"\"\n",
    "    Processes top-k activations and returns a concatenated DataFrame.\n",
    "\n",
    "    Args:\n",
    "        top_k_activations_by_token_string_and_hook_name (dict):\n",
    "            A nested dictionary where the first key is the token string, the second key is the hook name,\n",
    "            and the value is an object containing `activation_indices` and `activation_values` tensors.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing all processed activation data with the following columns:\n",
    "            - feature_index (int32)\n",
    "            - activation_value (float32)\n",
    "            - token_string (str)\n",
    "            - position (int16)\n",
    "            - k (int8)\n",
    "    \"\"\"\n",
    "    data_entries = []\n",
    "\n",
    "    # Iterate over each token string and its corresponding hooks\n",
    "    for token_string, hook_name_to_topk_activations in tqdm.tqdm(\n",
    "        top_k_activations_by_token_string_and_hook_name.items(),\n",
    "        desc=\"Processing tokens\",\n",
    "        leave=False,\n",
    "    ):\n",
    "        # Iterate over each hook name and its top-k activations\n",
    "        for hook_name, topk_activations in hook_name_to_topk_activations.items():\n",
    "            num_positions, top_k = topk_activations.activation_indices.shape\n",
    "\n",
    "            # Flatten the activation_indices and activation_values tensors\n",
    "            feature_indices = topk_activations.activation_indices.reshape(-1).cpu().numpy()\n",
    "            activation_values = topk_activations.activation_values.reshape(-1).cpu().numpy()\n",
    "\n",
    "            # Generate position indices\n",
    "            positions = (\n",
    "                torch.arange(num_positions).unsqueeze(1).repeat(1, top_k).reshape(-1).cpu().numpy()\n",
    "            )\n",
    "\n",
    "            # Generate k indices\n",
    "            ks = torch.arange(top_k).unsqueeze(0).repeat(num_positions, 1).reshape(-1).cpu().numpy()\n",
    "\n",
    "            # Create a list of the current token string repeated for each activation\n",
    "            token_strings = [token_string] * len(feature_indices)\n",
    "\n",
    "            # Create a DataFrame for the current set of activations\n",
    "            data = pd.DataFrame(\n",
    "                {\n",
    "                    \"feature_index\": feature_indices.astype(np.int32),\n",
    "                    \"activation_value\": activation_values.astype(np.float32),\n",
    "                    \"token_string\": token_strings,\n",
    "                    \"position\": positions.astype(np.int16),\n",
    "                    \"k\": ks.astype(np.int8),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Append the DataFrame to the list of data entries\n",
    "            data_entries.append(data)\n",
    "\n",
    "    # Combine all DataFrames into a single DataFrame\n",
    "    print(f\"Concatenating {len(data_entries)} dataframes...\")\n",
    "    all_data = pd.concat(data_entries, ignore_index=True)\n",
    "    print(f\"Done concatenating {len(data_entries)} dataframes\")\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "fac41232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and group data to get top N activations per feature\n",
    "num_top_activations_to_keep_per_feature = 100\n",
    "top_activations_per_feature = (\n",
    "    all_data.sort_values([\"feature_index\", \"activation_value\"], ascending=[True, False])\n",
    "    .groupby(\"feature_index\")\n",
    "    .head(num_top_activations_to_keep_per_feature)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "40d0aeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"feature_index\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037f902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f13f41e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Examples for <feature>58</feature>:\n",
      "\n",
      "<activation> 1.29 </activation>\t<full-string> < m w <token>f</token> k | f k m </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < g q <token>f</token> f | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < x x <token>f</token> a | a </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < l o <token>f</token> z | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < f w <token>f</token> m | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < m t <token>f</token> j | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < y e <token>f</token> s | e </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < r q <token>f</token> w | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < p g <token>f</token> s | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < k j <token>f</token> v | f </full-string>\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "# note: with relu we don't have negative activations\n",
    "def display_top_examples_for_feature(feature_index: int, top_n: int = 10) -> str:\n",
    "    \"\"\"\n",
    "    Returns a string containing the top N examples for the specified feature index.\n",
    "\n",
    "    Parameters:\n",
    "    - feature_index (int): The index of the feature to display.\n",
    "    - top_n (int): The number of top examples to display.\n",
    "\n",
    "    Returns:\n",
    "    - str: A formatted string containing the top examples.\n",
    "    \"\"\"\n",
    "    # Filter data for the specified feature\n",
    "    feature_data = top_activations_per_feature[\n",
    "        (top_activations_per_feature[\"feature_index\"] == feature_index)\n",
    "        & (top_activations_per_feature[\"k\"] == 0)\n",
    "    ]\n",
    "    feature_data = feature_data.sort_values(\"activation_value\", ascending=False)\n",
    "    top_examples = feature_data.head(top_n)\n",
    "\n",
    "    result = [f\"Top {top_n} Examples for <feature>{feature_index}</feature>:\\n\"]\n",
    "\n",
    "    for idx, row in top_examples.iterrows():\n",
    "        token_string = row[\"token_string\"]\n",
    "        position = int(row[\"position\"])\n",
    "\n",
    "        tokens = list(token_string)\n",
    "\n",
    "        if 0 <= position < len(tokens):\n",
    "            token = tokens[position]\n",
    "            token = f\"<token>{token}</token>\"\n",
    "            tokens[position] = token  # colored(token, \"red\", attrs=[\"bold\"])\n",
    "        else:\n",
    "            result.append(\n",
    "                f\"Warning: Position {position} is out of range for token_string '{token_string}'\"\n",
    "            )\n",
    "\n",
    "        highlighted_token_string = \" \".join(tokens)\n",
    "\n",
    "        result.append(\n",
    "            f\"<activation> {row['activation_value']:.2f} </activation>\\t\"\n",
    "            f\"<full-string> {highlighted_token_string} </full-string>\"\n",
    "        )\n",
    "\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "\n",
    "# Display top 10 examples for feature index 42\n",
    "print(display_top_examples_for_feature(58, top_n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "69f875d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No activation data available for token_string: '58'\n",
      "<full-string> < m w f k | f k m </full-string>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>0</position>\n",
      "<token><</token>:\n",
      "<feature>19</feature>\t<activation>0.7099</activation> <k>0</k>\n",
      "<feature>29</feature>\t<activation>0.2636</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>1</position>\n",
      "<token>m</token>:\n",
      "<feature>25</feature>\t<activation>1.1649</activation> <k>0</k>\n",
      "<feature>9</feature>\t<activation>0.1280</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>2</position>\n",
      "<token>w</token>:\n",
      "<feature>63</feature>\t<activation>0.7523</activation> <k>0</k>\n",
      "<feature>16</feature>\t<activation>0.5024</activation> <k>1</k>\n",
      "<feature>21</feature>\t<activation>0.0577</activation> <k>2</k>\n",
      "<feature>13</feature>\t<activation>0.0449</activation> <k>3</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>3</position>\n",
      "<token>f</token>:\n",
      "<feature>58</feature>\t<activation>1.2868</activation> <k>0</k>\n",
      "<feature>21</feature>\t<activation>0.2299</activation> <k>1</k>\n",
      "<feature>9</feature>\t<activation>0.0051</activation> <k>2</k>\n",
      "<feature>35</feature>\t<activation>0.0023</activation> <k>3</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>4</position>\n",
      "<token>k</token>:\n",
      "<feature>46</feature>\t<activation>1.3696</activation> <k>0</k>\n",
      "<feature>20</feature>\t<activation>0.9244</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>5</position>\n",
      "<token>|</token>:\n",
      "<feature>7</feature>\t<activation>1.2500</activation> <k>0</k>\n",
      "<feature>52</feature>\t<activation>1.0267</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>6</position>\n",
      "<token>f</token>:\n",
      "<feature>4</feature>\t<activation>1.0818</activation> <k>0</k>\n",
      "<feature>36</feature>\t<activation>0.7514</activation> <k>1</k>\n",
      "<feature>24</feature>\t<activation>0.0301</activation> <k>2</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>7</position>\n",
      "<token>k</token>:\n",
      "<feature>47</feature>\t<activation>1.0762</activation> <k>0</k>\n",
      "<feature>20</feature>\t<activation>0.9357</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>8</position>\n",
      "<token>m</token>:\n",
      "<feature>3</feature>\t<activation>1.3312</activation> <k>0</k>\n",
      "<feature>15</feature>\t<activation>0.9292</activation> <k>1</k>\n",
      "<feature>25</feature>\t<activation>0.0856</activation> <k>2</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n"
     ]
    }
   ],
   "source": [
    "def display_top_features_for_token_string(token_string, top_n=5) -> str:\n",
    "    \"\"\"\n",
    "    Generates a string containing the top activating features at each position in the given token_string.\n",
    "\n",
    "    Parameters:\n",
    "    - token_string (str): The token string to analyze.\n",
    "    - top_n (int): The number of top features to display per position.\n",
    "\n",
    "    Returns:\n",
    "    - str: A formatted string containing the analysis results.\n",
    "    \"\"\"\n",
    "    from termcolor import colored\n",
    "    import pandas as pd\n",
    "\n",
    "    result = []  # List to store all output strings\n",
    "\n",
    "    # Filter 'all_data' for the given token_string\n",
    "    data_for_string = all_data[all_data[\"token_string\"] == token_string]\n",
    "\n",
    "    if data_for_string.empty:\n",
    "        return f\"No activation data available for token_string: '{token_string}'\"\n",
    "\n",
    "    # Ensure 'position' is integer\n",
    "    data_for_string = data_for_string.copy()\n",
    "    data_for_string[\"position\"] = data_for_string[\"position\"].astype(int)\n",
    "\n",
    "    # Get the length of the token_string\n",
    "    token_length = len(token_string)\n",
    "\n",
    "    result.append(f\"<full-string> {' '.join(token_string)} </full-string>\")\n",
    "\n",
    "    # For each position in the token_string\n",
    "    for pos in range(token_length):\n",
    "        # Get the token at current position\n",
    "        token = token_string[pos]\n",
    "\n",
    "        # Filter data for the current position\n",
    "        data_at_position = data_for_string[data_for_string[\"position\"] == pos]\n",
    "\n",
    "        if data_at_position.empty:\n",
    "            result.append(f\"Position {pos} (Token '{token}'): No activations.\")\n",
    "            continue\n",
    "\n",
    "        # Get top N features by activation value (descending order)\n",
    "        top_features = data_at_position.nlargest(top_n, \"activation_value\")\n",
    "\n",
    "        # Generate the results\n",
    "        result.append(f\"\\n<top-{top_n}-activating-features-at-position>\")\n",
    "        result.append(f\"<position>{pos}</position>\\n<token>{token}</token>:\")\n",
    "        for idx, row in top_features.iterrows():\n",
    "            feature_index = int(row[\"feature_index\"])\n",
    "            activation_value = row[\"activation_value\"]\n",
    "            k = int(row[\"k\"])\n",
    "            result.append(\n",
    "                f\"<feature>{feature_index}</feature>\\t<activation>{activation_value:.4f}</activation> <k>{k}</k>\"\n",
    "            )\n",
    "        result.append(f\"</top-{top_n}-activating-features-at-position>\")\n",
    "\n",
    "    return \"\\n\".join(result)  # Join all strings with newlines\n",
    "\n",
    "\n",
    "def display_top_features_for_top_token_string(feature_index: int) -> str:\n",
    "    \"\"\"\n",
    "    Generates a string containing the top activating features at each position for the\n",
    "    top activating values for a given feature.\n",
    "\n",
    "    \"\"\"\n",
    "    # Filter data for the specified feature\n",
    "    feature_data = top_activations_per_feature[\n",
    "        (top_activations_per_feature[\"feature_index\"] == feature_index)\n",
    "        & (top_activations_per_feature[\"k\"] == 0)\n",
    "    ]\n",
    "    feature_data = feature_data.sort_values(\"activation_value\", ascending=False)\n",
    "    token_string = feature_data[\"token_string\"].values[0]\n",
    "\n",
    "    return display_top_features_for_token_string(token_string)\n",
    "\n",
    "\n",
    "print(display_top_features_for_token_string(58, top_n=10))\n",
    "\n",
    "print(display_top_features_for_top_token_string(58))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af2c864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e7ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa925c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d9c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0471e32c",
   "metadata": {},
   "source": [
    "#### Feature Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "908be057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'all_data' is your DataFrame containing all activations\n",
    "# Count the number of times each feature appears\n",
    "feature_counts = all_data[\"feature_index\"].value_counts().sort_index()\n",
    "\n",
    "# Convert to a DataFrame\n",
    "feature_counts_df = feature_counts.reset_index()\n",
    "feature_counts_df.columns = [\"feature_index\", \"count\"]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(feature_counts_df[\"count\"], bins=50, log=True)\n",
    "plt.xlabel(\"Number of Activations\")\n",
    "plt.ylabel(\"Number of Features\")\n",
    "plt.title(\"Distribution of Feature Activation Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48611f3a",
   "metadata": {},
   "source": [
    "#### Top Features (by frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "2e3f61ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAIsCAYAAACOb+jMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABpJ0lEQVR4nO3deXxMZ///8fckskhI7LHcqbjtsYVYGvtWUUHVrajWkqK0etMqSu2tnaq2qGqLLpaUWvqt0qJalC62KrXvu6gSgoTM9fvDL3MbSUjaJHPSvJ6PxzweyXXOmfnMzDkz8z7nOtexGWOMAAAAAACAy7m5ugAAAAAAAHAHIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAPwlo0aNks1mc3UZf4nNZtOoUaNcXcZf0rBhQzVs2NDVZQAAMgghHQAymc1mS9Xtu+++y9A6Tp48qdGjR6tmzZrKmzevChQooIYNG2rt2rXJzn/58mU9++yzKliwoHx9fdWoUSNt3749VY/VsGFD2Ww2lS5dOtnpa9ascTzvJUuW/OXndD9fffVVmkJZYs3J3fbt25chNVrR9evXNWrUqAxfH+9Vs2ZN2Ww2vfvuu3/5PtL6nqenzZs3a9SoUbp8+bJLHl+SgoKCUlyHb968mSGPOW7cOC1fvjxD7hsAsoscri4AALKbTz75xOn/jz/+WGvWrEnSXr58+QytY8WKFZo4caLatGmjrl276vbt2/r444/1yCOPaM6cOYqMjHTMa7fbFRERoV9//VUDBw5UgQIFNHPmTDVs2FDbtm1LMXzfzdvbW4cOHdLPP/+smjVrOk2bP3++vL29Myw4SHcC24wZM9IU2v71r39p/PjxSdqLFi2ajpVZ2/Xr1zV69GhJyrSjtwcPHtQvv/yioKAgzZ8/X88999xfup/7vec3btxQjhwZ9zNo8+bNGj16tLp166Y8efJk2OM8SEhIiF5++eUk7Z6enhnyeOPGjVO7du3Upk2bDLl/AMgOCOkAkMmefvppp/9//PFHrVmzJkl7RmvUqJFOnDihAgUKONp69+6tkJAQjRgxwimkL1myRJs3b9bixYvVrl07SVL79u1VpkwZjRw5UgsWLHjg45UsWVK3b9/WwoULnUL6zZs3tWzZMkVEROjzzz9Px2f49/n7+6fpfYmNjZWvr28GVpQ9fPrppypUqJDeeOMNtWvXTseOHVNQUFC6Poa3t3e63p9VFStWLNM/W9Kb3W5XfHx8tnnPAIDu7gBgQbGxsXr55ZcVGBgoLy8vlS1bVlOmTJExxmk+m82mF154QfPnz1fZsmXl7e2t0NBQbdiw4YGPUaFCBaeALkleXl5q0aKFTp06patXrzralyxZooCAALVt29bRVrBgQbVv314rVqxQXFxcqp7Xk08+qaioKNntdkfb//3f/+n69etq3759ssvs2LFDjz76qPz8/JQrVy41adJEP/74o9M8t27d0ujRo1W6dGl5e3srf/78qlu3rtasWSNJ6tatm2bMmCHJ+XSDv6Nbt27KlSuXDh8+rBYtWih37tx66qmnJN0JFdOmTVOFChXk7e2tgIAA9erVS3/++afTfRhjNGbMGP3rX/+Sj4+PGjVqpD179igoKEjdunVzzJfSud/z5s2TzWbTsWPHnNpXrVqlevXqydfXV7lz51ZERIT27NmTbP2nT59WmzZtlCtXLhUsWFADBgxQQkKCJOnYsWMqWLCgJGn06NGO1y2l3ggNGjRQlSpVkp1WtmxZhYeHp/h63m3BggVq166dWrZsKX9//xR3Av30009q0aKF8ubNK19fX1WuXFlvvfWW4/nd7z2/+3ksWbJENptN33//fZLHeO+992Sz2bR7925J0q5du9StWzf9+9//lre3twoXLqxnnnlGf/zxh2OZUaNGaeDAgZKkEiVKOB777vfp008/VWhoqHLmzKl8+fKpY8eOOnnyZJLHnz17tkqWLKmcOXOqZs2a2rhxY6pew9S6fPmyXnzxRcdnTalSpTRx4kSnbVSSpkyZotq1ayt//vzKmTOnQkNDk5yaYrPZFBsbq48++sjxnBPX427duiW7oyW5dfvuz7UKFSrIy8tLq1evliSdPn1azzzzjAICAuTl5aUKFSpozpw5Se73nXfeUYUKFeTj46O8efOqevXqqdqZCABWwJF0ALAYY4xat26t9evXq3v37goJCdHXX3+tgQMH6vTp03rzzTed5v/+++8VFRWlvn37ysvLSzNnzlTz5s31888/q2LFiml+/HPnzsnHx0c+Pj6Oth07dqhatWpyc3Pet1uzZk3Nnj1bBw4cUKVKlR543506dXKc39y4cWNJdwJZkyZNVKhQoSTz79mzR/Xq1ZOfn58GDRokDw8Pvffee2rYsKG+//571apVS9KdH/rjx49Xjx49VLNmTcXExGjr1q3avn27HnnkEfXq1UtnzpxJ9rSC+0lISNDFixed2ry9vZUrVy5J0u3btxUeHq66detqypQpjtesV69emjdvniIjI9W3b18dPXpU06dP144dO/TDDz/Iw8NDkjRixAiNGTNGLVq0UIsWLbR9+3Y1a9ZM8fHxqa7xXp988om6du2q8PBwTZw4UdevX9e7776runXraseOHU5BKSEhQeHh4apVq5amTJmitWvX6o033lDJkiX13HPPqWDBgnr33Xf13HPP6fHHH3fspKlcuXKyj925c2f17NlTu3fvdlr3fvnlFx04cEDDhg17YP0//fSTDh06pLlz58rT01Nt27bV/Pnz9eqrrzrNt2bNGrVs2VJFihRRv379VLhwYe3du1dffvml+vXrl6b3PCIiQrly5dJnn32mBg0aOE2LiopShQoVHM9nzZo1OnLkiCIjI1W4cGHt2bNHs2fP1p49e/Tjjz/KZrOpbdu2OnDggBYuXKg333zTsTMscYfH2LFjNXz4cLVv3149evRQdHS03nnnHdWvX187duxwdI//8MMP1atXL9WuXVsvvviijhw5otatWytfvnwKDAx84Gsp3dmBde86nLh9X79+XQ0aNNDp06fVq1cvPfTQQ9q8ebOGDBmis2fPatq0aY5l3nrrLbVu3VpPPfWU4uPjtWjRIj3xxBP68ssvFRERIenOupe4DT777LOS7vSg+Su+/fZbffbZZ3rhhRdUoEABBQUF6fz583r44YcdIb5gwYJatWqVunfvrpiYGL344ouSpPfff199+/ZVu3bt1K9fP928eVO7du3STz/9pE6dOv2legAgUxkAgEv16dPH3P1xvHz5ciPJjBkzxmm+du3aGZvNZg4dOuRok2Qkma1btzrajh8/bry9vc3jjz+e5loOHjxovL29TefOnZ3afX19zTPPPJNk/pUrVxpJZvXq1fe93wYNGpgKFSoYY4ypXr266d69uzHGmD///NN4enqajz76yKxfv95IMosXL3Ys16ZNG+Pp6WkOHz7saDtz5ozJnTu3qV+/vqOtSpUqJiIi4r413Ps6P0iDBg0cr+/dt65duxpjjOnatauRZAYPHuy03MaNG40kM3/+fKf21atXO7VfuHDBeHp6moiICGO32x3zvfrqq06PY4wxI0eOTLb2uXPnGknm6NGjxhhjrl69avLkyWN69uzpNN+5c+eMv7+/U3ti/a+99prTvFWrVjWhoaGO/6Ojo40kM3LkyCSPf29dly9fNt7e3uaVV15xmq9v377G19fXXLt2Lcl93OuFF14wgYGBjtfkm2++MZLMjh07HPPcvn3blChRwhQvXtz8+eefTsvf/Vre7z2/9zk9+eSTplChQub27duOtrNnzxo3Nzen1+j69etJ7mvhwoVGktmwYYOjbfLkyU7vTaJjx44Zd3d3M3bsWKf23377zeTIkcPRHh8fbwoVKmRCQkJMXFycY77Zs2cbSaZBgwbJPq+7FS9ePNl1OPF5v/7668bX19ccOHDAabnBgwcbd3d3c+LEiRSfd3x8vKlYsaJp3LixU7uvr6/Tupuoa9eupnjx4knak1u3JRk3NzezZ88ep/bu3bubIkWKmIsXLzq1d+zY0fj7+ztqfOyxxxyfNwCQFdHdHQAs5quvvpK7u7v69u3r1P7yyy/LGKNVq1Y5tYeFhSk0NNTx/0MPPaTHHntMX3/9taPbcmpcv35dTzzxhHLmzKkJEyY4Tbtx44a8vLySLJN4juiNGzdS/TidOnXS0qVLFR8fryVLlsjd3V2PP/54kvkSEhL0zTffqE2bNvr3v//taC9SpIg6deqkTZs2KSYmRpKUJ08e7dmzRwcPHkx1HakRFBSkNWvWON0GDRrkNM+9g5otXrxY/v7+euSRR3Tx4kXHLTQ0VLly5dL69eslSWvXrlV8fLz++9//OnX3TTwa+FesWbNGly9f1pNPPun02O7u7qpVq5bjse/Wu3dvp//r1aunI0eO/KXH9/f312OPPaaFCxc6Ts1ISEhQVFSU2rRp88Dz9W/fvq2oqCh16NDB8Zo0btxYhQoV0vz58x3z7dixQ0ePHtWLL76YZFC2v3oaQ4cOHXThwgWnUeyXLFkiu92uDh06ONpy5szp+PvmzZu6ePGiHn74YUlK1dUOli5dKrvdrvbt2zu9R4ULF1bp0qUd79HWrVt14cIF9e7d22mQt27dusnf3z/Vz6tWrVpJ1uEuXbpIurOu1qtXT3nz5nWqpWnTpkpISHA6bebu5/3nn3/qypUrqlevXqqv8JBWDRo0UHBwsON/Y4w+//xztWrVSsYYp3rDw8N15coVRy158uTRqVOn9Msvv2RIbQCQ0bJ1d/cNGzZo8uTJ2rZtm86ePatly5alaTTSUaNGOUa8vZuPj49iY2PTsVIA2cnx48dVtGhR5c6d26k9cbT348ePO7UnN7J6mTJldP36dUVHR6tw4cIPfMyEhAR17NhRv//+u1atWpVk9PKcOXMme9554mjsd/+Af5COHTtqwIABWrVqlebPn6+WLVsmea6SFB0drevXr6ts2bJJppUvX152u10nT55UhQoV9Nprr+mxxx5TmTJlVLFiRTVv3lydO3dOsVt2avn6+qpp06YpTs+RI4f+9a9/ObUdPHhQV65cSbb7viRduHBB0v/ex3vfv4IFCypv3rx/qd7EnRSJpxLcy8/Pz+l/b29vRxfsRHnz5k1y7nxadOnSRVFRUdq4caPq16+vtWvX6vz58+rcufMDl/3mm28UHR2tmjVr6tChQ472Ro0aaeHChZo4caLc3Nx0+PBhSfpLp3OkpHnz5vL391dUVJSaNGki6U5X95CQEJUpU8Yx36VLlzR69GgtWrTI8V4munLlygMf5+DBgzLGpHhFhMRTIVJaPzw8PJx2Wj1IgQIFUlyHDx48qF27diVZBxLd/fy+/PJLjRkzRjt37nT6LPi7YzukpESJEk7/R0dH6/Lly5o9e7Zmz55933pfeeUVrV27VjVr1lSpUqXUrFkzderUSXXq1MmQWgEgvWXrkB4bG6sqVaromWeecRoMKbUGDBiQ5AhEkyZNVKNGjfQqEQAyRc+ePfXll19q/vz5yQa8IkWK6OzZs0naE9vSckmyIkWKqGHDhnrjjTf0ww8/pMuI7vXr19fhw4e1YsUKffPNN/rggw/05ptvatasWerRo8ffvv+UeHl5JTlP3263Jznye7eUAtH9pBSE7u0pkTjY1yeffJLszpl7Lznm7u6e5loeJDw8XAEBAfr0009Vv359ffrppypcuPB9d3YkSnzNUhpE8Pvvv1ejRo3Std5EXl5eatOmjZYtW6aZM2fq/Pnz+uGHHzRu3Din+dq3b6/Nmzdr4MCBCgkJUa5cuWS329W8efMkg60lx263y2azadWqVcm+/onjHWQGu92uRx55JEnvkESJOyc2btyo1q1bq379+po5c6aKFCkiDw8PzZ07N9WDsaV2HU50746/xNf26aefVteuXZNdJnGnXPny5bV//359+eWXWr16tT7//HPNnDlTI0aMSPbgCgBYTbYO6Y8++qgeffTRFKfHxcVp6NChWrhwoS5fvqyKFStq4sSJjuvE5sqVy+nL9Ndff9Xvv/+uWbNmZXTpAP7BihcvrrVr1+rq1atOR5j37dvnmH635Lp4HzhwQD4+PqkKhAMHDtTcuXM1bdo0Pfnkk8nOExISoo0bN8putzuF0p9++kk+Pj5ORxpTo1OnTurRo4fy5MmjFi1aJDtPwYIF5ePjo/379yeZtm/fPrm5uTkNnpUvXz5FRkYqMjJS165dU/369TVq1ChHSM+oI373KlmypNauXas6derct4dB4vt48OBBpyOj0dHRSY5kJx5Zv3z5slP37nt7VSQO0lWoUKFUheLUSOvr5u7urk6dOmnevHmaOHGili9frp49ez5wh0BsbKxWrFihDh06OC7zd7e+fftq/vz5atSokeN57t69+77PM621d+jQQR999JHWrVunvXv3yhjj1NX9zz//1Lp16zR69GiNGDHC0Z7cNpjSY5csWVLGGJUoUeK+283d68fdO85u3bqlo0ePpjiKflqULFlS165de+C68vnnn8vb21tff/2102kvc+fOTTJvSs87b968unz5cpL2e9fhlBQsWFC5c+dWQkJCqtZtX19fdejQQR06dFB8fLzatm2rsWPHasiQIVzKDYDlcU76fbzwwgvasmWLFi1apF27dumJJ55Q8+bNUzzn8YMPPlCZMmVUr169TK4UwD9JixYtlJCQoOnTpzu1v/nmm7LZbEl2Lm7ZssXpvNCTJ09qxYoVatas2QOD0eTJkzVlyhS9+uqr6tevX4rztWvXTufPn9fSpUsdbRcvXtTixYvVqlWrZM9Xv5927dpp5MiRmjlzptP5tndzd3dXs2bNtGLFCqdLV50/f14LFixQ3bp1Hd237778lXRnJ2qpUqWcuuUmng+dXFBIT+3bt1dCQoJef/31JNNu377tePymTZvKw8ND77zzjtOl9e4eUTtRYii9+xzhxEtd3S08PFx+fn4aN26cbt26leR+oqOj0/x8EkesT8vr1rlzZ/3555/q1auXrl27lqrrdC9btkyxsbHq06eP2rVrl+TWsmVLff7554qLi1O1atVUokQJTZs2LUldd7+WaX3PmzZtqnz58ikqKkpRUVGqWbOmU7frxO3J3HMpxOTes5Qeu23btnJ3d9fo0aOT3I8xxrEuV69eXQULFtSsWbOcRvufN29euq3D7du315YtW/T1118nmXb58mXdvn1b0p3nbbPZnI56Hzt2TMuXL0+ynK+vb7L1lSxZUleuXNGuXbscbYmnGqaGu7u7/vOf/+jzzz93XA7vbnev2/d+Hnh6eio4OFjGmGS3CwCwmmx9JP1+Tpw4oblz5+rEiROObpwDBgzQ6tWrNXfu3CTd327evKn58+dr8ODBrigXwD9Iq1at1KhRIw0dOlTHjh1TlSpV9M0332jFihV68cUXk1zSqGLFigoPD3e6BJukB3brXLZsmQYNGqTSpUurfPny+vTTT52mP/LIIwoICJB0J1Q//PDDioyM1O+//64CBQpo5syZSkhI+EvdR/39/VO81vbdxowZozVr1qhu3bp6/vnnlSNHDr333nuKi4vTpEmTHPMFBwerYcOGCg0NVb58+bR161YtWbJEL7zwgmOexMH1+vbtq/DwcLm7u6tjx45prv1BGjRooF69emn8+PHauXOnmjVrJg8PDx08eFCLFy/WW2+9pXbt2jmuST5+/Hi1bNlSLVq00I4dO7Rq1aok169v1qyZHnroIXXv3l0DBw6Uu7u75syZo4IFC+rEiROO+fz8/PTuu++qc+fOqlatmjp27OiYZ+XKlapTp06SnT8PkjNnTgUHBysqKkplypRRvnz5VLFixfueD161alVVrFhRixcvVvny5VWtWrUHPs78+fOVP39+1a5dO9nprVu31vvvv6+VK1eqbdu2evfdd9WqVSuFhIQoMjJSRYoU0b59+7Rnzx5H6Ezre+7h4aG2bdtq0aJFio2N1ZQpU5ym+/n5qX79+po0aZJu3bqlYsWK6ZtvvtHRo0eT3FfiYw8dOlQdO3aUh4eHWrVqpZIlS2rMmDEaMmSIjh07pjZt2ih37tw6evSoli1bpmeffVYDBgyQh4eHxowZo169eqlx48bq0KGDjh49qrlz56bpnPT7GThwoL744gu1bNlS3bp1U2hoqGJjY/Xbb79pyZIlOnbsmAoUKKCIiAhNnTpVzZs3V6dOnXThwgXNmDFDpUqVcgrdic977dq1mjp1qooWLaoSJUqoVq1a6tixo1555RU9/vjj6tu3r+PSgGXKlEn14HMTJkzQ+vXrVatWLfXs2VPBwcG6dOmStm/frrVr1+rSpUuS7mwvhQsXVp06dRQQEKC9e/dq+vTpioiISHb8CwCwHJeMKW9BksyyZcsc/3/55ZdGkvH19XW65ciRw7Rv3z7J8gsWLDA5cuQw586dy8SqAfwTJHeZqKtXr5qXXnrJFC1a1Hh4eJjSpUubyZMnO11eypg7n119+vQxn376qSldurTx8vIyVatWNevXr3/g4yZe+iil2733cenSJdO9e3eTP39+4+PjYxo0aGB++eWXVD3Huy/BlpLkLsFmjDHbt2834eHhJleuXMbHx8c0atTIbN682WmeMWPGmJo1a5o8efKYnDlzmnLlypmxY8ea+Ph4xzy3b982//3vf03BggWNzWZ74OXYHlRz165dja+vb4rTZ8+ebUJDQ03OnDlN7ty5TaVKlcygQYPMmTNnHPMkJCSY0aNHmyJFipicOXOahg0bmt27d5vixYsnuYzVtm3bTK1atYynp6d56KGHzNSpU5Ncgi3R+vXrTXh4uPH39zfe3t6mZMmSplu3bk6X6kup/uQuibV582YTGhpqPD09nS7hldKl4YwxZtKkSUaSGTduXIqvUaLz58+bHDlyJLn0392uX79ufHx8nC4tuGnTJvPII4+Y3LlzG19fX1O5cmXzzjvvOKbf7z2/+3ncbc2aNUaSsdls5uTJk0mmnzp1yjz++OMmT548xt/f3zzxxBPmzJkzyd7f66+/booVK2bc3NySvE+ff/65qVu3ruP3Rbly5UyfPn3M/v37ne5j5syZpkSJEsbLy8tUr17dbNiwwTRo0CDVl2B70KUJr169aoYMGWJKlSplPD09TYECBUzt2rXNlClTnLafDz/80PEZU65cOTN37txk3/99+/aZ+vXrm5w5cya5lOA333xjKlasaDw9PU3ZsmXNp59+muIl2Pr06ZNsvefPnzd9+vQxgYGBxsPDwxQuXNg0adLEzJ492zHPe++9Z+rXr2/y589vvLy8TMmSJc3AgQPNlStXHviaAYAV2Iy5p69VNmWz2ZxGd4+KitJTTz2lPXv2JOkumitXriQD8jRp0kR+fn6p7rYFAOnBZrOpT58+aT46CmsLCgpSw4YNNW/ePFeX8pe99dZbeumll3Ts2DE99NBDri4HAIAsg+7uKahataoSEhJ04cKFB55jfvToUa1fv15ffPFFJlUHAIB1GWP04YcfqkGDBgR0AADSKFuH9GvXrjldh/Xo0aPauXOn8uXLpzJlyuipp55Sly5d9MYbb6hq1aqKjo7WunXrVLlyZUVERDiWmzNnjooUKXLfkeIBAPini42N1RdffKH169frt99+04oVK1xdEgAAWU62Dulbt251ut5q//79JUldu3bVvHnzNHfuXI0ZM0Yvv/yyTp8+rQIFCujhhx9Wy5YtHcvY7XbNmzdP3bp1y5DrzQIAkFVER0erU6dOypMnj1599VW1bt3a1SUBAJDlcE46AAAAAAAWwXXSAQAAAACwCEI6AAAAAAAWke3OSbfb7Tpz5oxy584tm83m6nIAAAAAAP9wxhhdvXpVRYsWlZvb/Y+VZ7uQfubMGQUGBrq6DAAAAABANnPy5En961//uu882S6k586dW9KdF8fPz8/F1QAAAAAA/uliYmIUGBjoyKP3k+1CemIXdz8/P0I6AAAAACDTpOaUawaOAwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLyOHKB9+wYYMmT56sbdu26ezZs1q2bJnatGlz32W+++479e/fX3v27FFgYKCGDRumbt26ZUq9rhA0eKWrS5AkHZsQ4eoSAAAAAOAfz6VH0mNjY1WlShXNmDEjVfMfPXpUERERatSokXbu3KkXX3xRPXr00Ndff53BlQIAAAAAkPFceiT90Ucf1aOPPprq+WfNmqUSJUrojTfekCSVL19emzZt0ptvvqnw8PCMKhMAAAAAgEyRpc5J37Jli5o2berUFh4eri1btrioIgAAAAAA0o9Lj6Sn1blz5xQQEODUFhAQoJiYGN24cUM5c+ZMskxcXJzi4uIc/8fExGR4nQAAAAAA/BVZ6kj6XzF+/Hj5+/s7boGBga4uCQAAAACAZGWpkF64cGGdP3/eqe38+fPy8/NL9ii6JA0ZMkRXrlxx3E6ePJkZpQIAAAAAkGZZqrt7WFiYvvrqK6e2NWvWKCwsLMVlvLy85OXlldGlAQAAAADwt7n0SPq1a9e0c+dO7dy5U9KdS6zt3LlTJ06ckHTnKHiXLl0c8/fu3VtHjhzRoEGDtG/fPs2cOVOfffaZXnrpJVeUDwAAAABAunJpSN+6dauqVq2qqlWrSpL69++vqlWrasSIEZKks2fPOgK7JJUoUUIrV67UmjVrVKVKFb3xxhv64IMPuPwaAAAAAOAfwWaMMa4uIjPFxMTI399fV65ckZ+fn6vLeaCgwStdXYIk6diECFeXAAAAAABZUlpyaJYaOA4AAAAAgH8yQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWITLQ/qMGTMUFBQkb29v1apVSz///PN95582bZrKli2rnDlzKjAwUC+99JJu3ryZSdUCAAAAAJBxXBrSo6Ki1L9/f40cOVLbt29XlSpVFB4ergsXLiQ7/4IFCzR48GCNHDlSe/fu1YcffqioqCi9+uqrmVw5AAAAAADpz6UhferUqerZs6ciIyMVHBysWbNmycfHR3PmzEl2/s2bN6tOnTrq1KmTgoKC1KxZMz355JMPPPoOAAAAAEBW4LKQHh8fr23btqlp06b/K8bNTU2bNtWWLVuSXaZ27dratm2bI5QfOXJEX331lVq0aJEpNQMAAAAAkJFyuOqBL168qISEBAUEBDi1BwQEaN++fcku06lTJ128eFF169aVMUa3b99W796979vdPS4uTnFxcY7/Y2Ji0ucJAAAAAACQzlw+cFxafPfddxo3bpxmzpyp7du3a+nSpVq5cqVef/31FJcZP368/P39HbfAwMBMrBgAAAAAgNRz2ZH0AgUKyN3dXefPn3dqP3/+vAoXLpzsMsOHD1fnzp3Vo0cPSVKlSpUUGxurZ599VkOHDpWbW9J9DkOGDFH//v0d/8fExBDUAQAAAACW5LIj6Z6engoNDdW6descbXa7XevWrVNYWFiyy1y/fj1JEHd3d5ckGWOSXcbLy0t+fn5ONwAAAAAArMhlR9IlqX///uratauqV6+umjVratq0aYqNjVVkZKQkqUuXLipWrJjGjx8vSWrVqpWmTp2qqlWrqlatWjp06JCGDx+uVq1aOcI6AAAAAABZlUtDeocOHRQdHa0RI0bo3LlzCgkJ0erVqx2DyZ04ccLpyPmwYcNks9k0bNgwnT59WgULFlSrVq00duxYVz0FAAAAAADSjc2k1E/8HyomJkb+/v66cuVKluj6HjR4patLkCQdmxDh6hIAAAAAIEtKSw7NUqO7AwAAAADwT0ZIBwAAAADAIgjpAAAAAABYhEsHjsM/B+fOAwAAAMDfx5F0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALCINId0d3d3XbhwIUn7H3/8IXd393QpCgAAAACA7CjNId0Yk2x7XFycPD09/3ZBAAAAAABkVzlSO+Pbb78tSbLZbPrggw+UK1cux7SEhARt2LBB5cqVS/8KAQAAAADIJlId0t98801Jd46kz5o1y6lru6enp4KCgjRr1qz0rxAAAAAAgGwi1SH96NGjkqRGjRpp6dKlyps3b4YVBQAAAABAdpTqkJ5o/fr1GVEHAAAAAADZXppDekJCgubNm6d169bpwoULstvtTtO//fbbdCsOAAAAAIDsJM0hvV+/fpo3b54iIiJUsWJF2Wy2jKgLAAAAAIBsJ80hfdGiRfrss8/UokWLjKgHAAAAAIBsK83XSff09FSpUqUyohYAAAAAALK1NIf0l19+WW+99ZaMMRlRDwAAAAAA2Vaau7tv2rRJ69ev16pVq1ShQgV5eHg4TV+6dGm6FQcAAAAAQHaS5pCeJ08ePf744xlRCwAAAAAA2VqaQ/rcuXMzog4AAAAAALK9NJ+TDgAAAAAAMkaaj6SXKFHivtdGP3LkyN8qCAAAAACA7CrNIf3FF190+v/WrVvasWOHVq9erYEDB6ZXXQAAAAAAZDtpDun9+vVLtn3GjBnaunXr3y4IAAAAAIDsKt3OSX/00Uf1+eefp9fdAQAAAACQ7aRbSF+yZIny5cuXXncHAAAAAEC2k+bu7lWrVnUaOM4Yo3Pnzik6OlozZ85M1+IAAAAAAMhO0hzS27Rp4/S/m5ubChYsqIYNG6pcuXJpLmDGjBmaPHmyzp07pypVquidd95RzZo1U5z/8uXLGjp0qJYuXapLly6pePHimjZtmlq0aJHmxwYAAAAAwErSHNJHjhyZbg8eFRWl/v37a9asWapVq5amTZum8PBw7d+/X4UKFUoyf3x8vB555BEVKlRIS5YsUbFixXT8+HHlyZMn3WoCAAAAAMBV0hzSJSkhIUHLly/X3r17JUkVKlRQ69at5e7unqb7mTp1qnr27KnIyEhJ0qxZs7Ry5UrNmTNHgwcPTjL/nDlzdOnSJW3evFkeHh6SpKCgoL/yFAAAAAAAsJw0Dxx36NAhlS9fXl26dNHSpUu1dOlSPf3006pQoYIOHz6c6vuJj4/Xtm3b1LRp0/8V4+ampk2basuWLcku88UXXygsLEx9+vRRQECAKlasqHHjxikhISGtTwMAAAAAAMtJc0jv27evSpYsqZMnT2r79u3avn27Tpw4oRIlSqhv376pvp+LFy8qISFBAQEBTu0BAQE6d+5cssscOXJES5YsUUJCgr766isNHz5cb7zxhsaMGZPi48TFxSkmJsbpBgAAAACAFaW5u/v333+vH3/80elya/nz59eECRNUp06ddC3uXna7XYUKFdLs2bPl7u6u0NBQnT59WpMnT07xXPnx48dr9OjRGVoXAAAAAADpIc1H0r28vHT16tUk7deuXZOnp2eq76dAgQJyd3fX+fPnndrPnz+vwoULJ7tMkSJFVKZMGadz38uXL69z584pPj4+2WWGDBmiK1euOG4nT55MdY0AAAAAAGSmNIf0li1b6tlnn9VPP/0kY4yMMfrxxx/Vu3dvtW7dOtX34+npqdDQUK1bt87RZrfbtW7dOoWFhSW7TJ06dXTo0CHZ7XZH24EDB1SkSJEUdxB4eXnJz8/P6QYAAAAAgBWlOaS//fbbKlmypMLCwuTt7S1vb2/VqVNHpUqV0ltvvZWm++rfv7/ef/99ffTRR9q7d6+ee+45xcbGOkZ779Kli4YMGeKY/7nnntOlS5fUr18/HThwQCtXrtS4cePUp0+ftD4NAAAAAAAsJ83npOfJk0crVqzQoUOHHJdgK1++vEqVKpXmB+/QoYOio6M1YsQInTt3TiEhIVq9erVjMLkTJ07Ize1/+xECAwP19ddf66WXXlLlypVVrFgx9evXT6+88kqaHxsAAAAAAKuxGWNMameOiYlRrly5nIKzdKeb+rVr17JEV/KYmBj5+/vrypUrWaLeoMErXV2CJOnYhIj7Ts8qdQIAAABAZktLDk11d/dly5apevXqunnzZpJpN27cUI0aNfR///d/aa8WAAAAAABISkNIf/fddzVo0CD5+Pgkmebr66tXXnlF06dPT9fiAAAAAADITlId0nfv3q2GDRumOL1+/fr67bff0qMmAAAAAACypVSH9D///FO3b99OcfqtW7f0559/pktRAAAAAABkR6kO6UFBQdq6dWuK07du3arixYunS1EAAAAAAGRHqQ7pbdu21dChQ3X+/Pkk086dO6dhw4bpP//5T7oWBwAAAABAdpLq66QPHjxYK1asUOnSpfX000+rbNmykqR9+/Zp/vz5CgwM1ODBgzOsUAAAAAAA/ulSHdJz586tH374QUOGDFFUVJTj/PM8efLo6aef1tixY5U7d+4MKxQAAAAAgH+6VId0SfL399fMmTM1Y8YMXbx4UcYYFSxYUDabLaPqAwAAAAAg20hTSE9ks9lUsGDB9K4FAAAAAIBsLdUDxwEAAAAAgIxFSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAi/hLA8etW7dO69at04ULF2S3252mzZkzJ10KAwAAAAAgu0lzSB89erRee+01Va9eXUWKFOHyawAAAAAApJM0h/RZs2Zp3rx56ty5c0bUAwAAAABAtpXmc9Lj4+NVu3btjKgFAAAAAIBsLc0hvUePHlqwYEFG1AIAAAAAQLaW5u7uN2/e1OzZs7V27VpVrlxZHh4eTtOnTp2absUBAAAAAJCdpDmk79q1SyEhIZKk3bt3O01jEDkAAAAAAP66NIf09evXZ0QdAAAAAABke2k+J/1up06d0qlTp9KrFgAAAAAAsrU0h3S73a7XXntN/v7+Kl68uIoXL648efLo9ddfl91uz4gaAQAAAADIFtLc3X3o0KH68MMPNWHCBNWpU0eStGnTJo0aNUo3b97U2LFj071IAAAAAACygzSH9I8++kgffPCBWrdu7WirXLmyihUrpueff56QDgAAAADAX5Tm7u6XLl1SuXLlkrSXK1dOly5dSpeiAAAAAADIjtIc0qtUqaLp06cnaZ8+fbqqVKmSLkUBAAAAAJAdpbm7+6RJkxQREaG1a9cqLCxMkrRlyxadPHlSX331VboXCAAAAABAdpHmI+kNGjTQgQMH9Pjjj+vy5cu6fPmy2rZtq/3796tevXoZUSMAAAAAANlCmo+kS1LRokUZIA4AAAAAgHSWqpC+a9cuVaxYUW5ubtq1a9d9561cuXK6FAYAAAAAQHaTqpAeEhKic+fOqVChQgoJCZHNZpMxJsl8NptNCQkJ6V4kAAAAAADZQapC+tGjR1WwYEHH3wAAAAAAIP2lKqQXL17c8ffx48dVu3Zt5cjhvOjt27e1efNmp3kBAAAAAEDqpXl090aNGunSpUtJ2q9cuaJGjRqlS1EAAAAAAGRHaQ7pxhjZbLYk7X/88Yd8fX3TpSgAAAAAALKjVF+CrW3btpLuDA7XrVs3eXl5OaYlJCRo165dql27dvpXCAAAAABANpHqkO7v7y/pzpH03LlzK2fOnI5pnp6eevjhh9WzZ8/0rxAAAAAAgGwi1SF97ty5kqSgoCANGDCAru0AAAAAAKSzVIf0RCNHjsyIOgAAAAAAyPbSHNIlacmSJfrss8904sQJxcfHO03bvn17uhQGAAAAAEB2k+bR3d9++21FRkYqICBAO3bsUM2aNZU/f34dOXJEjz76aEbUCAAAAABAtpDmkD5z5kzNnj1b77zzjjw9PTVo0CCtWbNGffv21ZUrVzKiRgAAAAAAsoU0h/QTJ044LrWWM2dOXb16VZLUuXNnLVy4MH2rAwAAAAAgG0lzSC9cuLAuXbokSXrooYf0448/SpKOHj0qY0z6VgcAAAAAQDaS5pDeuHFjffHFF5KkyMhIvfTSS3rkkUfUoUMHPf744+leIAAAAAAA2UWaR3efPXu27Ha7JKlPnz7Knz+/Nm/erNatW6tXr17pXiAAAAAAANlFmkO6m5ub3Nz+dwC+Y8eO6tixY7oWBQAAAABAdpTm7u6lSpXSqFGjdODAgYyoBwAAAACAbCvNIb1Pnz5auXKlypcvrxo1auitt97SuXPnMqI2AAAAAACylTSH9Jdeekm//PKL9u7dqxYtWmjGjBkKDAxUs2bN9PHHH2dEjQAAAAAAZAtpDumJypQpo9GjR+vAgQPauHGjoqOjFRkZmZ61AQAAAACQraR54Li7/fzzz1qwYIGioqIUExOjJ554Ir3qAgAAAAAg20lzSD9w4IDmz5+vhQsX6ujRo2rcuLEmTpyotm3bKleuXBlRI5CuggavdHUJkqRjEyJcXQIAAAAAi0lzSC9Xrpxq1KihPn36qGPHjgoICMiIugAAAAAAyHbSHNL379+v0qVLZ0QtAAAAAABka2keOI6ADgAAAABAxkjVkfR8+fLpwIEDKlCggPLmzSubzZbivJcuXUq34gAAAAAAyE5SFdLffPNN5c6d2/H3/UI6AAAAAAD4a1IV0rt27er4u1u3bhlVCwAAAAAA2Vqaz0l3d3fXhQsXkrT/8ccfcnd3T5eiAAAAAADIjtIc0o0xybbHxcXJ09PzbxcEAAAAAEB2lepLsL399tuSJJvNpg8++EC5cuVyTEtISNCGDRtUrly59K8QAAAAAIBsItUh/c0335R050j6rFmznLq2e3p6KigoSLNmzUr/CgEAAAAAyCZSHdKPHj0qSWrUqJGWLl2qvHnzZlhRAAAAAABkR6kO6YnWr1+fEXUAAAAAAJDtpXnguP/85z+aOHFikvZJkybpiSeeSJeiAAAAAADIjtIc0jds2KAWLVokaX/00Ue1YcOGdCkKAAAAAIDsKM0h/dq1a8leas3Dw0MxMTHpUhQAAAAAANlRmkN6pUqVFBUVlaR90aJFCg4OTpeiAAAAAADIjtI8cNzw4cPVtm1bHT58WI0bN5YkrVu3TgsXLtTixYvTvUAAAAAAALKLNIf0Vq1aafny5Ro3bpyWLFminDlzqnLlylq7dq0aNGiQETUCAAAAAJAtpDmkS1JERIQiIiKStO/evVsVK1b820UBAAAAAJAdpfmc9HtdvXpVs2fPVs2aNVWlSpX0qAkAAAAAgGzpL4f0DRs2qEuXLipSpIimTJmixo0b68cff0zP2gAAAAAAyFbS1N393Llzmjdvnj788EPFxMSoffv2iouL0/LlyxnZHQAAAACAvynVR9JbtWqlsmXLateuXZo2bZrOnDmjd955J12KmDFjhoKCguTt7a1atWrp559/TtVyixYtks1mU5s2bdKlDgAAAAAAXCnVIX3VqlXq3r27Ro8erYiICLm7u6dLAVFRUerfv79Gjhyp7du3q0qVKgoPD9eFCxfuu9yxY8c0YMAA1atXL13qAAAAAADA1VId0jdt2qSrV68qNDRUtWrV0vTp03Xx4sW/XcDUqVPVs2dPRUZGKjg4WLNmzZKPj4/mzJmT4jIJCQl66qmnNHr0aP373//+2zUAAAAAAGAFqQ7pDz/8sN5//32dPXtWvXr10qJFi1S0aFHZ7XatWbNGV69eTfODx8fHa9u2bWratOn/CnJzU9OmTbVly5YUl3vttddUqFAhde/e/YGPERcXp5iYGKcbAAAAAABWlObR3X19ffXMM89o06ZN+u233/Tyyy9rwoQJKlSokFq3bp2m+7p48aISEhIUEBDg1B4QEKBz584lu8ymTZv04Ycf6v3330/VY4wfP17+/v6OW2BgYJpqBAAAAAAgs/yt66SXLVtWkyZN0qlTp7Rw4cL0qilFV69eVefOnfX++++rQIECqVpmyJAhunLliuN28uTJDK4SAAAAAIC/Jk2XYEuJu7u72rRpk+ZR1gsUKCB3d3edP3/eqf38+fMqXLhwkvkPHz6sY8eOqVWrVo42u90uScqRI4f279+vkiVLOi3j5eUlLy+vNNUFAAAAAIAr/K0j6X+Xp6enQkNDtW7dOkeb3W7XunXrFBYWlmT+cuXK6bffftPOnTsdt9atW6tRo0bauXMnXdkBAAAAAFlauhxJ/zv69++vrl27qnr16qpZs6amTZum2NhYRUZGSpK6dOmiYsWKafz48fL29lbFihWdls+TJ48kJWkHAAAAACCrcXlI79Chg6KjozVixAidO3dOISEhWr16tWMwuRMnTsjNzaUH/AEAAAAAyBQuD+mS9MILL+iFF15Idtp3331332XnzZuX/gUBAAAAAOACHKIGAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwiByuLgBAyoIGr3R1CZKkYxMiXF0CAAAAkC1wJB0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiuE46gL/NKtdzl7imOwAAALI2jqQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhLhPQZM2YoKChI3t7eqlWrln7++ecU533//fdVr1495c2bV3nz5lXTpk3vOz8AAAAAAFmFy0N6VFSU+vfvr5EjR2r79u2qUqWKwsPDdeHChWTn/+677/Tkk09q/fr12rJliwIDA9WsWTOdPn06kysHAAAAACB9uTykT506VT179lRkZKSCg4M1a9Ys+fj4aM6cOcnOP3/+fD3//PMKCQlRuXLl9MEHH8hut2vdunWZXDkAAAAAAOnLpSE9Pj5e27ZtU9OmTR1tbm5uatq0qbZs2ZKq+7h+/bpu3bqlfPnyJTs9Li5OMTExTjcAAAAAAKzIpSH94sWLSkhIUEBAgFN7QECAzp07l6r7eOWVV1S0aFGnoH+38ePHy9/f33ELDAz823UDAAAAAJARXN7d/e+YMGGCFi1apGXLlsnb2zvZeYYMGaIrV644bidPnszkKgEAAAAASJ0crnzwAgUKyN3dXefPn3dqP3/+vAoXLnzfZadMmaIJEyZo7dq1qly5corzeXl5ycvLK13qBQAAAAAgI7n0SLqnp6dCQ0OdBn1LHAQuLCwsxeUmTZqk119/XatXr1b16tUzo1QAAAAAADKcS4+kS1L//v3VtWtXVa9eXTVr1tS0adMUGxuryMhISVKXLl1UrFgxjR8/XpI0ceJEjRgxQgsWLFBQUJDj3PVcuXIpV65cLnseAAAAAAD8XS4P6R06dFB0dLRGjBihc+fOKSQkRKtXr3YMJnfixAm5uf3vgP+7776r+Ph4tWvXzul+Ro4cqVGjRmVm6QAAAAAApCuXh3RJeuGFF/TCCy8kO+27775z+v/YsWMZXxAAAAAAAC6QpUd3BwAAAADgn4SQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWkcPVBQBAZgoavNLVJUiSjk2IcHUJAAAAsCCOpAMAAAAAYBEcSQcAi+KoPwAAQPZDSAcA/C1W2ZkgsUMBAABkfYR0AEC2YZUdCuxMAAAAKSGkAwBgQexQAAAge2LgOAAAAAAALIKQDgAAAACARRDSAQAAAACwCM5JBwAAfwvnzwMAkH44kg4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEXkcHUBAAAAmSFo8EpXlyBJOjYh4oHzZKVaAQDpiyPpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAInK4ugAAAABkXUGDV7q6BEnSsQkRri4BANIFR9IBAAAAALAIQjoAAAAAABZBd3cAAAD841mlW75E13wA90dIBwAAACzEKjsUUrMzISvVCmQVhHQAAAAA/2hW2ZkgPXiHglVqZceH63BOOgAAAAAAFsGRdAAAAABAmnHUP2NwJB0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARVgipM+YMUNBQUHy9vZWrVq19PPPP993/sWLF6tcuXLy9vZWpUqV9NVXX2VSpQAAAAAAZByXh/SoqCj1799fI0eO1Pbt21WlShWFh4frwoULyc6/efNmPfnkk+revbt27NihNm3aqE2bNtq9e3cmVw4AAAAAQPpyeUifOnWqevbsqcjISAUHB2vWrFny8fHRnDlzkp3/rbfeUvPmzTVw4ECVL19er7/+uqpVq6bp06dncuUAAAAAAKSvHK588Pj4eG3btk1DhgxxtLm5ualp06basmVLssts2bJF/fv3d2oLDw/X8uXLk50/Li5OcXFxjv+vXLkiSYqJifmb1WcOe9x1V5cg6cGvV1apU6LWvyKrvP9S1qmV9z9jZJVa/0nvv5R1as0qdUrU+ldklfdfyjq18v5njKxS6z/p/beCxBqNMQ+e2bjQ6dOnjSSzefNmp/aBAweamjVrJruMh4eHWbBggVPbjBkzTKFChZKdf+TIkUYSN27cuHHjxo0bN27cuHHj5tLbyZMnH5iTXXokPTMMGTLE6ci73W7XpUuXlD9/ftlsNhdWljliYmIUGBiokydPys/Pz9XlpCir1ClRa0bIKnVK1JpRskqtWaVOiVozQlapU6LWjJBV6pSoNaNklVqzSp1S1qr17zLG6OrVqypatOgD53VpSC9QoIDc3d11/vx5p/bz58+rcOHCyS5TuHDhNM3v5eUlLy8vp7Y8efL89aKzKD8/vyyx4meVOiVqzQhZpU6JWjNKVqk1q9QpUWtGyCp1StSaEbJKnRK1ZpSsUmtWqVPKWrX+Hf7+/qmaz6UDx3l6eio0NFTr1q1ztNntdq1bt05hYWHJLhMWFuY0vyStWbMmxfkBAAAAAMgqXN7dvX///uratauqV6+umjVratq0aYqNjVVkZKQkqUuXLipWrJjGjx8vSerXr58aNGigN954QxEREVq0aJG2bt2q2bNnu/JpAAAAAADwt7k8pHfo0EHR0dEaMWKEzp07p5CQEK1evVoBAQGSpBMnTsjN7X8H/GvXrq0FCxZo2LBhevXVV1W6dGktX75cFStWdNVTsDQvLy+NHDkySZd/q8kqdUrUmhGySp0StWaUrFJrVqlTotaMkFXqlKg1I2SVOiVqzShZpdasUqeUtWrNTDZjUjMGPAAAAAAAyGguPScdAAAAAAD8DyEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAJBGjLsLZE9s+8gMhPR/ILvdroSEBFeX8Y/Fh3P6sdvtstvtri4D+Mus+Hlw6tQp7dixw9Vl/GNFR0fLGCObzebqUrK8xN8qVtyOkHlu377t6hJS7fjx4/r6668lid8vyFCE9H+Y33//XV26dFF4eLiee+45bd682dUl3VdW2ZkQGxurq1evKiYmJsv8MEt8ba36JfL777+rW7duatq0qZ599lktWrTI1SWlyokTJ7Rv3z5Xl/GXZLUfwlas98yZM/rll1/05ZdfKi4uztXlJLFnzx7Vrl1bn376qSTrbv/3OnTokJYtW6b4+HhXl3Jfu3fvVr169fTuu+9a/rU9cuSIpk2bppdfflmbNm3SjRs3XF2Sk507d6pNmza6fv16lvleTY6VPqcuXbqkffv26eDBg5bflhLt379fw4YN06FDh1xdygPt3r1bpUqV0sCBAyVJbm7WjVFXr17V9evXXV1Gqhw5ckQbNmxwdRmWY921C2m2f/9+1a5dWwkJCapRo4a2bNmifv366e2333Z1ack6cOCApk2bprNnz7q6lPv6/fff1bZtWzVo0EDly5fX/PnzJVnri/leu3fvVtOmTXXy5Em5ublZ7sfkvn37VLduXXl6eqply5Y6ceKEhg8frv/+97+uLu2+duzYoerVq2v37t2uLuWBTpw4oblz52rq1Klau3atJFn2h/D+/fs1ZMgQde7cWVOmTNHOnTsl3anXStvZrl27VKdOHfXp00fPPvusypUrp/fff18XL150dWmSpF9//VU1a9ZUjhw5tGDBAl24cMHSPyIT7dq1S7Vr19aqVass81omZ9++fapfv74iIiLUsmVLS7+2v/32m8LCwvTNN99o+fLl6ty5sw4ePOjqshx+/fVX1a5dWxUqVJCPj4+j3Urb+70OHTqkiRMnatCgQZo3b56io6MlWedzKvF7v3379qpUqZImTZpk6QMhxhjduHFDnTt31qRJk/TGG2/o5MmTTtOtZOfOnXr44YcVHh6uGzdu6JNPPnF1SSk6cOCA6tatq6ioKMsH9V27dqlu3br6+OOPdeHCBVeXYy0G/wh2u928+uqrpn379o62mJgYM2bMGBMSEmImTpzowuqSOnjwoMmXL5+x2WxmyJAhJjo62tUlJWvPnj0mf/785qWXXjLz5883/fv3Nx4eHmbHjh2uLi1FR48eNaVKlTI2m82ULl3anDx50hhjTEJCgosru+PmzZvmqaeeMn379nW03bhxw1StWtXYbDbz5JNPurC6lO3cudP4+vqal156ydWlPNCuXbtM8eLFTZ06dUxwcLDx8PAwH330kavLStaePXtMnjx5zBNPPGF69+5tAgMDTbVq1cy7777rmMdut7uwwjtOnjxpSpUqZUaPHm3OnDlj7Ha7adu2rfH29jYvvviiOX36tEvr27lzp8mZM6d59dVXTXR0tKlQoYIZM2aMsdvtlnj9UnL8+HHz0EMPmYEDB6Y4jxXqT0hIMM8++6yJjIx0/L9hwwYzZ84cs3//fvPnn38aY6xR65kzZ0z58uXNqFGjzO3bt40xxgQHB5uZM2e6uLI7fv31V+Pr65vkPY+Li3NRRQ/222+/mXz58pkWLVqYdu3aGS8vL9OwYUOzfPlyxzyufO8Tf6sMGDDA7Nmzx0yZMsXYbDZz4sQJl9WUWq+++qqJjIw0OXPmNE8++aQ5evSoq0tKYufOncbHx8cMHz7cxMfHm4cffth07tzZ1WWlaOjQocZms5kiRYqYTz75xNy4ccNpuhU+p4wx5siRI6Zw4cJm4MCBKdZklVpdgZD+D9KtWzdTv359p7aYmBgzZcoUU716dfPpp5+6qDJn165dM88884zp1q2bmTFjhrHZbGbgwIGWC+p//PGHadasmVOYNMaYhg0bmv/+97/GGOt9eNy4ccMMGzbMPP7442bdunWmfv36pnjx4pYL6k2aNDGjRo0yxhjHl8egQYPMf/7zH1OtWjUzefJkV5aXxN69e42Pj4959dVXjTHG3Lp1y3z33Xdm2bJlZsOGDS6uztmRI0dM8eLFzSuvvGJu3rxpoqOjzejRo03VqlXN2bNnLbXOXr161YSHh5tBgwY52k6dOmXy589vAgICzNixY11YnbPVq1ebWrVqmejoaEeY+OWXX0yBAgVM1apVzciRI5P8EMosv/76q/Hy8nKsnwkJCaZdu3amRo0ajnms9L7f7f/+7/9MixYtjDHGxMfHm6FDh5o2bdqYHj16OO1YcnX9t2/fNnXr1nXU1KBBAxMaGmr8/f1NyZIlTa9evSwTiDZt2mQqVqxoDhw44Gjr0KGDGTBggHn66afNnDlzXFbr2bNnTeHChU14eLgx5s7r+uKLL5qIiAhTrlw58+abb5q9e/e6pLaUXL582dSuXdsMGTLE0bZ3716TI0cOU61aNTNv3jwXVmdMdHS0qV+/vunXr5+jzW63m+bNm5vNmzebHTt2WGbdvFvi75F+/fqZGTNmmD179hgvLy/TpUsXExsbayZPnmyOHTvm4irvHFSy2Wxm6NChjrbFixcbLy8vs379etcVdh9r1qwxQ4cONa+88orx9PQ08+bNc/lnaHI+/vhj07ZtW2PMnc//CRMmmGeeecYMGzbMfPvtt475rFh7ZrBuXy2kmvn/XYKqVaumhIQE7d+/3zEtd+7ceuaZZ1S1alXNnDnTEt1e3NzcFBoaqubNm+v555/XokWLNGXKFE2aNMlSXR1v3bqly5cvq127dpL+d25niRIldOnSJUnW6z7s7e2tihUrqmPHjmrcuLE+/vhjPfTQQ6pbt65OnTrl8q7vxhhdv35d8fHxOnz4sG7fvi1vb2+dPn1aUVFRioiIUHBwsL766iuX1XivW7du6dVXX5Wvr69at24tSWrbtq369eun3r17q0mTJnrhhRcs0U3r1q1bmjt3rkJCQjRy5Eh5eXmpQIECCgsL09mzZy032JWbm5suXbqkkJAQSdL169dVrFgxNW7cWBUrVtTKlSu1atUq1xb5/504cUJHjx5VgQIF5OnpKUm6du2awsLCVKlSJc2ePdtl60BcXJwGDRqksWPHym63y83NTWPGjNGBAwf07rvvSrLeZ1Wi7du3Oz5PW7RooR9++EHFixfX8ePH9eabb+rVV1+V5Pr63d3dVahQIV2+fFkjRoyQl5eXoqKidPHiRf33v//Vb7/9prlz50pyfTfdK1eu6MKFCzp8+LDi4uI0efJkLV26VHFxcfrjjz/07rvvavLkyS77PRAWFqY//vhDK1asUMuWLfXbb7+pXLlyatKkid5++21NmTJFJ06ccEltybl165Zu3LihZs2aOb7DSpcurdq1a8tut+uTTz5x6SlQNptNzZs3V58+fRxtY8aM0ddff63nn39erVq1Us+ePbVp0yaX1ZicxNNFmjdvru3btys4OFgbN25UVFSUKlSooGnTplniVD1vb2/NnDlTY8aMkXRn+w4LC1P16tX1xRdfSLLm2B/Lli3ThAkTFBkZqeeee05ffPGFevfurbfeesvVpTns2LHDMVZGs2bN9MUXX+jGjRtavHixhg8fbvnvrwznyj0ESF+HDh0yBQoUMM8884y5evWqMeZ/e59OnDhhbDabWbVqlStLdLh27ZrT/4sWLTI2m80MGDDAXLx40RhzZy/rkSNHXFGew91HIuLj440xxgwbNixJN6fE19tq7Ha7OXz4sOOI+qlTp4wxd7qcb9++3cTGxrqkrk2bNhk3NzdTv35907lzZ+Pr62t69OhhjLnTrTB37txm3759ltl7um3bNhMeHm6aNWtmypUrZ5o3b262b99ujh8/blauXGk8PT2djrK4QmK31s8++yzJEejLly+bwMBAs2vXLleUliy73W7Onz9vihYt6tRz4uTJkyY4ONh89NFHpnLlyo71wtUSjwB27tzZHDp0yGzatMn4+PiYCRMmGGOMKVu2rHn99dddXOUddrvdXL582bRp08a0b9/e3L592zLb0r3WrFljGjdubD744APzyCOPOD6jLl++bEaPHm0efvhhs2fPHpfUdubMGafH7tWrlwkJCTFPPfWUee+995zmHTBggClfvrzje8LVGjVqZIoUKWKaNGlivLy8nL77J0yYYB566CFz/Phxl9R25swZ06VLF5MzZ07zyCOPOL7zjTFm/vz5Jk+ePOarr75ySW3JOXz4sMmZM6eZP3++o+348eOmZs2aZuHChSZfvnxmxIgRLqzwTq/JRAsXLjQ2m81ERUWZP/74w3z//femRo0ajt5rVnD359G6detM2bJlzfXr140xxjz66KPGzc3NPProo+bs2bOuKtGcOXPG7N692/H/vZ+hI0aMMHnz5nWsv678jE38/k/snRATE2Pq16/v+I3Xv39/4+7ubvLkyWN++eUXl9V5r7lz55o2bdqYRYsWmaZNm5pz584ZY+5833bt2tU0bdrU6fMhuyGk/8N8++23xsvLy/Tp08ep+/jZs2dNlSpVzObNm11YXVJ3/3hM/GIZOHCgOX36tHnppZdM27ZtXRYk73Z3N/GhQ4c6uuoZY8y4cePMG2+8YW7duuWK0sy1a9dMTEyMuXLlilP73TUfOnTIEdSPHDli+vTpY6pXr+44j9IVfv75Z/P000+bHj16mBkzZjjaV6xYYcqXL28uX77sstqMuXO6w++//2727dtnjLnTvbFOnTrmkUceSXLO3PTp002BAgXMyZMnXfJFvWPHDtOyZUtz/fp1py7XibVcu3bNBAYGmm3btjmm/fjjj5lepzH/+zGRaPr06cZmszm6uOXKlcv07NnTGHOnS2FQUJC5ePFipp+qkdx2tWzZMhMYGGgKFSpk8uXLZ/r37++YVrduXTN48OBMrfFBPv/8c2Oz2cymTZtcXYrDve//3r17TdGiRU1wcLBp2rSp07QTJ04YHx8fs2DBgsws0Rjzv9MuHn/8cfPTTz8ZY4yJjY01lStXNjabzXFqQaJvvvnGVKlSxSWfqSl9B2zatMksX77chIaGmosXLzq+ozZv3mxKlSpl9u/fn+m1Jjp9+rQZMmSIWbdunTHGOeCUKlXqvmMUZIY//vjD7N271/H5P2LECOPp6WmGDh1q3nrrLePv72+effZZY4wxU6dONbVr1zbXrl2zxM6wY8eOOX3WG2NMRESEadWqlYsquiOl9fTMmTOmZcuWxhhjIiMjzb/+9S8zb948kytXLtO6dWvHjrvMdPf2f2+oTXyPo6OjTfny5c3gwYNd+r4nfv/f+1u5Ro0aZs2aNcYYY3r27Gly5cplvLy8zKJFixw7RDJb4naVeABs165dxtvb21StWtXR7T3Rvn37jM1mM19//bUrSrUEQvo/0BdffGG8vLxM27ZtzaJFi8zvv/9uBg8ebIoUKeI4N9lK7Ha74wf4okWLjIeHhylbtqzJkSOHpQZoS/wQHjp0qHn00UeNMcYMHz7c2Gw2s3PnTpfUtGfPHtOsWTNTtWpVU7RoUce4A8l9YRw+fNg0bNjQ2Gw24+vra37++efMLjeJ5OocMGCAadiwYZIv8sz022+/mapVq5pKlSoZDw8PxxGIffv2mSVLljiOliXWP336dFOpUiWXnJOcOGDY3ed1G/O/MBQfH2/OnTtnihYt6jjXc8iQIcZms5kLFy5kaq379+83U6ZMMWfOnHG0JSQkmHnz5pkaNWqY5s2bOw1y+c4775iqVatm+g+ge7erTz75xDHt6tWr5qeffjK//vqro+3mzZumefPmjp1NVvihbsydgbiaNWtmnnrqKZf9KLtbcu+/McZ8+eWXJkeOHKZQoUJOO5Lj4uJM48aNzerVqzO7VLN+/XqTI0cO07hxY9OlSxdHUP/xxx9N+fLlTWBgoFm9erWjV9jLL79sGjRokOk7lZP7Drh7h/GqVatMpUqVnJYZMGCAqV69url06VKm1nqvK1euOA0WZ7fbzcWLF01YWJjTUevMdvfnv6enpxk7dqw5ceKEGTNmjPn3v/9twsLCzGuvveaYf+jQoSYsLMxl9d5PQkKCuXHjhunQoYNLx/hI6beKMXe+qxo0aGCKFCliAgICHKF4w4YNJiAgwCWDct67/d+90yMhIcEkJCSYW7dumcjISBMWFuayHjSJ3/+vvPKKoy0uLs7Y7XbTqVMns3LlStO3b19TtGhRc/z4cdOvXz9HL4vMdu92lfi76r333jM5cuQwISEh5vDhw475L168aGrXrm2pI/+ZjZD+D7Vt2zbToEEDU7x4cVOyZElTpkwZs337dleXlaK7RyBu3LixyZcvn6W65hrzvyPTI0eONM8++6yZPHmy8fLySrLHOrOkdeT5uLg407FjR5MvXz6XdR+9n127dpnnn3/e+Pn5uWynhzEpj5KbOIBNckd0+/XrZ/7zn/9k+g/01IySbLfbTXR0tClatKg5cuSIee2110yuXLkyfSfNg67ocOPGDXPz5k2nthdeeMG0a9fO3LhxI9OCb0rbVUqfnzExMWbw4MGmUKFCTj8wrGL8+PHGz8/Ppd1GjXnw+79w4ULj5uZmwsPDzcKFC83BgwfN4MGDTdGiRV0y6NUff/xhWrdubd577z1TrVo189RTT5nff//dGHNnu2vYsKEJDAw0VapUMa1atTJ58uTJ9M+t1HwHXL582RQrVszUq1fPDB8+3HTv3t3kz5/fpZ+x9zNixAhTunRplw0Ydu/n/+TJk42bm5vjAMeff/6ZpJfXs88+a7p3727i4+Mts4PubsOHDzcPPfSQ0+l7melB6+mtW7fMsGHDTMOGDR2/pxJ3MrtqMM7ktv/Eru93/wY4cuSIsdlsSU5/yQwpff8nfo++9dZbxmazmcKFCzsF3QEDBmT64Iwp/a46fvy4uXHjhpk4caJxc3MzXbp0MRs2bDDnzp0zw4YNM0FBQS6/coorEdL/wa5cuWKOHj1qdu3aZbmR05Nz+/Zt89JLLxmbzeZ0lMpqxowZY2w2m/H393fZHr60jjyfkJBg3nnnHePu7m7JnTU3b940S5cuNR07dnTpe3+/UXJ/+OEHx3noiQ4dOmSGDx9u8uTJ43TuWmZIzSjJiV01b968aSpWrGiaNm1qPD09zdatWzO11tRc0eHu9XXv3r3mxRdfNLlz587UnXWp2a7u/oG2Y8cO07t3b1O0aFGX7axLSeLreenSJRMaGurSyxql9ooea9euNWFhYSYgIMCUK1fOZTuXb9++bS5cuGDKlCljTp06ZZYuXWpq1KhhevToYWrXru0Yk2TWrFlmxIgRZsKECZnedTw162riEfU9e/aYRo0ambCwMPPEE09YciftwoULzbPPPmvy5s3rsu+olD7/w8PDzQ8//GC2bdvm1Btx//79ZtCgQcbPzy/TP/9T47PPPjN9+vQx+fPnd9lrmpr11Jg732f39rAxxjW9klLa/nv27Glq165t/vOf/xhj7mxfMTEx5r///W+m7wC53/d/2bJlzVtvvWVmzZplXnrpJcfOkHtPNcos99uuNm/ebHbu3GmOHTtmVq5caYoVK2YCAgJM+fLlTfHixS35ezUz5XD1wHXIOH5+fvLz83N1GWlSoUIFbd++XZUrV3Z1KSkKDw/X8OHDtXnzZgUHB7ukhuRGnndzc0tx5Hk3NzcVL15ce/fuVenSpV1S8/14eXmpRYsWatasmXx9fV1WR+IouYmvq/S/UXLPnTunP/74Q8HBwRo+fLgKFy6sl19+Wb/++qvWr1+vChUqZHq9YWFhOnnypFasWKFZs2bp1q1bCgkJUVBQkN5++23t3r1bw4YNU44cObRnzx4dPHhQv/zyS6ZvX4lXdMifP786dOigAgUKqGPHjpKkQYMGqUCBAo719erVq1qzZo127NihDRs2qFKlSplWZ2q2q8QRiSUpJCRETZs21aBBg1SiRIlMqzM1El/PPHny6Pvvv3fpdpWa91+SmjRpopCQEF26dEmxsbH617/+5ZiW2fUWLFhQNWrU0O7du/X444/Ly8tLXbt21c2bNxUZGSlJ6tWrV6bXlig162qOHHd+4gUHB+vbb79VXFycbDab4+oEVhIcHKxPP/1UGzdudMlnqZTy5/8333yj8+fP6+LFi6pQoYKGDRum0NBQffrpp1q/fr2+//57l9V8P8HBwVqyZIk2btyo8uXLu6SG1KyndrtdhQsXTnZ5V4zqfb/tPy4uTj179pR0Z/vKnTu3Jk+eLC8vr0yvM6Xv/+LFi2v69Ol65JFH9Nxzz6lixYqS7lyhwhXut12dO3dOly5dUrly5TRr1ixt27ZNR48eVXx8vEqXLq0iRYq4pGbLcPVeAuBuVuwqlpx7R6d3hdSOPH/3qK94sNSMkjt69GgTHx9vvv32W5ceoUzNKMlffvmlMcaYadOmufQIWmqu6HD79m1z/vx5c+vWLZedL5va7cqVYyZkRal5/2/duuXS7eleXbp0cQwG2L17d5M3b14THBxsnnnmGaeBF131vZXaddXVg3Cm1t2n6bhKWkZJP336tDl//ryrSk0VK1xtIKteJed+23/iGBWudL/v/08++cRSV0m433b13XffmdDQUJdfIcGKOJIOS8kq10J05VGpRIlHxO12uzw8PCTduX7n3ddqHj9+vLy8vNS3b1/HURXcX+7cuR1/h4WFaevWrapWrZokqX79+ipUqJC2bt0qDw8PNWrUyFVlSpKKFCmi8ePHq1ixYmratKny58/vuBZ6p06dNHLkSH3//feKiIjQCy+84LI96dL/tpmEhAS5ubmpQ4cOMsaoU6dOstlsevHFFzVlyhQdPXpUCxYsUN68eV1SJ9tVxkjt+3/8+HF9/PHH8vHxcdn3QeI21LhxYx09elTPP/+8vvrqK23btk07d+7UwIED5enpqZCQEHl5ebmszn/aumqFI/yp/fw3xqho0aKuKjPVEtcLV8pq62lqt//KlSvL29vbZXXe7/v/6aef1ujRo7V+/Xo9+uijLqsx0f22qwYNGqhw4cLavn27q8qzLGt/YgN4IDc3N8cHc+L/kjRixAiNGTNGO3bscPmXXlZVvHhxFS9eXNKdHxjx8fHKlSuXpU7HKFq0qAYPHuz4sWCz2WSM0aVLl1SwYEFHra4M6Hdzd3eXMUZ2u10dO3aUzWZT586d9cUXX+jw4cP6+eeflTNnTleXyXaVQR70/v/yyy8u3wma+J6XKFFCkZGRCggI0JdffqkSJUqoRIkSstlsqlKliku6uCaHdTVj3O/zP6scULCSrLKepnb7d2VAT/Sg7/+QkBDXFpiMrPC7yircHjwLAKszxki6c45UYGCgpkyZokmTJmnr1q2qUqWKi6v7Z3Bzc9O4ceO0ZcsWPfHEE64ux4mfn5/TUSibzaa3335bFy9eVL169VxYWfJsNpvjx0SHDh1Ur149RUdHa/v27apataqry3Ngu8oY93v/rfSjMiwsTB988IG+/vprhYaGOtaHNm3aWG4MAtbVjGXlz/+sJCutp1ll+7/f93+dOnVcWNmDsV3dn+t3WQH42xL3SHt4eOj999+Xn5+fNm3a5OhOhL9n8eLF+v7777Vo0SKtWbPGkoPvJVq0aJHWr1+vxYsXa926dY491lZjs9mUkJCggQMHav369dq5c2emDhKXGmxXGScrvP8eHh7q1q2bYz2w8tFT1tWMk5U+/60uK62nWWn7T5RVvv8ltqvU4Eg68A8SHh4uSdq8ebOqV6/u4mr+OYKDgxUdHa2NGzda6khvcoKDg3X69OksUauUda7oILFdZQSrv/93j+afFbCupr+s9PmfVWSV9TSrbf9Z6fuf7erBbCax/waAf4TY2FiXn9P5T3Tr1i1LDMKTGvHx8ZYYhCk17j5H0crYrjJGVnn/sxLW1fSXlT7/swrW04yRlb7/2a7uj5AOAAAAAIBFZK1+HAAAAAAA/IMR0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAABLs9lsWr58uavLAAAgUxDSAQBwgW7duslmsyW5HTp0KF3uf968ecqTJ0+63Ndf1a1bN7Vp08alNQAAkNXkcHUBAABkV82bN9fcuXOd2goWLOiialJ269YteXh4uLoMAACyBY6kAwDgIl5eXipcuLDTzd3dXZK0YsUKVatWTd7e3vr3v/+t0aNH6/bt245lp06dqkqVKsnX11eBgYF6/vnnde3aNUnSd999p8jISF25csVxhH7UqFGSku86nidPHs2bN0+SdOzYMdlsNkVFRalBgwby9vbW/PnzJUkffPCBypcvL29vb5UrV04zZ85M0/Nt2LCh+vbtq0GDBilfvnwqXLiwo65EBw8eVP369eXt7a3g4GCtWbMmyf2cPHlS7du3V548eZQvXz499thjOnbsmCRp37598vHx0YIFCxzzf/bZZ8qZM6d+//33NNULAIArENIBALCYjRs3qkuXLurXr59+//13vffee5o3b57Gjh3rmMfNzU1vv/229uzZo48++kjffvutBg0aJEmqXbu2pk2bJj8/P509e1Znz57VgAED0lTD4MGD1a9fP+3du1fh4eGaP3++RowYobFjx2rv3r0aN26chg8fro8++ihN9/vRRx/J19dXP/30kyZNmqTXXnvNEcTtdrvatm0rT09P/fTTT5o1a5ZeeeUVp+Vv3bql8PBw5c6dWxs3btQPP/ygXLlyqXnz5oqPj1e5cuU0ZcoUPf/88zpx4oROnTql3r17a+LEiQoODk5TrQAAuIQBAACZrmvXrsbd3d34+vo6bu3atTPGGNOkSRMzbtw4p/k/+eQTU6RIkRTvb/HixSZ//vyO/+fOnWv8/f2TzCfJLFu2zKnN39/fzJ071xhjzNGjR40kM23aNKd5SpYsaRYsWODU9vrrr5uwsLD7PsfHHnvM8X+DBg1M3bp1neapUaOGeeWVV4wxxnz99dcmR44c5vTp047pq1atcqr5k08+MWXLljV2u90xT1xcnMmZM6f5+uuvHW0RERGmXr16pkmTJqZZs2ZO8wMAYGWckw4AgIs0atRI7777ruN/X19fSdKvv/6qH374wenIeUJCgm7evKnr16/Lx8dHa9eu1fjx47Vv3z7FxMTo9u3bTtP/rurVqzv+jo2N1eHDh9W9e3f17NnT0X779m35+/un6X4rV67s9H+RIkV04cIFSdLevXsVGBiookWLOqaHhYU5zf/rr7/q0KFDyp07t1P7zZs3dfjwYcf/c+bMUZkyZeTm5qY9e/bIZrOlqU4AAFyFkA4AgIv4+vqqVKlSSdqvXbum0aNHq23btkmmeXt769ixY2rZsqWee+45jR07Vvny5dOmTZvUvXt3xcfH3zek22w2GWOc2m7dupVsbXfXI0nvv/++atWq5TRf4jn0qXXvAHQ2m012uz3Vy1+7dk2hoaGO8+Tvdvege7/++qtiY2Pl5uams2fPqkiRImmqEwAAVyGkAwBgMdWqVdP+/fuTDfCStG3bNtntdr3xxhtyc7szvMxnn33mNI+np6cSEhKSLFuwYEGdPXvW8f/Bgwd1/fr1+9YTEBCgokWL6siRI3rqqafS+nRSrXz58jp58qRTqP7xxx+d5qlWrZqioqJUqFAh+fn5JXs/ly5dUrdu3TR06FCdPXtWTz31lLZv366cOXNmWO0AAKQXBo4DAMBiRowYoY8//lijR4/Wnj17tHfvXi1atEjDhg2TJJUqVUq3bt3SO++8oyNHjuiTTz7RrFmznO4jKChI165d07p163Tx4kVHEG/cuLGmT5+uHTt2aOvWrerdu3eqLq82evRojR8/Xm+//bYOHDig3377TXPnztXUqVPT7Xk3bdpUZcqUUdeuXfXrr79q48aNGjp0qNM8Tz31lAoUKKDHHntMGzdu1NGjR/Xdd9+pb9++OnXqlCSpd+/eCgwM1LBhwzR16lQlJCSkeeA8AABchZAOAIDFhIeH68svv9Q333yjGjVq6OGHH9abb76p4sWLS5KqVKmiqVOnauLEiapYsaLmz5+v8ePHO91H7dq11bt3b3Xo0EEFCxbUpEmTJElvvPGGAgMDVa9ePXXq1EkDBgxI1TnsPXr00AcffKC5c+eqUqVKatCggebNm6cSJUqk2/N2c3PTsmXLdOPGDdWsWVM9evRwOi9fknx8fLRhwwY99NBDatu2rcqXL6/u3bvr5s2b8vPz08cff6yvvvpKn3zyiXLkyCFfX199+umnev/997Vq1ap0qxUAgIxiM/eemAYAAAAAAFyCI+kAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALOL/Ac6ueVpGI5NgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the top N features by frequency\n",
    "N = 20  # Adjust as needed\n",
    "top_features = feature_counts_df.nlargest(N, \"count\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Note: Converting feature_index to string (astype(str)) ensures proper labeling on the x-axis.\n",
    "plt.bar(top_features[\"feature_index\"].astype(str), top_features[\"count\"])\n",
    "plt.xlabel(\"Feature Index\")\n",
    "plt.ylabel(\"Activation Count\")\n",
    "plt.title(f\"Top {N} Most Frequently Activated Features\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d9ac6",
   "metadata": {},
   "source": [
    "#### Feature Activation Values for Specific Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fdeef966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Plot activation value distribution for a specific feature\n",
    "feature_index_to_plot = 47  # Replace with the feature index you're interested in\n",
    "feature_data = all_data[all_data[\"feature_index\"] == feature_index_to_plot]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(feature_data[\"activation_value\"], bins=50)\n",
    "plt.xlabel(\"Activation Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(f\"Activation Value Distribution for Feature {feature_index_to_plot}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ae1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e041c7e",
   "metadata": {},
   "source": [
    "### Automated Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5218483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have the model summarize each example\n",
    "\n",
    "# TODO(bschoen): Could group different examples together if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5b079eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron_explainer.activations.activation_records import calculate_max_activation\n",
    "from neuron_explainer.activations.activations import ActivationRecord\n",
    "from neuron_explainer.explanations.calibrated_simulator import (\n",
    "    UncalibratedNeuronSimulator,\n",
    ")\n",
    "from neuron_explainer.explanations.explainer import (\n",
    "    HARMONY_V4_MODELS,\n",
    "    ContextSize,\n",
    "    TokenActivationPairExplainer,\n",
    ")\n",
    "from neuron_explainer.explanations.explanations import ScoredSimulation\n",
    "from neuron_explainer.explanations.few_shot_examples import FewShotExampleSet\n",
    "from neuron_explainer.explanations.prompt_builder import PromptFormat\n",
    "from neuron_explainer.explanations.scoring import (\n",
    "    _simulate_and_score_sequence,\n",
    "    aggregate_scored_sequence_simulations,\n",
    ")\n",
    "from neuron_explainer.explanations.simulator import (\n",
    "    LogprobFreeExplanationTokenSimulator,\n",
    "    NeuronSimulator,\n",
    ")\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "69277dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mActivationRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m        \n",
      "\u001b[0;34m@\u001b[0m\u001b[0mregister_dataclass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mclass\u001b[0m \u001b[0mActivationRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFastDataclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Collated lists of tokens and their activations for a single neuron.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Tokens in the text sequence, represented as strings.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mactivations\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Raw activation values for the neuron on each token in the text sequence.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m           ~/gpt_from_scratch/venv/lib/python3.12/site-packages/neuron_explainer/activations/activations.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "ActivationRecord??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "94055695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 58 activation range: [1.29, 1.29]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "feature_index = 58\n",
    "\n",
    "top_activations_for_feature = top_activations_per_feature[\n",
    "    (top_activations_per_feature[\"feature_index\"] == feature_index)\n",
    "    & (top_activations_per_feature[\"k\"] == 0)\n",
    "]\n",
    "\n",
    "activation_min = top_activations_for_feature[\"activation_value\"].min()\n",
    "activation_max = top_activations_for_feature[\"activation_value\"].max()\n",
    "\n",
    "# TODO(bschoen): Can give this to model\n",
    "print(f\"Feature {feature_index} activation range: [{activation_min:.2f}, {activation_max:.2f}]\")\n",
    "\n",
    "# sample some so we're not always taking nearly identical strings (this is fine because\n",
    "# our data is so compact, we likely don't have far spread in activation values\n",
    "top_activations_for_feature = top_activations_for_feature.sort_values(\n",
    "    \"activation_value\", ascending=False\n",
    ").head(10)\n",
    "\n",
    "print(len(top_activations_for_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "54eca82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_index</th>\n",
       "      <th>activation_value</th>\n",
       "      <th>position</th>\n",
       "      <th>k</th>\n",
       "      <th>token_string</th>\n",
       "      <th>hook_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;mwfk|fkm</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48120</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;gqff|f</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55330</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;xxfa|a</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54210</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;lofz|f</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53195</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;fwfm|f</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52600</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;mtfj|f</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50640</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;yefs|e</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50500</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;rqfw|f</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49835</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;pgfs|f</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48820</th>\n",
       "      <td>58</td>\n",
       "      <td>1.286841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;kjfv|f</td>\n",
       "      <td>blocks.0.hook_resid_pre</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_index  activation_value  position  k token_string  \\\n",
       "1635              58          1.286841         3  0    <mwfk|fkm   \n",
       "48120             58          1.286841         3  0      <gqff|f   \n",
       "55330             58          1.286841         3  0      <xxfa|a   \n",
       "54210             58          1.286841         3  0      <lofz|f   \n",
       "53195             58          1.286841         3  0      <fwfm|f   \n",
       "52600             58          1.286841         3  0      <mtfj|f   \n",
       "50640             58          1.286841         3  0      <yefs|e   \n",
       "50500             58          1.286841         3  0      <rqfw|f   \n",
       "49835             58          1.286841         3  0      <pgfs|f   \n",
       "48820             58          1.286841         3  0      <kjfv|f   \n",
       "\n",
       "                     hook_name  \n",
       "1635   blocks.0.hook_resid_pre  \n",
       "48120  blocks.0.hook_resid_pre  \n",
       "55330  blocks.0.hook_resid_pre  \n",
       "54210  blocks.0.hook_resid_pre  \n",
       "53195  blocks.0.hook_resid_pre  \n",
       "52600  blocks.0.hook_resid_pre  \n",
       "50640  blocks.0.hook_resid_pre  \n",
       "50500  blocks.0.hook_resid_pre  \n",
       "49835  blocks.0.hook_resid_pre  \n",
       "48820  blocks.0.hook_resid_pre  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_activations_for_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c8607c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<task-description>\n",
      "Generate a human readable explanation for a feature activation in a transformer model that sorts characters in a sequence. The transformerm odel is given at least the first half of a sequence and must produce the second half in sorted order. Pay especially close attention to anything that could prove your explanation wrong to avoid outputting incorrect explanations!\n",
      "\n",
      "Please generate an explanation for <feature>58</feature>\n",
      "\n",
      "</task-description>\n",
      "\n",
      "<max-activating-examples-for-feature>\n",
      "Top 10 Examples for <feature>58</feature>:\n",
      "\n",
      "<activation> 1.29 </activation>\t<full-string> < m w \u001b[1m\u001b[31m<token>f</token>\u001b[0m k | f k m </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < g q \u001b[1m\u001b[31m<token>f</token>\u001b[0m f | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < x x \u001b[1m\u001b[31m<token>f</token>\u001b[0m a | a </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < l o \u001b[1m\u001b[31m<token>f</token>\u001b[0m z | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < f w \u001b[1m\u001b[31m<token>f</token>\u001b[0m m | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < m t \u001b[1m\u001b[31m<token>f</token>\u001b[0m j | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < y e \u001b[1m\u001b[31m<token>f</token>\u001b[0m s | e </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < r q \u001b[1m\u001b[31m<token>f</token>\u001b[0m w | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < p g \u001b[1m\u001b[31m<token>f</token>\u001b[0m s | f </full-string>\n",
      "<activation> 1.29 </activation>\t<full-string> < k j \u001b[1m\u001b[31m<token>f</token>\u001b[0m v | f </full-string>\n",
      "</max-activating-examples-for-feature>\n",
      "\n",
      "<example-full-string-all-features>\n",
      "<full-string> < m w f k | f k m </full-string>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>0</position>\n",
      "<token><</token>:\n",
      "<feature>19</feature>\t<activation>0.7099</activation> <k>0</k>\n",
      "<feature>29</feature>\t<activation>0.2636</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>1</position>\n",
      "<token>m</token>:\n",
      "<feature>25</feature>\t<activation>1.1649</activation> <k>0</k>\n",
      "<feature>9</feature>\t<activation>0.1280</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>2</position>\n",
      "<token>w</token>:\n",
      "<feature>63</feature>\t<activation>0.7523</activation> <k>0</k>\n",
      "<feature>16</feature>\t<activation>0.5024</activation> <k>1</k>\n",
      "<feature>21</feature>\t<activation>0.0577</activation> <k>2</k>\n",
      "<feature>13</feature>\t<activation>0.0449</activation> <k>3</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>3</position>\n",
      "<token>f</token>:\n",
      "<feature>58</feature>\t<activation>1.2868</activation> <k>0</k>\n",
      "<feature>21</feature>\t<activation>0.2299</activation> <k>1</k>\n",
      "<feature>9</feature>\t<activation>0.0051</activation> <k>2</k>\n",
      "<feature>35</feature>\t<activation>0.0023</activation> <k>3</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>4</position>\n",
      "<token>k</token>:\n",
      "<feature>46</feature>\t<activation>1.3696</activation> <k>0</k>\n",
      "<feature>20</feature>\t<activation>0.9244</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>5</position>\n",
      "<token>|</token>:\n",
      "<feature>7</feature>\t<activation>1.2500</activation> <k>0</k>\n",
      "<feature>52</feature>\t<activation>1.0267</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>6</position>\n",
      "<token>f</token>:\n",
      "<feature>4</feature>\t<activation>1.0818</activation> <k>0</k>\n",
      "<feature>36</feature>\t<activation>0.7514</activation> <k>1</k>\n",
      "<feature>24</feature>\t<activation>0.0301</activation> <k>2</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>7</position>\n",
      "<token>k</token>:\n",
      "<feature>47</feature>\t<activation>1.0762</activation> <k>0</k>\n",
      "<feature>20</feature>\t<activation>0.9357</activation> <k>1</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>2</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>2</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "\n",
      "<top-5-activating-features-at-position>\n",
      "<position>8</position>\n",
      "<token>m</token>:\n",
      "<feature>3</feature>\t<activation>1.3312</activation> <k>0</k>\n",
      "<feature>15</feature>\t<activation>0.9292</activation> <k>1</k>\n",
      "<feature>25</feature>\t<activation>0.0856</activation> <k>2</k>\n",
      "<feature>0</feature>\t<activation>0.0000</activation> <k>3</k>\n",
      "<feature>1</feature>\t<activation>0.0000</activation> <k>4</k>\n",
      "</top-5-activating-features-at-position>\n",
      "</example-full-string-all-features>\n",
      "\n",
      "Remember, your task is generate a very brief, concise, useful explanation for interpreting <feature>58</feature> and a score between 0 and 10 for how confident you are in your explanation. \n",
      "\n",
      "Please output in the following format:\n",
      "\n",
      "<explanation-text>EXPLANATION</explanation-text>\n",
      "<explanation-confidence-score-0-to-10>SCORE</explanation-confidence-score-0-to-10>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO(bschoen): Could do this with tool use or structured output, but better to be able to do it with o1\n",
    "def generate_complete_explanation_request_prompt_for_feature(feature_index: int) -> str:\n",
    "    prompt = rf\"\"\"\n",
    "<task-description>\n",
    "Generate a human readable explanation for a feature activation in a transformer model that sorts characters in a sequence. The transformer model is given at least the first half of a sequence and must produce the second half in sorted order. Pay especially close attention to anything that could prove your explanation wrong to avoid outputting incorrect explanations!\n",
    "\n",
    "Please generate an explanation for <feature>{feature_index}</feature>\n",
    "\n",
    "</task-description>\n",
    "\n",
    "<max-activating-examples-for-feature>\n",
    "{display_top_examples_for_feature(feature_index, top_n=10)}\n",
    "</max-activating-examples-for-feature>\n",
    "\n",
    "<example-full-string-all-features>\n",
    "{display_top_features_for_top_token_string(feature_index)}\n",
    "</example-full-string-all-features>\n",
    "\n",
    "Remember, your task is generate a very brief, concise, useful explanation for interpreting <feature>{feature_index}</feature> and a score between 0 and 10 for how confident you are in your explanation. \n",
    "\n",
    "Please output in the following format:\n",
    "\n",
    "<explanation-text>EXPLANATION</explanation-text>\n",
    "<explanation-confidence-score-0-to-10>SCORE</explanation-confidence-score-0-to-10>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "print(generate_complete_explanation_request_prompt_for_feature(58))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "31f5e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def format_text(text):\n",
    "    \"\"\"\n",
    "    Replaces escaped text in angle brackets with colored text.\n",
    "    \"\"\"\n",
    "    # Mapping of tags to colors\n",
    "    tag_colors = {\n",
    "        \"feature\": \"blue\",\n",
    "        \"activation\": \"green\",\n",
    "        \"token\": \"red\",\n",
    "        \"full-string\": \"cyan\",\n",
    "        \"position\": \"yellow\",\n",
    "        \"top-5-activating-features-at-position\": \"magenta\",\n",
    "        \"k\": \"white\",\n",
    "        # Add more tags and colors as needed\n",
    "    }\n",
    "\n",
    "    # Wrap the text in a root element to make it valid XML\n",
    "    wrapped_text = f\"<root>{text}</root>\"\n",
    "\n",
    "    # Parse the text with BeautifulSoup\n",
    "    soup = BeautifulSoup(wrapped_text, \"html.parser\")\n",
    "\n",
    "    def traverse(element):\n",
    "        result = \"\"\n",
    "        for content in element.contents:\n",
    "            if isinstance(content, str):\n",
    "                # Clean up whitespace\n",
    "                result += content\n",
    "            else:\n",
    "                tag = content.name\n",
    "                color = tag_colors.get(tag, \"white\")\n",
    "                inner_text = traverse(content)\n",
    "                # Apply color to inner text\n",
    "                colored_text = colored(inner_text.strip(), color)\n",
    "                result += colored_text\n",
    "        return result\n",
    "\n",
    "    formatted_text = traverse(soup)\n",
    "\n",
    "    # Further formatting for readability\n",
    "    lines = formatted_text.split(\"\\n\")\n",
    "    formatted_lines = []\n",
    "    for line in lines:\n",
    "        # Remove extra spaces and tabs\n",
    "        line = line.strip()\n",
    "        if line == \"---\":\n",
    "            # Add separator lines\n",
    "            formatted_lines.append(\"-\" * 40)\n",
    "        elif line:\n",
    "            formatted_lines.append(line)\n",
    "    return \"\\n\".join(formatted_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "e64ec338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(feature_indices)=35\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from jaxtyping import Float, Int\n",
    "import openai\n",
    "import tqdm\n",
    "\n",
    "import tenacity\n",
    "\n",
    "FeatureIndex = int\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class FeatureExplanation:\n",
    "    text: str\n",
    "    confidence_score: float | None\n",
    "\n",
    "\n",
    "def parse_explanation(response_text: str) -> FeatureExplanation:\n",
    "    \"\"\"\n",
    "    Parse the explanation text and confidence score from the API response.\n",
    "\n",
    "    Expects the response to contain <explanation-text> and <explanation-confidence-score-0-to-10> tags.\n",
    "    \"\"\"\n",
    "    explanation = None\n",
    "    confidence_score = None\n",
    "\n",
    "    # Regex patterns to extract the required fields\n",
    "    explanation_pattern = re.compile(r\"<explanation-text>(.*?)<\\/explanation-text>\", re.DOTALL)\n",
    "    confidence_pattern = re.compile(\n",
    "        r\"<explanation-confidence-score-0-to-10>(\\d+)<\\/explanation-confidence-score-0-to-10>\"\n",
    "    )\n",
    "\n",
    "    explanation_match = explanation_pattern.search(response_text)\n",
    "    confidence_match = confidence_pattern.search(response_text)\n",
    "\n",
    "    if explanation_match:\n",
    "        explanation = explanation_match.group(1).strip()\n",
    "    else:\n",
    "        print(f\"Warning: <explanation-text> tag not found: {response_text}\")\n",
    "\n",
    "    if confidence_match:\n",
    "        confidence_score = float(confidence_match.group(1).strip())\n",
    "    else:\n",
    "        print(f\"Warning: <explanation-confidence-score-0-to-10> tag not found: {response_text}\")\n",
    "\n",
    "    return FeatureExplanation(explanation, confidence_score)\n",
    "\n",
    "\n",
    "@tenacity.retry(\n",
    "    wait=tenacity.wait_random_exponential(min=1, max=60),\n",
    "    stop=tenacity.stop_after_attempt(3),\n",
    ")\n",
    "def get_model_generated_feature_explanation(\n",
    "    client: openai.OpenAI,\n",
    "    feature_index: int,\n",
    ") -> FeatureExplanation:\n",
    "\n",
    "    prompt = generate_complete_explanation_request_prompt_for_feature(feature_index)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"<feature>{feature_index}</feature>\"},\n",
    "        ],\n",
    "        max_tokens=256,  # TODO(bschoen): Is this way too high?\n",
    "    )\n",
    "\n",
    "    # Parse the response\n",
    "    return parse_explanation(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "def get_model_generated_feature_explanations(\n",
    "    client: openai.OpenAI,\n",
    "    feature_indices: list[FeatureIndex],\n",
    ") -> dict[FeatureIndex, FeatureExplanation]:\n",
    "    \"\"\"Generate explanations for a list of feature indices using the OpenAI API.\"\"\"\n",
    "    feature_index_to_explanation: dict[FeatureIndex, FeatureExplanation] = {}\n",
    "\n",
    "    for feature_index in tqdm.tqdm(feature_indices):\n",
    "\n",
    "        feature_explanation = get_model_generated_feature_explanation(client, feature_index)\n",
    "\n",
    "        feature_index_to_explanation[feature_index] = feature_explanation\n",
    "\n",
    "    return feature_index_to_explanation\n",
    "\n",
    "\n",
    "# note: not all numbers 0 to 64 are features\n",
    "#\n",
    "# also we only use features that have top examples\n",
    "#\n",
    "# TODO(bschoen): Which ones are we missing?\n",
    "feature_indices = sorted(\n",
    "    top_activations_per_feature[top_activations_per_feature[\"k\"] == 0][\"feature_index\"]\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "print(f\"{len(feature_indices)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "763d2dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [01:57<00:00,  3.35s/it]\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI()\n",
    "\n",
    "feature_explanations = get_model_generated_feature_explanations(client, feature_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70551e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 35/35 [00:00<00:00, 935.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "\n",
      "feature_index=0 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 0 likely activates when the character 'a' in the second half of the sequence is being\n",
      "processed. This is evident because all of the top-activating examples for Feature 0 have 'a' as the\n",
      "first character in the second half of the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=1 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 1 is activated when the token 'b' appears in the sequence that needs to be completed or\n",
      "sorted. This indicates that Feature 1 might be responsible for identifying the occurrence of the\n",
      "token 'b' as part of the input sequence to assist in completing the sequence in sorted order.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=2 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 2 appears to be significantly activated when the token 'd' appears in the output sequence,\n",
      "especially around the sorted part of the sequence. This suggests that Feature 2 might be responsible\n",
      "for identifying or determining the presence and positioning of the token 'd' in the second half of\n",
      "the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=3 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 3 appears to be highly activated for the character 'j' in the second half of the sequence.\n",
      "This pattern is consistent across all examples, indicating that Feature 3 is likely identifying the\n",
      "presence or position of the character 'j' specifically in the output sequence after the sorting\n",
      "operation.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=4 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 4 appears to be highly active when the character 'f' appears in the second half of the\n",
      "sequence. This suggests that Feature 4 is likely associated with detecting or predicting the\n",
      "character 'f' specifically in the sorted output segment of the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=5 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 5 appears to be highly activated when the model processes the character 'a' in the sequence,\n",
      "regardless of its position. This suggests that Feature 5 might specifically detect the presence of\n",
      "the character 'a', which could be relevant for sorting tasks where 'a' is the smallest and\n",
      "potentially an influential character in the sorting operation.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=7 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 7 appears to be highly activated at the position of the token \"|\", which separates the first\n",
      "half of the sequence from the second half. This suggests that Feature 7 is likely involved in\n",
      "signaling the boundary where the sorting process for the second half should begin. It seems to\n",
      "function as an indicator for the model to switch from processing the given segment to generating the\n",
      "sorted segment.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=10 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 10 is consistently activated by the presence of the character 'l' in the sequence. It serves\n",
      "as an indicator of the 'l' token, likely playing a role in marking or processing this specific\n",
      "character within the model's mechanism for sorting characters in the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=12 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 12 appears to be highly activated when the token 'q' is present in the sequence. This\n",
      "suggests that Feature 12 is specifically sensitive to or identifies the presence of the character\n",
      "'q' in the input sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=13 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 13 appears to be highly activated by the token \"v\" within sequences, potentially serving as\n",
      "a signal to identify the presence of this character when processing the input. This consistent\n",
      "activation suggests that Feature 13 plays a role in recognizing and processing the token \"v,\" which\n",
      "is essential for correctly sorting and generating the second half of the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=14 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 14 appears to activate strongly in sequences where the character 'c' is present. Based on\n",
      "the top-activating examples, the highest activations consistently occur with the token 'c' in the\n",
      "predicted sequence. This suggests that Feature 14 likely plays a role in detecting or confirming the\n",
      "presence of the character 'c' during the generation of the sorted second half of the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=15 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 15 appears to specifically activate for the character 'm' when it is present in the second\n",
      "half of the sequence after the boundary marker '|'. All the top 10 examples show high activation of\n",
      "Feature 15 for 'm' post-boundary, suggesting that Feature 15 is used by the transformer model to\n",
      "identify and possibly handle occurrences of 'm' as part of its sorting task.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=18 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 18 appears to activate strongly when the token 'p' occurs in the first half of the sequence.\n",
      "Given the specific activated examples, it is likely contributing to recognizing or handling the\n",
      "presence of the character 'p' for the sorting task in the transformer model.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=19 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 19 appears to be highly activated in the presence of the \"<\" token, which always occurs at\n",
      "the beginning of the sequence. This suggests that Feature 19 plays a role in recognizing the start\n",
      "of a sequence that needs to be sorted. Therefore, Feature 19 is likely involved in identifying the\n",
      "starting point or the context of the sequence to be processed by the transformer model.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=20 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 20 seems to be activated by the presence of the character 'k' in the first half of the\n",
      "sequence, regardless of its position. This pattern is consistent in the provided top 10 examples,\n",
      "where 'k' appears in the first half of each sequence and the feature shows high activation.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=23 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 23 appears to be associated with the presence and placement of the character 'z' in the\n",
      "second half of the sorted sequence. This is inferred from the high activation values for sequences\n",
      "where 'z' is the expected token in the sorted second half, despite variation in the other\n",
      "characters.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=24 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 24 appears to be activated by characters in the second half of the sequence, specifically\n",
      "when the character being predicted is 'z' or lower alphabetical-order characters. It consistently\n",
      "has strong activation when the token following the vertical bar is 'z'. This feature seems to play a\n",
      "role in predicting or validating the presence of lower alphabetical-order characters (likely 'z') in\n",
      "the sorted continuation of the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=25 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 25 seems to be highly activated by the presence of the token 'm' in the sequence. This is\n",
      "evident from the fact that it is the top activating feature when 'm' appears in various positions,\n",
      "both before and after the delimiter '|'. This suggests that Feature 25 may be associated with\n",
      "identifying or emphasizing the token 'm' in the input sequence, regardless of its position.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=28 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 28 appears to strongly activate for the token 'u' in a sequence, suggesting that it plays a\n",
      "role in identifying or processing this specific character. This can be inferred from consistent high\n",
      "activations for 'u' across all top-activating examples.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=30 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 30 is highly activated when the character 'q' appears in the second half of the sequence\n",
      "after the sorting is completed. This suggests that Feature 30 is used by the model to identify or\n",
      "confirm the presence of the character 'q' in its correct sorted position in the output sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=31 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 31 appears to be highly activated by the presence of the token 'e' in the first half of the\n",
      "sequence. This suggests that Feature 31 could be contributing to the identification or handling of\n",
      "the character 'e' within the sequence, potentially marking its importance or preparing for its\n",
      "position in the sorted output of the second half. The consistent activation across examples implies\n",
      "a specific role related to processing or recognizing 'e' in the initial sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=32 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 32 appears to be activated when the token 'e' is part of the second half of the sequence\n",
      "that should be in sorted order. This is suggested by the consistent presence of 'e' at the\n",
      "activating positions in the top examples. Additionally, it seems to be related to the presence of\n",
      "'e' both in the first half and the sorted second half of the sequences.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=33 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 33 is strongly associated with the character 'd'. It activates maximally for the token 'd'\n",
      "in the sequence, indicating it plays a role in identifying or processing this specific character for\n",
      "subsequent operations like sorting or pattern recognition in the given machine learning task.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=34 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 34 appears to be highly activated in the presence of the token 'c', particularly when this\n",
      "token appears at the beginning of the sequence provided. In the given examples, the token 'c' is\n",
      "consistently present early in the sequence, suggesting that this feature might be related to\n",
      "detecting or handling sequences that start with 'c', which could help in decisions related to\n",
      "sorting or sequence generation.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=38 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 38 appears to be strongly associated with detecting the character 'c' in the sorted sequence\n",
      "of the second half. It activates consistently when 'c' is expected to be placed in the correct\n",
      "position during the sorting process, suggesting it plays a role in identifying and confirming the\n",
      "presence of 'c' in the output sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=43 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 43 activates in sequences where the token 'a' is present in the second half of the sequence,\n",
      "especially when it appears frequently or predominantly after the dividing marker '|'. This feature\n",
      "likely contributes to identifying and ensuring the sorting of 'a's in the output sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=44 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 44 is highly activated by the token \"z\", which appears in the first half of sequences where\n",
      "the model must produce the second half in sorted order. This suggests that Feature 44 is likely\n",
      "responsible for identifying the presence of the letter \"z\" in the initial sequence, potentially as a\n",
      "signal for the sorting operation or a trigger for considering specific sorting rules.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=45 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 45 appears to be activated when the character 'p' is in the output sequence. This is evident\n",
      "because, in all the top 10 activating examples, the token 'p' is consistently present in the second\n",
      "half of the sequence, specifically occupying one of the positions where feature 45 has a high\n",
      "activation. The model seems to use this feature to identify and generate the character 'p' as part\n",
      "of the sorted output sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=46 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 46 is highly activated by the token 'k' within sequences where 'k' needs to be identified or\n",
      "sorted. This is evident from examples where 'k' appears as part of the input sequence that requires\n",
      "sorting. In these cases, the activation is consistently high around the token 'k', suggesting a\n",
      "strong association with recognizing or processing 'k' for sorting purposes.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=47 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 47 appears to be highly active when the character 'k' appears in the second half of the\n",
      "sequence that needs to be sorted. All top activating examples show 'k' in the second half,\n",
      "suggesting that this feature is likely associated with identifying or handling the character 'k'\n",
      "when sorting characters in the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=54 - explanation.confidence_score=8.0\n",
      "\n",
      "Feature 54 is highly activated by the presence of the token 'y'. This suggests that Feature 54 is\n",
      "likely associated with identifying or responding to the character 'y' in the input sequence.\n",
      "However, the activation does not vary to different extents depending on the surrounding characters\n",
      "or other tokens, which implies that Feature 54 consistently responds to 'y' regardless of its\n",
      "context within the sequence.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=58 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 58 seems to strongly activate for the token 'f', indicating that it plays a role in\n",
      "identifying or producing the token 'f' as part of the sequence generation or sorting mechanism.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=59 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 59 appears to be strongly associated with the token \"x\" appearing in the sorted section (the\n",
      "second half) of the sequence. This feature activates especially when \"x\" is positioned correctly in\n",
      "the sequence according to the sorting rules.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=62 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 62 appears to be highly activated in sequences where the token 'b' is encountered. This\n",
      "suggests that feature 62 may play a role in recognizing or processing the 'b' character within the\n",
      "input sequence, potentially influencing the subsequent sorting or completion of the sequence. Given\n",
      "that the feature consistently shows the highest activation at positions containing 'b', it is likely\n",
      "key to the model's behavior when dealing with sequences involving this character.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "feature_index=63 - explanation.confidence_score=9.0\n",
      "\n",
      "Feature 63 appears to be highly activated for the token \"w\", potentially indicating that it plays a\n",
      "role in recognizing or processing the character \"w\" in the sequence, especially for its occurrences\n",
      "in the given sorted sequences. The feature is consistently activated for \"w\" in different contexts,\n",
      "suggesting a specialized function for this character.\n",
      "\n",
      "\n",
      "---\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "for feature_index, explanation in tqdm.tqdm(feature_explanations.items()):\n",
    "\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "    print(f\"{feature_index=} - {explanation.confidence_score=}\")\n",
    "\n",
    "    print(f\"\\n{textwrap.fill(explanation.text, width=100)}\\n\")\n",
    "\n",
    "    print(format_text(display_top_examples_for_feature(feature_index, top_n=10)))\n",
    "\n",
    "    # print(\"---\")\n",
    "\n",
    "    # print(display_top_features_for_top_token_string(feature_index))\n",
    "\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff5343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "90cbf856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1462272"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"token_string\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe15ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "542c6b8f",
   "metadata": {},
   "source": [
    "## Transcoder - Checking Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f5501b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15055be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7202db",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    len(test_example_per_difficulty) == 1\n",
    "), \"Here we're assuming only one difficulty, can be easily adapted for more\"\n",
    "\n",
    "\n",
    "print(f\"{transcoder_training_cfg.hook_point=}\")\n",
    "print(f\"{transcoder_training_cfg.out_hook_point=}\")\n",
    "\n",
    "mlp_in = correct_cache[transcoder_training_cfg.hook_point]\n",
    "mlp_out = correct_cache[transcoder_training_cfg.out_hook_point]\n",
    "\n",
    "transcoder_results = mlp_transcoder(mlp_in)\n",
    "\n",
    "# Print shapes of tensors\n",
    "print([c for c in correct_string])\n",
    "print(f\"mlp_in: {mlp_in.shape}\")\n",
    "print(f\"mlp_out: {mlp_out.shape}\")\n",
    "print(f\"transcoder_out: {transcoder_results.transcoder_out.shape}\")\n",
    "print(f\"hidden_activations: {transcoder_results.hidden_activations.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d816c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have imported or defined `mlp_in`, `mlp_out`, `transcoder_out`, `hidden_activations`, and `input_tokens_str`\n",
    "\n",
    "\n",
    "# Function to plot heatmap of activations\n",
    "def plot_activations(\n",
    "    activations,\n",
    "    title,\n",
    "    xlabel=\"Neuron\",\n",
    "    ylabel=\"Sequence Position\",\n",
    "    tokens=None,\n",
    "    cmap: str = \"RdBu\",\n",
    "):\n",
    "    # Remove batch dimension and convert to numpy\n",
    "    activations = activations.squeeze(0).detach().cpu().numpy()\n",
    "    plt.figure(figsize=(4, 2))\n",
    "    sns.heatmap(activations, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if tokens is not None:\n",
    "        plt.yticks(np.arange(len(tokens)) + 0.5, tokens, rotation=0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 1. Visualize MLP Input Activations (mlp_in)\n",
    "plot_activations(mlp_in, title=\"MLP Input Activations\", tokens=correct_string)\n",
    "\n",
    "# 2. Visualize MLP Output Activations (mlp_out)\n",
    "plot_activations(mlp_out, title=\"MLP Output Activations\", tokens=correct_string)\n",
    "\n",
    "# 3. Visualize Transcoder Output (transcoder_out)\n",
    "plot_activations(\n",
    "    transcoder_results.transcoder_out,\n",
    "    title=\"Transcoder Output Activations\",\n",
    "    tokens=correct_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hidden_activations(hidden_activations, tokens):\n",
    "    # hidden_activations: [seq_len, hidden_size]\n",
    "    # tokens: list of token strings\n",
    "\n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(\n",
    "        hidden_activations,\n",
    "        cmap=\"YlOrRd\",\n",
    "        cbar=True,\n",
    "        vmin=0,\n",
    "        vmax=np.max(hidden_activations),\n",
    "    )\n",
    "    plt.ylabel(\"Token Position\")\n",
    "    plt.xlabel(\"Neuron Index\")\n",
    "    plt.yticks(np.arange(len(tokens)) + 0.5, tokens, rotation=90)\n",
    "    plt.title(\"Hidden Activations Heatmap\")\n",
    "    plt.show()\n",
    "\n",
    "    # Activation Distribution\n",
    "    activation_values = hidden_activations.flatten()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(activation_values, bins=100, color=\"blue\", alpha=0.7)\n",
    "    plt.xlabel(\"Activation Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Distribution of Hidden Activations\")\n",
    "    plt.show()\n",
    "\n",
    "    # PCA\n",
    "    \"\"\"from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    activations_pca = pca.fit_transform(hidden_activations)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(\n",
    "        activations_pca[:, 0],\n",
    "        activations_pca[:, 1],\n",
    "        c=np.arange(len(tokens)),\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    for i, token in enumerate(tokens):\n",
    "        plt.text(activations_pca[i, 0], activations_pca[i, 1], token)\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(\"PCA of Hidden Activations\")\n",
    "    plt.colorbar(label=\"Token Position\")\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "\n",
    "visualize_hidden_activations(\n",
    "    hidden_activations=transcoder_results.hidden_activations[0].detach().cpu().numpy(),\n",
    "    tokens=incorrect_string,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualize Hidden Activations of MLP (hidden_activations)\n",
    "# Due to the high dimensionality (2048), we might need to reduce dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA to reduce dimensions to 2 for visualization\n",
    "activations = transcoder_results.hidden_activations.squeeze(0).detach().cpu().numpy()\n",
    "pca = PCA(n_components=2)\n",
    "reduced_activations = pca.fit_transform(activations.reshape(-1, activations.shape[-1]))\n",
    "\n",
    "# Plot the PCA-reduced activations\n",
    "plt.figure(figsize=(4, 2))\n",
    "scatter = plt.scatter(\n",
    "    reduced_activations[:, 0],\n",
    "    reduced_activations[:, 1],\n",
    "    c=np.arange(activations.shape[0]),\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "plt.colorbar(scatter, label=\"Sequence Position\")\n",
    "plt.title(\"PCA of Hidden Activations\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()\n",
    "\n",
    "# Alternatively, plot a subset of neurons\n",
    "num_neurons_to_plot = 2048  # Adjust based on preference\n",
    "selected_neurons = activations[:, :num_neurons_to_plot]\n",
    "\n",
    "plot_activations(\n",
    "    torch.tensor(selected_neurons),\n",
    "    title=\"Hidden Activations (First {} Neurons)\".format(num_neurons_to_plot),\n",
    "    xlabel=\"Neuron\",\n",
    "    tokens=input_tokens_str,\n",
    "    cmap=\"grey\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb077e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualize Distributions of Activations\n",
    "def plot_activation_distribution(activations, title):\n",
    "    activations = activations.detach().cpu().numpy().flatten()\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    sns.histplot(activations, bins=100, kde=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Activation Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_activation_distribution(mlp_in, title=\"Distribution of MLP Input Activations\")\n",
    "\n",
    "plot_activation_distribution(mlp_out, title=\"Distribution of MLP Output Activations\")\n",
    "\n",
    "plot_activation_distribution(\n",
    "    transcoder_results.hidden_activations,\n",
    "    title=\"Distribution of Hidden Activations\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d188f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = model.blocks[1].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.W_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588f5fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5820e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualize MLP Weights\n",
    "# Assuming you have access to the MLP model\n",
    "# Replace `model` with your transformer model variable and adjust layer indices accordingly\n",
    "\n",
    "# Visualize weights of the first linear layer\n",
    "weight_matrix = model.blocks[0].mlp.W_in.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(weight_matrix, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Weights of MLP Layer fc1\")\n",
    "plt.xlabel(\"Input Neuron\")\n",
    "plt.ylabel(\"Output Neuron\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize weights of the second linear layer\n",
    "weight_matrix = model.blocks[1].mlp.W_in.detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(weight_matrix, cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Weights of MLP Layer fc2\")\n",
    "plt.xlabel(\"Input Neuron\")\n",
    "plt.ylabel(\"Output Neuron\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ea5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "705bcb63",
   "metadata": {},
   "source": [
    "## Optuna Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df666bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "# TODO(bschoen): Do need to use lightning if want to do this generally\n",
    "# note: generally do want to iterate on this part itself, i.e. once find promising learning rate, searching other hyperparameters\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "\n",
    "    # TODO(bschoen): up to one per position, eh might as well try it\n",
    "\n",
    "    d_model = trial.suggest_categorical(\"d_model\", [8, 16, 32, 64, 128])\n",
    "    n_heads = trial.suggest_int(\"n_heads\", 1, 8)\n",
    "\n",
    "    cfg = ModelAndTrainingConfig(\n",
    "        num_epochs=1000,\n",
    "        eval_test_every_n=10000,  # not worth evaluating test loss for study\n",
    "        n_layers=1,  # trial.suggest_int(\"n_layers\", 1, 2),\n",
    "        d_model=d_model,\n",
    "        n_heads=n_heads,\n",
    "        learning_rate=5e-4,\n",
    "    )\n",
    "\n",
    "    # sanity check `d_heads`\n",
    "    if (cfg.d_model % cfg.n_heads) != 0:\n",
    "        print(f\"Pruning trial for {cfg.d_model=} {cfg.n_heads=}\")\n",
    "        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    result = train_model(cfg)\n",
    "\n",
    "    return result.train_loss\n",
    "\n",
    "\n",
    "enable_optuna = False\n",
    "\n",
    "if enable_optuna:\n",
    "\n",
    "    study_storage_url = \"sqlite:///toy-problem-hooked-transformer.db\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        directions=[optuna.study.StudyDirection.MINIMIZE],\n",
    "        storage=study_storage_url,\n",
    "    )\n",
    "\n",
    "    study.optimize(objective, n_trials=10)\n",
    "\n",
    "    print(\"View by launching optuna dashboard from the command line:\")\n",
    "    print(f\"optuna-dashboard {study_storage_url}\")\n",
    "\n",
    "    # now let's do a real run\n",
    "    training_config = ModelAndTrainingConfig(\n",
    "        num_epochs=10000,\n",
    "        eval_test_every_n=1000,\n",
    "        n_layers=1,\n",
    "        d_model=16,\n",
    "        n_heads=1,\n",
    "    )\n",
    "\n",
    "    result = train_model(cfg=training_config)\n",
    "\n",
    "    # for compatibility with code later\n",
    "    model = result.model\n",
    "    cfg = training_config.get_hooked_transformer_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450e6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at some example output\n",
    "import circuitsvis as cv\n",
    "\n",
    "import functools\n",
    "\n",
    "\n",
    "def visualize_pattern_hook(\n",
    "    pattern: Float32[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
    "    hook: transformer_lens.hook_points.HookPoint,\n",
    "    tokens_as_strings: list[str],\n",
    ") -> None:\n",
    "    print(f\"Batch size: {pattern.shape[0]}\")\n",
    "    print(\"Layer: \", hook.layer())\n",
    "    display(cv.attention.attention_patterns(tokens=tokens_as_strings, attention=pattern.mean(0)))\n",
    "\n",
    "\n",
    "test_input_string_to_cache = {}\n",
    "\n",
    "for difficulty, test_loader in test_loaders.items():\n",
    "\n",
    "    print(difficulty)\n",
    "\n",
    "    # grab something from the test batch\n",
    "    example_batch = next(iter(test_loader))\n",
    "\n",
    "    x, y = example_batch\n",
    "\n",
    "    example_sample = x[0]\n",
    "\n",
    "    # example_sample = torch.tensor(tokenizer.encode(\"<az|za|az>>>>>>>>>>\"))\n",
    "\n",
    "    # grab the first part of it, ex: `<abc|`\n",
    "    example_prompt = example_sample  # [:8]\n",
    "\n",
    "    example_prompt = example_prompt.to(device)\n",
    "\n",
    "    print(f\"Using {example_prompt} from {example_sample} (from test set)\")\n",
    "\n",
    "    # note: already encoded\n",
    "    input_tokens = example_prompt\n",
    "\n",
    "    # first let's get these as strings so can easily work with them\n",
    "    input_tokens_as_strings = [token_to_string(x.item()) for x in input_tokens]\n",
    "\n",
    "    # wrap to bind input tokens\n",
    "    visualize_pattern_hook_fn = functools.partial(\n",
    "        visualize_pattern_hook, tokens_as_strings=input_tokens_as_strings\n",
    "    )\n",
    "\n",
    "    model.run_with_hooks(\n",
    "        input_tokens,\n",
    "        return_type=None,  # For efficiency, we don't need to calculate the logits\n",
    "        fwd_hooks=[(lambda name: name.endswith(\"pattern\"), visualize_pattern_hook_fn)],\n",
    "    )\n",
    "\n",
    "    logits_batch, cache = model.run_with_cache(input_tokens)\n",
    "\n",
    "    # store so can plot together later\n",
    "    test_input_string_to_cache[\"\".join(input_tokens_as_strings)] = cache\n",
    "\n",
    "    logits = logits_batch[0]\n",
    "\n",
    "    log_probs = logits.log_softmax(dim=-1)\n",
    "\n",
    "    cv.logits.token_log_probs(\n",
    "        token_indices=input_tokens,\n",
    "        log_probs=log_probs,\n",
    "        to_string=token_to_string,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d2143",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.apply_ln_to_stack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c96b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.stack_head_results??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b78938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens.patching\n",
    "\n",
    "transformer_lens.patching.get_act_patch_resid_pre??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2f20a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8b41fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a9eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "\n",
    "\n",
    "def logit_attribution(\n",
    "    embed: Float32[torch.Tensor, \"seq d_model\"],\n",
    "    l1_results: Float32[torch.Tensor, \"seq nheads d_model\"],\n",
    "    l2_results: Float32[torch.Tensor, \"seq nheads d_model\"],\n",
    "    W_U: Float32[torch.Tensor, \"d_model d_vocab\"],\n",
    "    tokens: Int64[torch.Tensor, \"seq\"],\n",
    ") -> Float32[torch.Tensor, \"seq-1 n_components\"]:\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        embed: the embeddings of the tokens (i.e. token + position embeddings)\n",
    "        l1_results: the outputs of the attention heads at layer 1 (with head as one of the dimensions)\n",
    "        l2_results: the outputs of the attention heads at layer 2 (with head as one of the dimensions)\n",
    "        W_U: the unembedding matrix\n",
    "        tokens: the token ids of the sequence\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape (seq_len-1, n_components)\n",
    "        represents the concatenation (along dim=-1) of logit attributions from:\n",
    "            the direct path (seq-1,1)\n",
    "            layer 0 logits (seq-1, n_heads)\n",
    "            layer 1 logits (seq-1, n_heads)\n",
    "        so n_components = 1 + 2*n_heads\n",
    "    \"\"\"\n",
    "    W_U_correct_tokens = W_U[:, tokens[1:]]\n",
    "    # SOLUTION\n",
    "    direct_attributions = einops.einsum(W_U_correct_tokens, embed[:-1], \"emb seq, seq emb -> seq\")\n",
    "    l1_attributions = einops.einsum(\n",
    "        W_U_correct_tokens, l1_results[:-1], \"emb seq, seq nhead emb -> seq nhead\"\n",
    "    )\n",
    "    l2_attributions = einops.einsum(\n",
    "        W_U_correct_tokens, l2_results[:-1], \"emb seq, seq nhead emb -> seq nhead\"\n",
    "    )\n",
    "    return torch.concat(\n",
    "        [direct_attributions.unsqueeze(-1), l1_attributions, l2_attributions], dim=-1\n",
    "    )\n",
    "\n",
    "\n",
    "logits, cache = model.run_with_cache(input_tokens, remove_batch_dim=True)\n",
    "str_tokens = input_tokens_as_strings\n",
    "tokens = input_tokens\n",
    "\n",
    "with t.inference_mode():\n",
    "    embed = cache[\"embed\"]\n",
    "    l1_results = cache[\"result\", 0]\n",
    "    l2_results = cache[\"result\", 1]\n",
    "    logit_attr = logit_attribution(\n",
    "        embed,\n",
    "        l1_results,\n",
    "        l2_results,\n",
    "        model.W_U,\n",
    "        tokens[0],\n",
    "    )\n",
    "\n",
    "    # Uses fancy indexing to get a len(tokens[0])-1 length tensor, where the kth entry is the predicted logit for the correct k+1th token\n",
    "    correct_token_logits = logits[0, torch.arange(len(tokens[0]) - 1), tokens[0, 1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13997a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a544cede",
   "metadata": {},
   "source": [
    "## Looking at it with CircuitsViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cedde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before even going to SAE, let's look at circuitsviz here\n",
    "import circuitsvis as cv\n",
    "\n",
    "import circuitsvis.activations\n",
    "import circuitsvis.attention\n",
    "import circuitsvis.logits\n",
    "import circuitsvis.tokens\n",
    "import circuitsvis.topk_samples\n",
    "import circuitsvis.topk_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b587d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's see what we have\n",
    "import tabulate\n",
    "\n",
    "print(f\"{len(input_tokens)=}\")\n",
    "\n",
    "# show the first few elements of the `HookedTransformerConfig`, since that has things like `d_model`, num heads, etc\n",
    "print(tabulate.tabulate([(k, v) for k, v in cfg.__dict__.items()][:10]))\n",
    "\n",
    "print(tabulate.tabulate([(k, v.shape) for k, v in cache.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519db727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, HoverTool\n",
    "from bokeh.palettes import Viridis256\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Enable Bokeh output in the notebook\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "def tensor_to_dataframe(tensor: torch.Tensor, labels: list[str], tokens: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a 2D PyTorch tensor to a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): A 2D tensor to convert.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame representation of the input tensor.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input tensor is not 2D.\n",
    "    \"\"\"\n",
    "    if tensor.dim() != 2:\n",
    "        raise ValueError(f\"Input tensor must be 2D, got {tensor.dim()}D\")\n",
    "    if len(labels) != 2:\n",
    "        raise ValueError(f\"Expected labels for both dimensions, got {len(labels)}\")\n",
    "\n",
    "    # Convert tensor to numpy array\n",
    "    numpy_array = tensor.detach().cpu().numpy()\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(numpy_array)\n",
    "\n",
    "    # Name the index the first label\n",
    "    df.index.name = labels[0]\n",
    "\n",
    "    # Name the columns the second label\n",
    "    df.columns = [f\"{labels[1]}_{i}\" for i in range(numpy_array.shape[1])]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def visualize_tensor_heatmap(\n",
    "    tensor: torch.Tensor,\n",
    "    title: str = \"Tensor Heatmap\",\n",
    "    colormap: list[str] = Viridis256,\n",
    "    width: int = 800,\n",
    "    height: int = 400,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Visualize a 2D tensor as a heatmap.\n",
    "\n",
    "    Args:\n",
    "        tensor (torch.Tensor): A 2D tensor to visualize.\n",
    "        title (str): Title of the heatmap.\n",
    "        colormap (List[str]): A list of colors to use for the heatmap.\n",
    "        width (int): Width of the plot in pixels.\n",
    "        height (int): Height of the plot in pixels.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure tensor is 2D\n",
    "    if tensor.dim() != 2:\n",
    "        raise ValueError(f\"Input tensor must be 2D, got {tensor.shape}\")\n",
    "\n",
    "    # convert tensor to dataframe\n",
    "    df = tensor_to_dataframe(tensor)\n",
    "\n",
    "    # Create a 2D grid of coordinates\n",
    "    y, x = np.mgrid[0 : data.shape[0], 0 : data.shape[1]]\n",
    "\n",
    "    # Flatten the arrays\n",
    "    x = x.flatten()\n",
    "    y = y.flatten()\n",
    "    z = data.flatten()\n",
    "\n",
    "    # Create a ColumnDataSource\n",
    "    source = ColumnDataSource(\n",
    "        data=dict(\n",
    "            x=x,\n",
    "            y=y,\n",
    "            z=z,\n",
    "            color=Viridis256[:: int(256 / len(z))][: len(z)],  # Map values to colors\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    p = figure(\n",
    "        title=\"Tensor Heatmap\",\n",
    "        x_range=(0, data.shape[1]),\n",
    "        y_range=(0, data.shape[0]),\n",
    "        toolbar_location=\"below\",\n",
    "        tools=\"pan,wheel_zoom,box_zoom,reset\",\n",
    "    )\n",
    "\n",
    "    # Add rectangular glyphs\n",
    "    p.rect(\n",
    "        x=\"x\",\n",
    "        y=\"y\",\n",
    "        width=1,\n",
    "        height=1,\n",
    "        source=source,\n",
    "        fill_color=\"color\",\n",
    "        line_color=None,\n",
    "    )\n",
    "\n",
    "    # Add hover tool\n",
    "    hover = HoverTool(tooltips=[(\"x\", \"@x\"), (\"y\", \"@y\"), (\"value\", \"@z{0.000}\")])\n",
    "    p.add_tools(hover)\n",
    "\n",
    "    # Invert y-axis to match tensor indexing\n",
    "    p.y_range.start, p.y_range.end = p.y_range.end, p.y_range.start\n",
    "\n",
    "    # Show the plot\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5317b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate.tabulate([(k, v[0].shape) for k, v in cache.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52ad382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's go ahead and just use first batch\n",
    "def first_batch(tensor: Float32[torch.Tensor, \"b t c\"]) -> Float32[torch.Tensor, \"t c\"]:\n",
    "    return tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb2343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439c2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "from typing import Iterable, TypeVar\n",
    "\n",
    "import tabulate\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "# alias for `print(tabulate.tabulate(data))`\n",
    "def print_table(data: T) -> None:\n",
    "    print(tabulate.tabulate(data))\n",
    "\n",
    "\n",
    "# Define a function to print module weights recursively\n",
    "def print_module_weights(module: nn.Module) -> Iterable[tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Recursively prints the weights of a PyTorch module and its submodules.\n",
    "\n",
    "    This function traverses through the module hierarchy, printing information\n",
    "    about parameters that require gradients and are not hook-related.\n",
    "\n",
    "    Example:\n",
    "        >>> print_table(print_module_weights(model))\n",
    "\n",
    "        ------------------  ----------------------\n",
    "        embed.W_E           torch.Size([29, 14])\n",
    "        pos_embed.W_pos     torch.Size([9, 14])\n",
    "        blocks.0.ln1.w      torch.Size([14])\n",
    "        blocks.0.ln1.b      torch.Size([14])\n",
    "        blocks.0.ln2.w      torch.Size([14])\n",
    "        blocks.0.ln2.b      torch.Size([14])\n",
    "        blocks.0.attn.W_Q   torch.Size([3, 14, 4])\n",
    "        blocks.0.attn.W_O   torch.Size([3, 4, 14])\n",
    "        blocks.0.attn.b_Q   torch.Size([3, 4])\n",
    "        blocks.0.attn.b_O   torch.Size([14])\n",
    "        blocks.0.attn.W_K   torch.Size([3, 14, 4])\n",
    "        blocks.0.attn.W_V   torch.Size([3, 14, 4])\n",
    "        blocks.0.attn.b_K   torch.Size([3, 4])\n",
    "        blocks.0.attn.b_V   torch.Size([3, 4])\n",
    "        blocks.0.mlp.W_in   torch.Size([14, 56])\n",
    "        blocks.0.mlp.b_in   torch.Size([56])\n",
    "        blocks.0.mlp.W_out  torch.Size([56, 14])\n",
    "        blocks.0.mlp.b_out  torch.Size([14])\n",
    "        ln_final.w          torch.Size([14])\n",
    "        ln_final.b          torch.Size([14])\n",
    "        unembed.W_U         torch.Size([14, 29])\n",
    "        unembed.b_U         torch.Size([29])\n",
    "        ------------------  ----------------------\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): The PyTorch module to inspect.\n",
    "        prefix (str, optional): A string prefix for indentation in the output.\n",
    "                                Defaults to an empty string.\n",
    "\n",
    "    Returns:\n",
    "        Iterable[tuple[str, str]]: A list of tuples, where each tuple contains\n",
    "            the name and shape of the parameter.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate through named parameters of the module\n",
    "    for name, param in module.named_parameters():\n",
    "\n",
    "        # Check if parameter requires gradient and doesn't start with 'hook_'\n",
    "        if param.requires_grad and not name.startswith(\"hook_\"):\n",
    "\n",
    "            # yield parameter name and type\n",
    "            yield f\"{name}\", f\"{param.shape}\"\n",
    "\n",
    "\n",
    "def print_cache(cache: transformer_lens.ActivationCache) -> None:\n",
    "    print(tabulate.tabulate([(k, v[0].shape) for k, v in cache.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b1c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weights in the model:\")\n",
    "print_table(print_module_weights(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb6a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cached activations:\")\n",
    "print_cache(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6910da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cache_activation(\n",
    "    cache: transformer_lens.ActivationCache,\n",
    "    cache_key: str,\n",
    "    input_tokens_as_strings: list[str],\n",
    ") -> None:\n",
    "\n",
    "    activations = first_batch(cache[cache_key])\n",
    "\n",
    "    figsize = (4, 4)\n",
    "\n",
    "    # make figure smaller for vectors\n",
    "    if activations.shape[-1] == 1:\n",
    "        figsize = (4, 1.5)\n",
    "\n",
    "    # for larger activations like MLP, allow it to be taller\n",
    "    elif activations.shape[-1] > 20:\n",
    "        figsize = (4, 12)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    sns.heatmap(\n",
    "        activations.cpu().numpy().T,\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "        xticklabels=input_tokens_as_strings,\n",
    "    )\n",
    "\n",
    "    plt.title(cache_key)\n",
    "\n",
    "    # TODO(bschoen): Allow specifying this\n",
    "    #\n",
    "    plt.ylabel(\"Embedding Dimension\")\n",
    "    plt.xlabel(\"Token\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for cache_key in [\n",
    "    \"hook_embed\",\n",
    "    \"hook_pos_embed\",\n",
    "    \"blocks.0.hook_resid_pre\",\n",
    "    \"blocks.0.ln1.hook_scale\",\n",
    "    \"blocks.0.ln1.hook_normalized\",\n",
    "    \"blocks.0.hook_attn_out\",\n",
    "    \"blocks.0.hook_resid_mid\",\n",
    "    \"blocks.0.ln2.hook_scale\",\n",
    "    \"blocks.0.ln2.hook_normalized\",\n",
    "    \"blocks.0.mlp.hook_pre\",\n",
    "    \"blocks.0.mlp.hook_post\",\n",
    "    \"blocks.0.hook_mlp_out\",\n",
    "    \"blocks.0.hook_resid_post\",\n",
    "    \"ln_final.hook_scale\",\n",
    "    \"ln_final.hook_normalized\",\n",
    "]:\n",
    "\n",
    "    plot_cache_activation(\n",
    "        cache=cache,\n",
    "        cache_key=cache_key,\n",
    "        input_tokens_as_strings=input_tokens_as_strings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dedf265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize MLP\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "\n",
    "def plot_mlp_weights_and_biases(model):\n",
    "    # Function to plot heatmaps for MLP weights and biases\n",
    "\n",
    "    def plot_weight_bias_pair(weight, bias, title):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        sns.heatmap(weight.detach().cpu().numpy(), ax=ax1, cmap=\"coolwarm\", center=0)\n",
    "        ax1.set_title(f\"{title} - Weights\")\n",
    "        ax1.set_xlabel(\"Output dimension\")\n",
    "        ax1.set_ylabel(\"Input dimension\")\n",
    "\n",
    "        sns.heatmap(\n",
    "            bias.detach().cpu().numpy().reshape(-1, 1),\n",
    "            ax=ax2,\n",
    "            cmap=\"coolwarm\",\n",
    "            center=0,\n",
    "        )\n",
    "        ax2.set_title(f\"{title} - Biases\")\n",
    "        ax2.set_xlabel(\"Bias\")\n",
    "        ax2.set_ylabel(\"Dimension\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # MLP weights and biases\n",
    "    plot_weight_bias_pair(model.blocks[0].mlp.W_in, model.blocks[0].mlp.b_in, \"MLP Input\")\n",
    "    plot_weight_bias_pair(model.blocks[0].mlp.W_out, model.blocks[0].mlp.b_out, \"MLP Output\")\n",
    "\n",
    "    # Layer Norm final\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(\n",
    "        model.ln_final.w.detach().cpu().numpy().reshape(1, -1),\n",
    "        cmap=\"coolwarm\",\n",
    "        center=1,\n",
    "    )\n",
    "    plt.title(\"Layer Norm Final - Weights\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.heatmap(\n",
    "        model.ln_final.b.detach().cpu().numpy().reshape(1, -1),\n",
    "        cmap=\"coolwarm\",\n",
    "        center=0,\n",
    "    )\n",
    "    plt.title(\"Layer Norm Final - Biases\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Unembed\n",
    "    plot_weight_bias_pair(model.unembed.W_U, model.unembed.b_U, \"Unembed\")\n",
    "\n",
    "\n",
    "# Call the function\n",
    "plot_mlp_weights_and_biases(model)\n",
    "\n",
    "# Comment: Additional visualizations that could be useful:\n",
    "# 1. Histograms of weight/bias distributions\n",
    "# 2. 3D surface plots for weights to show patterns\n",
    "# 3. Network architecture diagram with weight magnitudes represented by line thickness\n",
    "# 4. Animated heatmaps showing weight changes during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7a8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weight_bias_activation(\n",
    "    weight,\n",
    "    bias,\n",
    "    activation,\n",
    "    title: str,\n",
    ") -> None:\n",
    "\n",
    "    activation = first_batch(activation)\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "    sns.heatmap(weight.detach().cpu().numpy().T, ax=ax1, cmap=\"coolwarm\", center=0)\n",
    "    ax1.set_title(f\"{title} - Weight\")\n",
    "\n",
    "    sns.barplot(x=list(range(len(bias))), y=bias.detach().cpu().numpy(), ax=ax2)\n",
    "    ax2.set_title(f\"{title} - Bias\")\n",
    "    ax2.set_xlabel(\"Index\")\n",
    "    ax2.set_ylabel(\"Value\")\n",
    "\n",
    "    sns.heatmap(activation.detach().cpu().numpy().T, ax=ax3, cmap=\"coolwarm\", center=0)\n",
    "    ax3.set_title(f\"{title} - Activation\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_weight_bias_activation(\n",
    "    model.embed.W_E,\n",
    "    torch.zeros(model.embed.W_E.shape[1]),\n",
    "    cache[\"hook_embed\"],\n",
    "    \"Embedding\",\n",
    ")\n",
    "plot_weight_bias_activation(\n",
    "    model.pos_embed.W_pos,\n",
    "    torch.zeros(model.pos_embed.W_pos.shape[1]),\n",
    "    cache[\"hook_pos_embed\"],\n",
    "    \"Positional Embedding\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ec88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(bschoen): Hook residual pre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8937bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d7f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting LayerNorm components\n",
    "\n",
    "\n",
    "def plot_layernorm(scale, normalized, title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    scale = first_batch(scale)\n",
    "    normalized = first_batch(normalized)\n",
    "\n",
    "    sns.barplot(x=list(range(len(scale))), y=scale.squeeze().detach().cpu().numpy(), ax=ax1)\n",
    "    ax1.set_title(f\"{title} - Scale\")\n",
    "    ax1.set_xlabel(\"Index\")\n",
    "    ax1.set_ylabel(\"Value\")\n",
    "\n",
    "    sns.heatmap(normalized.detach().cpu().numpy().T, ax=ax2, cmap=\"coolwarm\", center=0)\n",
    "    ax2.set_title(f\"{title} - Normalized\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_layernorm(\n",
    "    cache[\"blocks.0.ln1.hook_scale\"],\n",
    "    cache[\"blocks.0.ln1.hook_normalized\"],\n",
    "    \"LayerNorm 1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a7cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting MLP components\n",
    "plot_weight_bias_activation(\n",
    "    model.blocks[0].mlp.W_in,\n",
    "    model.blocks[0].mlp.b_in,\n",
    "    cache[\"blocks.0.mlp.hook_pre\"],\n",
    "    \"MLP Input\",\n",
    ")\n",
    "plot_weight_bias_activation(\n",
    "    model.blocks[0].mlp.W_out,\n",
    "    model.blocks[0].mlp.b_out,\n",
    "    cache[\"blocks.0.mlp.hook_post\"],\n",
    "    \"MLP Output\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdf33f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c51ff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ff7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a5f4f8",
   "metadata": {},
   "source": [
    "#### circuitsvis.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cc70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens := List of tokens if single sample (e.g. `[\"A\", \"person\"]`) or list of lists of tokens (e.g. `[[[\"A\", \"person\"], [\"is\", \"walking\"]]]`)\n",
    "# activations := Activations of the shape [tokens x layers x neurons] if single sample or list of [tokens x layers x neurons] if multiple samples\n",
    "\n",
    "# take first batch for now\n",
    "activations = cache[\"blocks.0.hook_mlp_out\"][0]\n",
    "print(f\"{activations.shape=}\")\n",
    "\n",
    "# reshape [tokens x neurons] -> [tokens x 1 x neurons]\n",
    "#  - `-1` means to automatically infer the size of the last dimension\n",
    "activations_view = activations.view(len(input_tokens), cfg.n_layers, -1)\n",
    "\n",
    "print(f\"{activations_view.shape=}\")\n",
    "\n",
    "# convert to strings (which this function expects)\n",
    "input_tokens_as_strings = [token_to_string(x.item()) for x in input_tokens]\n",
    "\n",
    "# TODO(bschoen): Is there a way to essentially stack these? Claude can probably give the React for that\n",
    "\n",
    "# so here we can visualize activations for a `torch.Size([1, 8, 16])`, which is most\n",
    "# of them since this is the size of the embedding dimension\n",
    "circuitsvis.activations.text_neuron_activations(\n",
    "    tokens=[token_to_string(x.item()) for x in input_tokens],\n",
    "    activations=activations_view,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f7aa2",
   "metadata": {},
   "source": [
    "#### circuitsvis.attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5ba9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens: List of tokens (e.g. `[\"A\", \"person\"]`). Must be the same length as the list of values.\n",
    "# attention: Attention head activations of the shape [dest_tokens x src_tokens]\n",
    "# max_value: Maximum value. Used to determine how dark the token color is when positive (i.e. based on how close it is to the maximum value).\n",
    "# min_value: Minimum value. Used to determine how dark the token color is when negative (i.e. based on how close it is to the minimum value).\n",
    "# negative_color: Color for negative values\n",
    "# positive_color: Color for positive values.\n",
    "# show_axis_labels: Whether to show axis labels.\n",
    "# mask_upper_tri: Whether or not to mask the upper triangular portion of the attention patterns. Should be true for causal attention, false for bidirectional attention.\n",
    "\n",
    "\n",
    "# take first batch\n",
    "# ex: torch.Size([4, 8, 8]) -> [n_heads, n_ctx, n_ctx]\n",
    "# note: `blocks.0.attn.hook_attn_scores` is too early (not normalized?)\n",
    "attention = cache[\"blocks.0.attn.hook_pattern\"][0]\n",
    "\n",
    "print(f\"{attention.shape=}\")\n",
    "\n",
    "circuitsvis.attention.attention_heads(\n",
    "    tokens=input_tokens_as_strings,\n",
    "    attention=attention,\n",
    "    max_value=1,\n",
    "    min_value=-1,\n",
    "    negative_color=\"blue\",\n",
    "    positive_color=\"red\",\n",
    "    mask_upper_tri=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777d512f",
   "metadata": {},
   "source": [
    "#### circuitsvis.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the normal one we usually show, i.e.\n",
    "# cv.logits.token_log_probs(\n",
    "#     token_indices=input_tokens,\n",
    "#     log_probs=log_probs,\n",
    "#     to_string=token_to_string,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a72925",
   "metadata": {},
   "source": [
    "#### circuitsvis.tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa878bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example, we'll look at each\n",
    "\n",
    "# take first batch, ex: torch.Size([8, 16])\n",
    "pos_embed = cache[\"hook_pos_embed\"][0]\n",
    "\n",
    "# low level function for coloring tokens according to single value\n",
    "for i in range(cfg.d_model):\n",
    "    display(\n",
    "        circuitsvis.tokens.colored_tokens(\n",
    "            tokens=input_tokens_as_strings,\n",
    "            values=pos_embed[:, i],\n",
    "            negative_color=\"blue\",\n",
    "            positive_color=\"red\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # only display a few for example\n",
    "    # if i >= 2:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69c3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first batch\n",
    "# ex: torch.size([8, 16]) = [n_ctx, d_model]\n",
    "attention_out = cache[\"blocks.0.hook_attn_out\"][0]\n",
    "\n",
    "circuitsvis.tokens.colored_tokens_multi(\n",
    "    tokens=input_tokens_as_strings,\n",
    "    values=attention_out,\n",
    "    labels=[str(x) for x in range(cfg.d_model)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163a765",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitsvis.tokens.visualize_model_performance(\n",
    "    tokens=input_tokens,\n",
    "    str_tokens=input_tokens_as_strings,\n",
    "    logits=logits,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0406d0",
   "metadata": {},
   "source": [
    "#### circuitsvis.topk_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d155e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitsvis.topk_samples.topk_samples??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f90d626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e239f06",
   "metadata": {},
   "source": [
    "#### circuitsvis.topk_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuitsvis.topk_tokens.topk_tokens??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0533d521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee20ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4195832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c59598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86be5940",
   "metadata": {},
   "source": [
    "## SAE (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaee566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_index in range(cfg.n_layers):\n",
    "    imshow(\n",
    "        transformer_lens.utils.to_numpy(cache[\"attn\", layer_index].mean([0, 1])),\n",
    "        title=f\"Layer {layer_index} Attention Pattern\",\n",
    "        height=400,\n",
    "        width=400,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5469c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dataclasses\n",
    "\n",
    "Loss = Float32[torch.Tensor, \"\"]\n",
    "MSELoss = Float32[torch.Tensor, \"\"]\n",
    "WeightedSparsityLoss = Float32[torch.Tensor, \"\"]\n",
    "\n",
    "Logits = Float32[torch.Tensor, \"n_ctx d_vocab\"]\n",
    "BatchedLogits = Float32[torch.Tensor, \"batch n_ctx d_vocab\"]\n",
    "\n",
    "ModelActivations = Float32[torch.Tensor, \"n_ctx d_model\"]\n",
    "BatchedModelActivations = Float32[torch.Tensor, \"batch n_ctx d_model\"]\n",
    "\n",
    "FlattenedModelActivations = Float32[torch.Tensor, \"d_sae_in\"]\n",
    "\n",
    "BatchedFlattenedModelActivations = Float32[torch.Tensor, \"batch d_sae_in\"]\n",
    "BatchedSAEActivations = Float32[torch.Tensor, \"batch d_sae_model\"]\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SAEOutput:\n",
    "    sae_activations: BatchedSAEActivations\n",
    "    reconstructed_model_activations: BatchedFlattenedModelActivations\n",
    "\n",
    "\n",
    "def sparse_loss_kl_divergence(\n",
    "    flattened_model_activations: BatchedFlattenedModelActivations,\n",
    "    sae_output: SAEOutput,\n",
    "    sparsity_target: float,\n",
    "    sparsity_weight: float,\n",
    "    epsilon: float = 1e-7,\n",
    ") -> tuple[Loss, MSELoss, WeightedSparsityLoss]:\n",
    "\n",
    "    # same as dense loss (this is constant?)\n",
    "    mse_loss = F.mse_loss(\n",
    "        sae_output.reconstructed_model_activations,\n",
    "        flattened_model_activations,\n",
    "    )\n",
    "\n",
    "    # KL divergence for sparsity\n",
    "    avg_activation = torch.mean(sae_output.sae_activations, dim=0)\n",
    "\n",
    "    # print(f'[pre-clamping] {avg_activation=}')\n",
    "\n",
    "    # Add epsilon for numerical stability\n",
    "    avg_activation = torch.clamp(avg_activation, epsilon, 1 - epsilon)\n",
    "\n",
    "    kl_div = sparsity_target * torch.log(sparsity_target / avg_activation) + (\n",
    "        1 - sparsity_target\n",
    "    ) * torch.log((1 - sparsity_target) / (1 - avg_activation))\n",
    "    kl_div = torch.sum(kl_div)\n",
    "\n",
    "    # `sparsity_weight` decides how much we weight `KL-Divergence`\n",
    "    sparsity_penalty = sparsity_weight * kl_div\n",
    "\n",
    "    # print(f\"{mse_loss=}, {avg_activation=}, {kl_div.item()}, {sparsity_penalty=}\")\n",
    "\n",
    "    return mse_loss + sparsity_penalty, mse_loss, sparsity_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ac6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_loss_l1_norm(\n",
    "    flattened_model_activations: BatchedFlattenedModelActivations,\n",
    "    sae_output: SAEOutput,\n",
    "    sparsity_weight: float,\n",
    ") -> tuple[Loss, MSELoss, WeightedSparsityLoss]:\n",
    "\n",
    "    # Reconstruction loss (Mean Squared Error)\n",
    "    mse_loss = F.mse_loss(\n",
    "        sae_output.reconstructed_model_activations,\n",
    "        flattened_model_activations,\n",
    "    )\n",
    "\n",
    "    # L1 sparsity penalty\n",
    "    l1_penalty = torch.mean(torch.abs(sae_output.sae_activations))\n",
    "\n",
    "    sparsity_penalty = sparsity_weight * l1_penalty\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = mse_loss + sparsity_penalty\n",
    "\n",
    "    return total_loss, mse_loss, sparsity_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc92db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class SparseAutoencoderConfig:\n",
    "    d_in: int\n",
    "    d_model: int\n",
    "\n",
    "\n",
    "# TODO(bschoen): Start using the config pattern, it stays typesafe and allows\n",
    "#                easy logging to things like wandb\n",
    "class SparseAutoencoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: SparseAutoencoderConfig,\n",
    "    ) -> None:\n",
    "\n",
    "        print(f\"Creating SparseAutoencoder with {cfg}\")\n",
    "\n",
    "        super(SparseAutoencoder, self).__init__()\n",
    "\n",
    "        self.d_in = cfg.d_in\n",
    "        self.d_model = cfg.d_model\n",
    "\n",
    "        self.encoder = nn.Linear(cfg.d_in, cfg.d_model)\n",
    "        self.decoder = nn.Linear(cfg.d_model, cfg.d_in)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: BatchedFlattenedModelActivations,\n",
    "    ) -> SAEOutput:\n",
    "\n",
    "        # TODO(bschoen): Which activation function should we use?\n",
    "        encoded = F.gelu(self.encoder(x))\n",
    "\n",
    "        decoded = self.decoder(encoded)\n",
    "\n",
    "        return SAEOutput(\n",
    "            sae_activations=encoded,\n",
    "            reconstructed_model_activations=decoded,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22b5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch\n",
    "\n",
    "\n",
    "@dataclasses.dataclass\n",
    "class LightningSparseAutoencoderConfig:\n",
    "\n",
    "    model_config: transformer_lens.HookedTransformerConfig\n",
    "    sae_config: SparseAutoencoderConfig\n",
    "    learning_rate: float\n",
    "    sparsity_weight: float\n",
    "\n",
    "\n",
    "# note: this kind of lightning adapter is a common pattern: https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#starter-example\n",
    "class LightningSparseAutoencoder(lightning.pytorch.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: LightningSparseAutoencoderConfig,\n",
    "    ) -> None:\n",
    "\n",
    "        super(LightningSparseAutoencoder, self).__init__()\n",
    "\n",
    "        self.model = transformer_lens.HookedTransformer(cfg=cfg.model_config)\n",
    "        self.sae = SparseAutoencoder(cfg=cfg.sae_config)\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        return self.model(inputs, target)\n",
    "\n",
    "    def training_step(self, batch, batch_idx: int) -> Loss:\n",
    "        inputs, target = batch\n",
    "\n",
    "        self.model\n",
    "        output = self(inputs, target)\n",
    "        loss = torch.nn.functional.cr(output, target.view(-1))\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.SGD(self.model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_id = \"blocks.0.hook_mlp_out\"\n",
    "\n",
    "cache[hook_id].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "sae_num_epochs = 100000\n",
    "sae_expansion_factor = 64\n",
    "\n",
    "learning_rate = 5e-4\n",
    "\n",
    "# both arbitrary for now\n",
    "# - Start small: A common approach is to begin with a relatively small sparsity weight,\n",
    "#                typically in the range of 1e-5 to 1e-3. This allows the model to\n",
    "#                learn meaningful representations before enforcing strong sparsity\n",
    "#                constraints.\n",
    "sparsity_weight: float = 1e-3  # Weight of the sparsity loss in the total loss\n",
    "sparsity_target: float = 0.05  # Target average activation of hidden neurons\n",
    "\n",
    "print(f\"Training SAE for {hook_id}...\")\n",
    "sae_d_in = (cfg.n_ctx - 1) * cfg.d_model  # -1 since not predicting first token\n",
    "sae_d_model = sae_d_in * sae_expansion_factor\n",
    "\n",
    "sae_cfg = SparseAutoencoderConfig(\n",
    "    d_in=sae_d_in,\n",
    "    d_model=sae_d_model,\n",
    ")\n",
    "\n",
    "sae_model = SparseAutoencoder(cfg=sae_cfg)\n",
    "sae_model.to(device)\n",
    "\n",
    "sae_optimizer = optim.Adam(sae_model.parameters(), lr=learning_rate)\n",
    "\n",
    "wandb.init(\n",
    "    project=\"toy-problem-hooked-transformer-sae\",\n",
    "    config={\n",
    "        \"sae_num_epochs\": sae_num_epochs,\n",
    "        \"sae_expansion_factor\": sae_expansion_factor,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"sparsity_weight\": sparsity_weight,\n",
    "        \"sparsity_target\": sparsity_target,\n",
    "        \"sae_d_in\": sae_d_in,\n",
    "        \"sae_d_model\": sae_d_model,\n",
    "        \"hook_id\": hook_id,\n",
    "    },\n",
    ")\n",
    "\n",
    "# put model itself into eval mode so doesn't change\n",
    "model.eval()\n",
    "\n",
    "# go through the training data again, this time training the sae on the activations\n",
    "for epoch, batch in tqdm.tqdm(\n",
    "    zip(\n",
    "        range(sae_num_epochs),\n",
    "        itertools.cycle(train_loader),\n",
    "    )\n",
    "):\n",
    "\n",
    "    tokens, target = batch\n",
    "\n",
    "    tokens, target = tokens.to(device), target.to(device)\n",
    "\n",
    "    # run through the model (with cache) to get the activations\n",
    "    logits, cache = model.run_with_cache(tokens)\n",
    "\n",
    "    # ex: torch.Size([4, 8, 16])\n",
    "    activations = cache[hook_id]\n",
    "\n",
    "    # ex: torch.Size([4, 128])\n",
    "    flattened_activations = activations.reshape(activations.size(0), -1)\n",
    "\n",
    "    sae_optimizer.zero_grad()\n",
    "\n",
    "    # now the SAE model is given the *activations*\n",
    "    sae_output = sae_model.forward(flattened_activations)\n",
    "\n",
    "    # compute loss\n",
    "\n",
    "    total_loss, reconstruction_loss, weighted_sparsity_loss = sparse_loss_kl_divergence(\n",
    "        flattened_activations,\n",
    "        sae_output,\n",
    "        sparsity_target=sparsity_target,\n",
    "        sparsity_weight=sparsity_weight,\n",
    "    )\n",
    "\n",
    "    \"\"\"total_loss, reconstruction_loss, weighted_sparsity_loss = sparse_loss_l1_norm(\n",
    "        flattened_model_activations=flattened_activations,\n",
    "        sae_output=sae_output,\n",
    "        sparsity_weight=sparsity_weight,\n",
    "    )\"\"\"\n",
    "\n",
    "    total_loss.backward()\n",
    "\n",
    "    sae_optimizer.step()\n",
    "\n",
    "    if epoch % 500 == 0:\n",
    "        print(\n",
    "            f\"Step {epoch}, \"\n",
    "            f\"Total Loss: {total_loss.item():.6f}, \"\n",
    "            f\"Reconstruction Loss: {reconstruction_loss.item():.6f}, \"\n",
    "            f\"Sparsity Loss: {weighted_sparsity_loss.item():.6f}\",\n",
    "        )\n",
    "\n",
    "        wandb.log(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"total_loss\": total_loss.item(),\n",
    "                \"reconstruction_loss\": reconstruction_loss.item(),\n",
    "                \"weighted_sparsity_loss\": weighted_sparsity_loss.item(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a407f",
   "metadata": {},
   "source": [
    "#### Dictionary Learning Implementation\n",
    "\n",
    "See [simple_dictionary_learning.ipynb](simple_dictionary_learning.ipynb) for a details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a1011",
   "metadata": {},
   "source": [
    "#### Extracting the learned dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating SparseAutoencoder with d_in=128, d_model=512, sparsity_target=0.05\n",
    "dictionary: Float32[torch.Tensor, \"sae_hidden sae_in\"] = sae_model.encoder.weight.detach()\n",
    "\n",
    "# ex: Dictionary shape: torch.Size([512, 128])\n",
    "print(f\"Dictionary shape: {dictionary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ba6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape dictionary elements to match original activation shape\n",
    "# (essentially `unflatting`)\n",
    "reshaped_dictionary = dictionary.reshape(sae_d_model, (cfg.n_ctx - 1), cfg.d_model)\n",
    "\n",
    "# Motivation: Extract the learned features (dictionary elements) from the encoder weights\n",
    "# ex: Dictionary shape: torch.Size([512, 8, 16])\n",
    "print(f\"Dictionary shape: {reshaped_dictionary.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac34bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's always worth checking this sort of thing when you do this by hand\n",
    "# to check that you haven't got the wrong site, or are missing a\n",
    "# scaling factor or something like this.\n",
    "#\n",
    "# This is like the overfitting thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afd13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f65ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at an example batch from `test`\n",
    "\n",
    "# set both to eval mode\n",
    "model.eval()\n",
    "sae_model.eval()\n",
    "\n",
    "# grab something from the test batch\n",
    "example_batch = next(iter(test_loader))\n",
    "\n",
    "x, y = example_batch\n",
    "\n",
    "_, cache = model.run_with_cache(x)\n",
    "\n",
    "activations = cache[hook_id]\n",
    "\n",
    "print(f\"Activations shape: {activations.shape}\")\n",
    "\n",
    "# flatten it\n",
    "flattened_activations = activations.reshape(activations.size(0), -1)\n",
    "\n",
    "print(f\"{flattened_activations.shape=}\")\n",
    "\n",
    "sae_outputs = sae_model(flattened_activations)\n",
    "\n",
    "print(f\"{sae_outputs.sae_activations.shape=}\")\n",
    "print(f\"{sae_outputs.reconstructed_model_activations.shape=}\")\n",
    "\n",
    "# now we can get the dictionary\n",
    "dictionary = sae_model.encoder.weight.detach()\n",
    "\n",
    "print(f\"Dictionary shape: {dictionary.shape}\")\n",
    "\n",
    "# now we can get the sparse coefficients\n",
    "alpha = dictionary @ flattened_activations.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef94946",
   "metadata": {},
   "source": [
    "### Determine Quality Of SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sparsity(\n",
    "    sae_activations: BatchedSAEActivations,\n",
    "    threshold: float = 1e-5,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate sparsity of SAE activations across a batch.\n",
    "\n",
    "    Args:\n",
    "    sae_activations (torch.Tensor): The activations from the Sparse Autoencoder.\n",
    "                                    Shape: (batch, d_sae_model)\n",
    "    threshold (float): The threshold below which an activation is considered \"inactive\".\n",
    "\n",
    "    Returns:\n",
    "    float: The average sparsity value across the batch (fraction of inactive neurons).\n",
    "    \"\"\"\n",
    "    # Count the number of neurons that are below the threshold (inactive)\n",
    "    inactive_neurons = torch.sum(torch.abs(sae_activations) < threshold, dim=1)\n",
    "\n",
    "    # Calculate the fraction of inactive neurons for each item in the batch\n",
    "    sparsity_per_item = inactive_neurons.float() / sae_activations.shape[1]\n",
    "\n",
    "    # Take the mean across the batch\n",
    "    average_sparsity = torch.mean(sparsity_per_item)\n",
    "\n",
    "    return average_sparsity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce98afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_explained_variance(\n",
    "    reconstructed_model_activations: BatchedFlattenedModelActivations,\n",
    "    flattened_activations: BatchedFlattenedModelActivations,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Calculate the explained variance of the SAE activations.\n",
    "    \"\"\"\n",
    "\n",
    "    numerator = torch.mean(\n",
    "        (reconstructed_model_activations[:, 1:] - flattened_activations[:, 1:]) ** 2\n",
    "    )\n",
    "    denominator = flattened_activations[:, 1:].to(torch.float32).var()\n",
    "\n",
    "    explained_variance = 1 - (numerator / denominator)\n",
    "\n",
    "    return explained_variance.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba21e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explained_variance=0.995 -> good, basically all the variance is explained by our SAE\n",
    "# sparsity=0.0045 -> good, very sparse, and more sparse than our target of 0.05\n",
    "explained_variance = calculate_explained_variance(\n",
    "    sae_outputs.reconstructed_model_activations,\n",
    "    flattened_activations,\n",
    ")\n",
    "print(f\"{explained_variance=:.4f}\")\n",
    "\n",
    "sparsity = calculate_sparsity(sae_outputs.sae_activations)\n",
    "print(f\"{sparsity=:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa3d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's analyze the relationship between SAE activations and input features\n",
    "\n",
    "# TODO(bschoen): Oh `imshow` is huge here!\n",
    "\n",
    "# 1. Visualize the dictionary (encoder weights)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(dictionary.cpu().T, aspect=\"auto\", cmap=\"RdBu_r\")\n",
    "plt.colorbar()\n",
    "plt.title(\"SAE Dictionary (Encoder Weights)\")\n",
    "plt.xlabel(\"Dictionary Elements\")\n",
    "plt.ylabel(\"Input Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Find the most active neurons for each input\n",
    "top_k = 5  # Number of top activations to consider\n",
    "\n",
    "# so this is essentially the top 5 activations over `batch_size` examples\n",
    "top_activations = torch.topk(sae_outputs.sae_activations, k=top_k, dim=1)\n",
    "\n",
    "# Visualization of top activations\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.heatmap(top_activations.values.detach().cpu().numpy(), cmap=\"viridis\", annot=True, fmt=\".2f\")\n",
    "plt.title(\"Top 5 Activation Values\")\n",
    "plt.xlabel(\"Top K\")\n",
    "plt.ylabel(\"Batch Sample\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.heatmap(top_activations.indices.detach().cpu().numpy(), cmap=\"YlOrRd\", annot=True, fmt=\"d\")\n",
    "plt.title(\"Indices of Top 5 Activations\")\n",
    "plt.xlabel(\"Top K\")\n",
    "plt.ylabel(\"Batch Sample\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: frequency of top neurons\n",
    "top_neuron_counts = torch.bincount(\n",
    "    top_activations.indices.flatten().detach().cpu(),\n",
    "    minlength=sae_outputs.sae_activations.shape[1],\n",
    ")\n",
    "top_10_neurons = torch.topk(top_neuron_counts, k=10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(10), top_10_neurons.values.detach().cpu().numpy())\n",
    "plt.title(\"Top 10 Most Frequently Activated Neurons\")\n",
    "plt.xlabel(\"Neuron Index\")\n",
    "plt.ylabel(\"Activation Frequency\")\n",
    "plt.xticks(range(10), top_10_neurons.indices.detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52cdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_outputs.sae_activations[:, 1210]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{sae_outputs.sae_activations.shape=}\")\n",
    "print(f\"{top_activations.values.shape=}\")\n",
    "print(f\"{top_activations.indices.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_activations.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4932383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex: 51 and 410 show up a lot\n",
    "sns.heatmap(top_activations.values.cpu().T, cmap=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Analyze feature importance for each neuron\n",
    "feature_importance = torch.abs(dictionary).sum(dim=1)\n",
    "top_features = torch.topk(feature_importance, k=10)\n",
    "\n",
    "print(f\"{dictionary.shape=}\")\n",
    "print(f\"{feature_importance.shape=}\")\n",
    "print(f\"{top_features.values.shape=}\")\n",
    "print(f\"{top_features.indices.shape=}\")\n",
    "\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597dd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTop 10 most important neurons:\")\n",
    "for i, (value, index) in enumerate(\n",
    "    zip(top_features.values.tolist(), top_features.indices.tolist())\n",
    "):\n",
    "    print(f\"Neuron {index}:\\t{value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0168d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77201da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features.indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Visualize activations for a few examples\n",
    "\n",
    "# first look at a single batch\n",
    "sae_activations = sae_outputs.sae_activations[0].detach().cpu()\n",
    "\n",
    "print(f\"{sae_activations.shape=}\")\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 1, 1)\n",
    "\n",
    "# Look at a single batch\n",
    "plt.bar(range(sae_activations.shape[0]), sae_activations)\n",
    "\n",
    "plt.title(f\"SAE Activations for Example\")\n",
    "plt.xlabel(\"Neuron\")\n",
    "plt.ylabel(\"Activation\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0fa395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a496682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Reconstruct input features from SAE activations\n",
    "#\n",
    "# Take a single batch first\n",
    "reconstructed_model_activations = sae_outputs.reconstructed_model_activations.detach().cpu()\n",
    "\n",
    "# 6. Compare original and reconstructed features\n",
    "num_features = 5\n",
    "\n",
    "plt.figure(figsize=(15, 3 * num_features))\n",
    "for i in range(num_features):\n",
    "    plt.subplot(num_features, 1, i + 1)\n",
    "    plt.ylim(-1, 1)  # Set y-axis range from -1 to 1\n",
    "    plt.plot(flattened_activations[:, i].cpu(), label=\"Original\", alpha=0.5)\n",
    "    plt.plot(reconstructed_model_activations[:, i], label=\"Reconstructed\", alpha=0.5)\n",
    "    plt.title(f\"Feature {i}: Original vs Reconstructed\")\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b59930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Correlation between SAE activations and input features\n",
    "correlation_matrix = torch.corrcoef(\n",
    "    torch.cat([sae_outputs.sae_activations, flattened_activations], dim=1).T\n",
    ")\n",
    "num_neurons = sae_outputs.sae_activations.shape[1]\n",
    "neuron_feature_correlation = correlation_matrix[:num_neurons, num_neurons:]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(\n",
    "    neuron_feature_correlation.detach().cpu(),\n",
    "    aspect=\"auto\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    ")\n",
    "plt.colorbar()\n",
    "plt.title(\"Correlation between SAE Neurons and Input Features\")\n",
    "plt.xlabel(\"Input Features\")\n",
    "plt.ylabel(\"SAE Neurons\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d72027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385d16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02318ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47054e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_outputs.sae_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960382a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9c6bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcdbe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect max activations\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # go through the training data again, but don't cycle, no reason to go through more than once\n",
    "    for batch in tqdm.tqdm(train_loader):\n",
    "\n",
    "        tokens, target = batch\n",
    "\n",
    "        tokens, target = tokens.to(device), target.to(device)\n",
    "\n",
    "        # run through the model (with cache) to get the activations\n",
    "        logits, cache = model.run_with_cache(tokens)\n",
    "\n",
    "        # ex: torch.Size([4, 8, 16])\n",
    "        activations = cache[hook_id]\n",
    "\n",
    "        # ex: torch.Size([4, 128])\n",
    "        flattened_activations = activations.reshape(activations.size(0), -1)\n",
    "\n",
    "        # now the SAE model is given the *activations*\n",
    "        encoded, decoded = sae_model(flattened_activations)\n",
    "\n",
    "        sae_activations = encoded\n",
    "\n",
    "        # sae_activations.reshape(sae_d_model, (cfg.n_ctx - 1), cfg.d_model)\n",
    "\n",
    "        # max_activations = torch.max(encoded, dim=1)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc950af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = sae_model.encoder.weight @ flattened_activations[0]\n",
    "\n",
    "print(f\"{alpha.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9278a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.abs(alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae_activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04427556",
   "metadata": {},
   "outputs": [],
   "source": [
    "8 * 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5474f153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
