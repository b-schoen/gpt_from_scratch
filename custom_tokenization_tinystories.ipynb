{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da35ebe7-1521-411c-a821-d448f3ffff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc806079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import regex as re\n",
    "\n",
    "from gpt_from_scratch.dataset_loaders import (\n",
    "    tinystories_loader,\n",
    "    tinyshakespeare_loader,\n",
    ")\n",
    "from gpt_from_scratch import (\n",
    "    file_utils,\n",
    "    tokenizer_utils,\n",
    "    byte_pair_encoding_tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaccb6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference tokenizer to use for special tokens\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "585911f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<|endoftext|>': 50256}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer._special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e1320b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mType:\u001b[0m        dict\n",
      "\u001b[0;31mString form:\u001b[0m {b'!': 0, b'\"': 1, b'#': 2, b'$': 3, b'%': 4, b'&': 5, b\"'\": 6, b'(': 7, b')': 8, b'*': 9, b'+':  <...> inated': 50251, b' regress': 50252, b' Collider': 50253, b' informants': 50254, b' gazed': 50255}\n",
      "\u001b[0;31mLength:\u001b[0m      50256\n",
      "\u001b[0;31mDocstring:\u001b[0m  \n",
      "dict() -> new empty dictionary\n",
      "dict(mapping) -> new dictionary initialized from a mapping object's\n",
      "    (key, value) pairs\n",
      "dict(iterable) -> new dictionary initialized as if via:\n",
      "    d = {}\n",
      "    for k, v in iterable:\n",
      "        d[k] = v\n",
      "dict(**kwargs) -> new dictionary initialized with the name=value pairs\n",
      "    in the keyword argument list.  For example:  dict(one=1, two=2)"
     ]
    }
   ],
   "source": [
    "tokenizer._mergeable_ranks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0f3de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TinyStoriesV2-GPT4-train.txt...\n",
      "Downloaded TinyStoriesV2-GPT4-train.txt to /Users/bronsonschoen/.cache/huggingface/hub/datasets--roneneldan--TinyStories/snapshots/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/TinyStoriesV2-GPT4-train.txt\n",
      "Downloading TinyStoriesV2-GPT4-valid.txt...\n",
      "Downloaded TinyStoriesV2-GPT4-valid.txt to /Users/bronsonschoen/.cache/huggingface/hub/datasets--roneneldan--TinyStories/snapshots/f54c09fd23315a6f9c86f9dc80f725de7d8f9c64/TinyStoriesV2-GPT4-valid.txt\n"
     ]
    }
   ],
   "source": [
    "# load tinystories\n",
    "tinystories_version = tinystories_loader.TinyStoriesVersion.V2\n",
    "\n",
    "tinystories_filepaths = tinystories_loader.download_tinystories(\n",
    "    tinystories_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b1799ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a subset to actually test out tokenizer on\n",
    "\n",
    "# note: full tinystories training set is 15,600,056 lines\n",
    "num_samples = 100000\n",
    "\n",
    "input_text_lines = file_utils.head(\n",
    "    filepath=tinystories_filepaths.train,\n",
    "    n=num_samples,\n",
    ")\n",
    "\n",
    "# join it together, since this is small enough for us to keep in memory\n",
    "# note: removes empty lines\n",
    "input_text = '\\n'.join([x for x in input_text_lines if x != ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "50617c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(bschoen): More general handling of special tokens? Is this okay? We actually\n",
    "#                still want to split this (so it needs to be in the regex pattern)\n",
    "#                but we don't want them merged during `bpe_merge`\n",
    "#\n",
    "#                This means we can assume that special tokens come in already split\n",
    "#                as an exact match (even if in a public api we'd want to construct\n",
    "#                this regex automatically for the user given special tokens)\n",
    "regex_pattern_str = '|'.join([\n",
    "    # Match whole words\n",
    "    #\n",
    "    #   \\b    - Represents a word boundary (transition from a non-word char to a word char or vice versa)\n",
    "    #   \\w+   - Matches one or more word characters (letters, digits, or underscores)\n",
    "    #   \\b    - Another word boundary to ensure we match whole words\n",
    "    #\n",
    "    r'\\b\\w+\\b', \n",
    "    #\n",
    "    # Match single punctuation marks\n",
    "    #\n",
    "    #   []       - Character set: match any single character listed inside the brackets\n",
    "    #   .,!?;:\"  - The actual characters we want to match (various punctuation marks)\n",
    "    #\n",
    "    r'[.,!?;:\"]',\n",
    "    # \n",
    "    # Match one or more whitespace characters  (spaces, tabs)\n",
    "    #\n",
    "    r'\\s+',\n",
    "    #\n",
    "    # Match the newline character\n",
    "    #\n",
    "    r'\\n',\n",
    "    #\n",
    "    # Match the special end-of-text token exactly\n",
    "    #\n",
    "    r'<\\|endoftext\\|>',\n",
    "])\n",
    "\n",
    "regex_pattern = re.compile(regex_pattern_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8c346f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42m\u001b[97mJack\u001b[0m\u001b[46m\u001b[97m \u001b[0m\u001b[41m\u001b[97mand\u001b[0m\u001b[43m\u001b[97m \u001b[0m\u001b[44m\u001b[97mJill\u001b[0m\u001b[45m\u001b[97m \u001b[0m\u001b[42m\u001b[97mwent\u001b[0m\u001b[46m\u001b[97m \u001b[0m\u001b[41m\u001b[97mup\u001b[0m\u001b[43m\u001b[97m \u001b[0m\u001b[44m\u001b[97mthe\u001b[0m\u001b[45m\u001b[97m \u001b[0m\u001b[42m\u001b[97mhill\u001b[0m\u001b[46m\u001b[97m\n",
      "\u001b[0m\u001b[41m\u001b[97mIt\u001b[0m\u001b[43m\u001b[97m \u001b[0m\u001b[44m\u001b[97mwas\u001b[0m\u001b[45m\u001b[97m \u001b[0m\u001b[42m\u001b[97mraining\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# show what it looks like (this also sanity checks that we get back the original string)\n",
    "split_string = regex_pattern.findall(\"Jack and Jill went up the hill\\nIt was raining\")\n",
    "\n",
    "print(tokenizer_utils.get_colored_tokenization_of_split_string(split_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9ca9ebb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing vocab_size=2048 from 620164 unmerged words...\n",
      "[vocab: 257 / 2048] Merging\t(b'h', b'e')\t(count: 40486)\t-> new token: 512\n",
      "[vocab: 258 / 2048] Merging\t(b'a', b'n')\t(count: 20944)\t-> new token: 513\n",
      "[vocab: 259 / 2048] Merging\t(b't', b'he')\t(count: 20276)\t-> new token: 514\n",
      "[vocab: 260 / 2048] Merging\t(b'e', b'd')\t(count: 15744)\t-> new token: 515\n",
      "[vocab: 261 / 2048] Merging\t(b't', b'o')\t(count: 14655)\t-> new token: 516\n",
      "[vocab: 262 / 2048] Merging\t(b'an', b'd')\t(count: 13376)\t-> new token: 517\n",
      "[vocab: 263 / 2048] Merging\t(b'i', b'n')\t(count: 11563)\t-> new token: 518\n",
      "[vocab: 264 / 2048] Merging\t(b'i', b't')\t(count: 9535)\t-> new token: 519\n",
      "[vocab: 265 / 2048] Merging\t(b'r', b'e')\t(count: 9453)\t-> new token: 520\n",
      "[vocab: 266 / 2048] Merging\t(b'w', b'a')\t(count: 9191)\t-> new token: 521\n",
      "[vocab: 267 / 2048] Merging\t(b'o', b'u')\t(count: 8947)\t-> new token: 522\n",
      "[vocab: 268 / 2048] Merging\t(b'e', b'n')\t(count: 8349)\t-> new token: 523\n",
      "[vocab: 269 / 2048] Merging\t(b'h', b'a')\t(count: 8228)\t-> new token: 524\n",
      "[vocab: 270 / 2048] Merging\t(b'T', b'he')\t(count: 7807)\t-> new token: 525\n",
      "[vocab: 271 / 2048] Merging\t(b'e', b'r')\t(count: 6861)\t-> new token: 526\n",
      "[vocab: 272 / 2048] Merging\t(b'a', b'y')\t(count: 6752)\t-> new token: 527\n",
      "[vocab: 273 / 2048] Merging\t(b'wa', b's')\t(count: 6723)\t-> new token: 528\n",
      "[vocab: 274 / 2048] Merging\t(b'o', b'm')\t(count: 6621)\t-> new token: 529\n",
      "[vocab: 275 / 2048] Merging\t(b'i', b's')\t(count: 6111)\t-> new token: 530\n",
      "[vocab: 276 / 2048] Merging\t(b'o', b'n')\t(count: 5957)\t-> new token: 531\n",
      "[vocab: 277 / 2048] Merging\t(b'a', b'r')\t(count: 5861)\t-> new token: 532\n",
      "[vocab: 278 / 2048] Merging\t(b'l', b'l')\t(count: 5755)\t-> new token: 533\n",
      "[vocab: 279 / 2048] Merging\t(b'i', b'd')\t(count: 5625)\t-> new token: 534\n",
      "[vocab: 280 / 2048] Merging\t(b's', b'a')\t(count: 5538)\t-> new token: 535\n",
      "[vocab: 281 / 2048] Merging\t(b'i', b'm')\t(count: 5537)\t-> new token: 536\n",
      "[vocab: 282 / 2048] Merging\t(b'l', b'e')\t(count: 5249)\t-> new token: 537\n",
      "[vocab: 283 / 2048] Merging\t(b'in', b'g')\t(count: 4837)\t-> new token: 538\n",
      "[vocab: 284 / 2048] Merging\t(b'd', b'o')\t(count: 4195)\t-> new token: 539\n",
      "[vocab: 285 / 2048] Merging\t(b'o', b't')\t(count: 4147)\t-> new token: 540\n",
      "[vocab: 286 / 2048] Merging\t(b's', b't')\t(count: 4039)\t-> new token: 541\n",
      "[vocab: 287 / 2048] Merging\t(b'o', b'r')\t(count: 3824)\t-> new token: 542\n",
      "[vocab: 288 / 2048] Merging\t(b'a', b'm')\t(count: 3765)\t-> new token: 543\n",
      "[vocab: 289 / 2048] Merging\t(b'The', b'y')\t(count: 3697)\t-> new token: 544\n",
      "[vocab: 290 / 2048] Merging\t(b'n', b'e')\t(count: 3659)\t-> new token: 545\n",
      "[vocab: 291 / 2048] Merging\t(b'i', b'r')\t(count: 3549)\t-> new token: 546\n",
      "[vocab: 292 / 2048] Merging\t(b'a', b't')\t(count: 3383)\t-> new token: 547\n",
      "[vocab: 293 / 2048] Merging\t(b'p', b'l')\t(count: 3382)\t-> new token: 548\n",
      "[vocab: 294 / 2048] Merging\t(b'H', b'e')\t(count: 3347)\t-> new token: 549\n",
      "[vocab: 295 / 2048] Merging\t(b'i', b'g')\t(count: 3259)\t-> new token: 550\n",
      "[vocab: 296 / 2048] Merging\t(b'i', b'l')\t(count: 3242)\t-> new token: 551\n",
      "[vocab: 297 / 2048] Merging\t(b'a', b'll')\t(count: 2963)\t-> new token: 552\n",
      "[vocab: 298 / 2048] Merging\t(b'b', b'e')\t(count: 2956)\t-> new token: 553\n",
      "[vocab: 299 / 2048] Merging\t(b'l', b'o')\t(count: 2927)\t-> new token: 554\n",
      "[vocab: 300 / 2048] Merging\t(b'r', b'i')\t(count: 2923)\t-> new token: 555\n",
      "[vocab: 301 / 2048] Merging\t(b'v', b'er')\t(count: 2864)\t-> new token: 556\n",
      "[vocab: 302 / 2048] Merging\t(b'u', b't')\t(count: 2857)\t-> new token: 557\n",
      "[vocab: 303 / 2048] Merging\t(b'd', b'ay')\t(count: 2833)\t-> new token: 558\n",
      "[vocab: 304 / 2048] Merging\t(b'h', b'is')\t(count: 2827)\t-> new token: 559\n",
      "[vocab: 305 / 2048] Merging\t(b'w', b'it')\t(count: 2793)\t-> new token: 560\n",
      "[vocab: 306 / 2048] Merging\t(b'pl', b'ay')\t(count: 2790)\t-> new token: 561\n",
      "[vocab: 307 / 2048] Merging\t(b's', b'e')\t(count: 2783)\t-> new token: 562\n",
      "[vocab: 308 / 2048] Merging\t(b'p', b'p')\t(count: 2778)\t-> new token: 563\n",
      "[vocab: 309 / 2048] Merging\t(b'wit', b'h')\t(count: 2761)\t-> new token: 564\n",
      "[vocab: 310 / 2048] Merging\t(b'he', b'r')\t(count: 2755)\t-> new token: 565\n",
      "[vocab: 311 / 2048] Merging\t(b'sa', b'id')\t(count: 2751)\t-> new token: 566\n",
      "[vocab: 312 / 2048] Merging\t(b'k', b'e')\t(count: 2641)\t-> new token: 567\n",
      "[vocab: 313 / 2048] Merging\t(b'S', b'he')\t(count: 2595)\t-> new token: 568\n",
      "[vocab: 314 / 2048] Merging\t(b'T', b'im')\t(count: 2591)\t-> new token: 569\n",
      "[vocab: 315 / 2048] Merging\t(b'u', b'n')\t(count: 2558)\t-> new token: 570\n",
      "[vocab: 316 / 2048] Merging\t(b'k', b'ed')\t(count: 2549)\t-> new token: 571\n",
      "[vocab: 317 / 2048] Merging\t(b'ha', b't')\t(count: 2460)\t-> new token: 572\n",
      "[vocab: 318 / 2048] Merging\t(b'c', b'e')\t(count: 2453)\t-> new token: 573\n",
      "[vocab: 319 / 2048] Merging\t(b'l', b'd')\t(count: 2424)\t-> new token: 574\n",
      "[vocab: 320 / 2048] Merging\t(b't', b'h')\t(count: 2390)\t-> new token: 575\n",
      "[vocab: 321 / 2048] Merging\t(b'f', b't')\t(count: 2328)\t-> new token: 576\n",
      "[vocab: 322 / 2048] Merging\t(b'an', b't')\t(count: 2212)\t-> new token: 577\n",
      "[vocab: 323 / 2048] Merging\t(b'b', b'ig')\t(count: 2209)\t-> new token: 578\n",
      "[vocab: 324 / 2048] Merging\t(b'e', b'x')\t(count: 2195)\t-> new token: 579\n",
      "[vocab: 325 / 2048] Merging\t(b'l', b'i')\t(count: 2168)\t-> new token: 580\n",
      "[vocab: 326 / 2048] Merging\t(b'en', b'd')\t(count: 2164)\t-> new token: 581\n",
      "[vocab: 327 / 2048] Merging\t(b'ver', b'y')\t(count: 2131)\t-> new token: 582\n",
      "[vocab: 328 / 2048] Merging\t(b'y', b'ou')\t(count: 2121)\t-> new token: 583\n",
      "[vocab: 329 / 2048] Merging\t(b'c', b'k')\t(count: 2103)\t-> new token: 584\n",
      "[vocab: 330 / 2048] Merging\t(b'o', b'w')\t(count: 2097)\t-> new token: 585\n",
      "[vocab: 331 / 2048] Merging\t(b'ha', b'pp')\t(count: 2057)\t-> new token: 586\n",
      "[vocab: 332 / 2048] Merging\t(b'v', b'e')\t(count: 2031)\t-> new token: 587\n",
      "[vocab: 333 / 2048] Merging\t(b'w', b'e')\t(count: 2015)\t-> new token: 588\n",
      "[vocab: 334 / 2048] Merging\t(b'il', b'y')\t(count: 1980)\t-> new token: 589\n",
      "[vocab: 335 / 2048] Merging\t(b'u', b'p')\t(count: 1973)\t-> new token: 590\n",
      "[vocab: 336 / 2048] Merging\t(b'n', b'ot')\t(count: 1959)\t-> new token: 591\n",
      "[vocab: 337 / 2048] Merging\t(b'a', b'd')\t(count: 1872)\t-> new token: 592\n",
      "[vocab: 338 / 2048] Merging\t(b'ri', b'end')\t(count: 1846)\t-> new token: 593\n",
      "[vocab: 339 / 2048] Merging\t(b'f', b'riend')\t(count: 1845)\t-> new token: 594\n",
      "[vocab: 340 / 2048] Merging\t(b'the', b'y')\t(count: 1844)\t-> new token: 595\n",
      "[vocab: 341 / 2048] Merging\t(b'ha', b'd')\t(count: 1834)\t-> new token: 596\n",
      "[vocab: 342 / 2048] Merging\t(b'w', b'ant')\t(count: 1805)\t-> new token: 597\n",
      "[vocab: 343 / 2048] Merging\t(b'o', b'f')\t(count: 1782)\t-> new token: 598\n",
      "[vocab: 344 / 2048] Merging\t(b'ex', b't')\t(count: 1753)\t-> new token: 599\n",
      "[vocab: 345 / 2048] Merging\t(b'g', b'e')\t(count: 1741)\t-> new token: 600\n",
      "[vocab: 346 / 2048] Merging\t(b'en', b'do')\t(count: 1737)\t-> new token: 601\n",
      "[vocab: 347 / 2048] Merging\t(b'om', b'e')\t(count: 1730)\t-> new token: 602\n",
      "[vocab: 348 / 2048] Merging\t(b'<', b'|')\t(count: 1727)\t-> new token: 603\n",
      "[vocab: 349 / 2048] Merging\t(b'<|', b'endo')\t(count: 1727)\t-> new token: 604\n",
      "[vocab: 350 / 2048] Merging\t(b'<|endo', b'ft')\t(count: 1727)\t-> new token: 605\n",
      "[vocab: 351 / 2048] Merging\t(b'<|endoft', b'ext')\t(count: 1727)\t-> new token: 606\n",
      "[vocab: 352 / 2048] Merging\t(b'<|endoftext', b'|')\t(count: 1727)\t-> new token: 607\n",
      "[vocab: 353 / 2048] Merging\t(b'<|endoftext|', b'>')\t(count: 1727)\t-> new token: 608\n",
      "[vocab: 354 / 2048] Merging\t(b'b', b'o')\t(count: 1710)\t-> new token: 609\n",
      "[vocab: 355 / 2048] Merging\t(b'L', b'ily')\t(count: 1696)\t-> new token: 610\n",
      "[vocab: 356 / 2048] Merging\t(b'n', b'd')\t(count: 1688)\t-> new token: 611\n",
      "[vocab: 357 / 2048] Merging\t(b'it', b't')\t(count: 1677)\t-> new token: 612\n",
      "[vocab: 358 / 2048] Merging\t(b'the', b'r')\t(count: 1673)\t-> new token: 613\n",
      "[vocab: 359 / 2048] Merging\t(b's', b'o')\t(count: 1641)\t-> new token: 614\n",
      "[vocab: 360 / 2048] Merging\t(b'happ', b'y')\t(count: 1638)\t-> new token: 615\n",
      "[vocab: 361 / 2048] Merging\t(b'en', b't')\t(count: 1611)\t-> new token: 616\n",
      "[vocab: 362 / 2048] Merging\t(b'c', b'h')\t(count: 1597)\t-> new token: 617\n",
      "[vocab: 363 / 2048] Merging\t(b'a', b'l')\t(count: 1586)\t-> new token: 618\n",
      "[vocab: 364 / 2048] Merging\t(b'm', b'om')\t(count: 1572)\t-> new token: 619\n",
      "[vocab: 365 / 2048] Merging\t(b'sa', b'w')\t(count: 1556)\t-> new token: 620\n",
      "[vocab: 366 / 2048] Merging\t(b'O', b'ne')\t(count: 1552)\t-> new token: 621\n",
      "[vocab: 367 / 2048] Merging\t(b't', b'hat')\t(count: 1535)\t-> new token: 622\n",
      "[vocab: 368 / 2048] Merging\t(b'r', b'o')\t(count: 1530)\t-> new token: 623\n",
      "[vocab: 369 / 2048] Merging\t(b'a', b's')\t(count: 1525)\t-> new token: 624\n",
      "[vocab: 370 / 2048] Merging\t(b'T', b'om')\t(count: 1525)\t-> new token: 625\n",
      "[vocab: 371 / 2048] Merging\t(b'f', b'or')\t(count: 1516)\t-> new token: 626\n",
      "[vocab: 372 / 2048] Merging\t(b'e', b's')\t(count: 1508)\t-> new token: 627\n",
      "[vocab: 373 / 2048] Merging\t(b't', b'im')\t(count: 1498)\t-> new token: 628\n",
      "[vocab: 374 / 2048] Merging\t(b'ou', b'ld')\t(count: 1490)\t-> new token: 629\n",
      "[vocab: 375 / 2048] Merging\t(b's', b'he')\t(count: 1469)\t-> new token: 630\n",
      "[vocab: 376 / 2048] Merging\t(b'f', b'e')\t(count: 1443)\t-> new token: 631\n",
      "[vocab: 377 / 2048] Merging\t(b'itt', b'le')\t(count: 1425)\t-> new token: 632\n",
      "[vocab: 378 / 2048] Merging\t(b'o', b'k')\t(count: 1417)\t-> new token: 633\n",
      "[vocab: 379 / 2048] Merging\t(b'l', b'ittle')\t(count: 1410)\t-> new token: 634\n",
      "[vocab: 380 / 2048] Merging\t(b'n', b'am')\t(count: 1400)\t-> new token: 635\n",
      "[vocab: 381 / 2048] Merging\t(b'ou', b'nd')\t(count: 1393)\t-> new token: 636\n",
      "[vocab: 382 / 2048] Merging\t(b'tim', b'e')\t(count: 1391)\t-> new token: 637\n",
      "[vocab: 383 / 2048] Merging\t(b'I', b't')\t(count: 1336)\t-> new token: 638\n",
      "[vocab: 384 / 2048] Merging\t(b'nam', b'ed')\t(count: 1330)\t-> new token: 639\n",
      "[vocab: 385 / 2048] Merging\t(b's', b'm')\t(count: 1316)\t-> new token: 640\n",
      "[vocab: 386 / 2048] Merging\t(b'the', b're')\t(count: 1309)\t-> new token: 641\n",
      "[vocab: 387 / 2048] Merging\t(b'r', b'y')\t(count: 1280)\t-> new token: 642\n",
      "[vocab: 388 / 2048] Merging\t(b'we', b're')\t(count: 1266)\t-> new token: 643\n",
      "[vocab: 389 / 2048] Merging\t(b'g', b'o')\t(count: 1241)\t-> new token: 644\n",
      "[vocab: 390 / 2048] Merging\t(b'v', b'ed')\t(count: 1228)\t-> new token: 645\n",
      "[vocab: 391 / 2048] Merging\t(b'b', b'ut')\t(count: 1220)\t-> new token: 646\n",
      "[vocab: 392 / 2048] Merging\t(b'want', b'ed')\t(count: 1214)\t-> new token: 647\n",
      "[vocab: 393 / 2048] Merging\t(b'a', b'ke')\t(count: 1183)\t-> new token: 648\n",
      "[vocab: 394 / 2048] Merging\t(b'a', b're')\t(count: 1181)\t-> new token: 649\n",
      "[vocab: 395 / 2048] Merging\t(b'w', b'ent')\t(count: 1162)\t-> new token: 650\n",
      "[vocab: 396 / 2048] Merging\t(b'friend', b's')\t(count: 1159)\t-> new token: 651\n",
      "[vocab: 397 / 2048] Merging\t(b'O', b'n')\t(count: 1138)\t-> new token: 652\n",
      "[vocab: 398 / 2048] Merging\t(b'h', b't')\t(count: 1135)\t-> new token: 653\n",
      "[vocab: 399 / 2048] Merging\t(b'ou', b't')\t(count: 1133)\t-> new token: 654\n",
      "[vocab: 400 / 2048] Merging\t(b's', b'h')\t(count: 1124)\t-> new token: 655\n",
      "[vocab: 401 / 2048] Merging\t(b'id', b'e')\t(count: 1116)\t-> new token: 656\n",
      "[vocab: 402 / 2048] Merging\t(b'r', b'a')\t(count: 1113)\t-> new token: 657\n",
      "[vocab: 403 / 2048] Merging\t(b'u', b'g')\t(count: 1102)\t-> new token: 658\n",
      "[vocab: 404 / 2048] Merging\t(b'ir', b'd')\t(count: 1099)\t-> new token: 659\n",
      "[vocab: 405 / 2048] Merging\t(b'On', b'ce')\t(count: 1088)\t-> new token: 660\n",
      "[vocab: 406 / 2048] Merging\t(b'u', b'e')\t(count: 1074)\t-> new token: 661\n",
      "[vocab: 407 / 2048] Merging\t(b'b', b'ird')\t(count: 1067)\t-> new token: 662\n",
      "[vocab: 408 / 2048] Merging\t(b'l', b'p')\t(count: 1054)\t-> new token: 663\n",
      "[vocab: 409 / 2048] Merging\t(b'd', b'id')\t(count: 1040)\t-> new token: 664\n",
      "[vocab: 410 / 2048] Merging\t(b'c', b'ar')\t(count: 1039)\t-> new token: 665\n",
      "[vocab: 411 / 2048] Merging\t(b'up', b'on')\t(count: 1030)\t-> new token: 666\n",
      "[vocab: 412 / 2048] Merging\t(b'i', b'll')\t(count: 1022)\t-> new token: 667\n",
      "[vocab: 413 / 2048] Merging\t(b'm', b'y')\t(count: 1021)\t-> new token: 668\n",
      "[vocab: 414 / 2048] Merging\t(b'he', b'lp')\t(count: 1020)\t-> new token: 669\n",
      "[vocab: 415 / 2048] Merging\t(b'o', b'd')\t(count: 1016)\t-> new token: 670\n",
      "[vocab: 416 / 2048] Merging\t(b'th', b'ing')\t(count: 1014)\t-> new token: 671\n",
      "[vocab: 417 / 2048] Merging\t(b'l', b'y')\t(count: 982)\t-> new token: 672\n",
      "[vocab: 418 / 2048] Merging\t(b'to', b'y')\t(count: 981)\t-> new token: 673\n",
      "[vocab: 419 / 2048] Merging\t(b'f', b'un')\t(count: 978)\t-> new token: 674\n",
      "[vocab: 420 / 2048] Merging\t(b'p', b'e')\t(count: 976)\t-> new token: 675\n",
      "[vocab: 421 / 2048] Merging\t(b'am', b'e')\t(count: 959)\t-> new token: 676\n",
      "[vocab: 422 / 2048] Merging\t(b'u', b'r')\t(count: 946)\t-> new token: 677\n",
      "[vocab: 423 / 2048] Merging\t(b'do', b'g')\t(count: 939)\t-> new token: 678\n",
      "[vocab: 424 / 2048] Merging\t(b'a', b'g')\t(count: 935)\t-> new token: 679\n",
      "[vocab: 425 / 2048] Merging\t(b'on', b'e')\t(count: 933)\t-> new token: 680\n",
      "[vocab: 426 / 2048] Merging\t(b'm', b'e')\t(count: 930)\t-> new token: 681\n",
      "[vocab: 427 / 2048] Merging\t(b'c', b'at')\t(count: 926)\t-> new token: 682\n",
      "[vocab: 428 / 2048] Merging\t(b's', b'ome')\t(count: 912)\t-> new token: 683\n",
      "[vocab: 429 / 2048] Merging\t(b'ge', b'ther')\t(count: 910)\t-> new token: 684\n",
      "[vocab: 430 / 2048] Merging\t(b'to', b'gether')\t(count: 887)\t-> new token: 685\n",
      "[vocab: 431 / 2048] Merging\t(b'wa', b'y')\t(count: 884)\t-> new token: 686\n",
      "[vocab: 432 / 2048] Merging\t(b't', b're')\t(count: 873)\t-> new token: 687\n",
      "[vocab: 433 / 2048] Merging\t(b'a', b'x')\t(count: 871)\t-> new token: 688\n",
      "[vocab: 434 / 2048] Merging\t(b'm', b'an')\t(count: 866)\t-> new token: 689\n",
      "[vocab: 435 / 2048] Merging\t(b't', b'ed')\t(count: 865)\t-> new token: 690\n",
      "[vocab: 436 / 2048] Merging\t(b'a', b'ck')\t(count: 856)\t-> new token: 691\n",
      "[vocab: 437 / 2048] Merging\t(b'm', b'o')\t(count: 855)\t-> new token: 692\n",
      "[vocab: 438 / 2048] Merging\t(b'in', b'd')\t(count: 853)\t-> new token: 693\n",
      "[vocab: 439 / 2048] Merging\t(b'M', b'ax')\t(count: 835)\t-> new token: 694\n",
      "[vocab: 440 / 2048] Merging\t(b'B', b'ut')\t(count: 823)\t-> new token: 695\n",
      "[vocab: 441 / 2048] Merging\t(b'c', b'ame')\t(count: 820)\t-> new token: 696\n",
      "[vocab: 442 / 2048] Merging\t(b'ne', b'w')\t(count: 815)\t-> new token: 697\n",
      "[vocab: 443 / 2048] Merging\t(b'the', b'ir')\t(count: 810)\t-> new token: 698\n",
      "[vocab: 444 / 2048] Merging\t(b'c', b'an')\t(count: 804)\t-> new token: 699\n",
      "[vocab: 445 / 2048] Merging\t(b't', b'er')\t(count: 803)\t-> new token: 700\n",
      "[vocab: 446 / 2048] Merging\t(b'i', b'c')\t(count: 801)\t-> new token: 701\n",
      "[vocab: 447 / 2048] Merging\t(b'b', b'all')\t(count: 795)\t-> new token: 702\n",
      "[vocab: 448 / 2048] Merging\t(b'p', b'ar')\t(count: 778)\t-> new token: 703\n",
      "[vocab: 449 / 2048] Merging\t(b'h', b'o')\t(count: 764)\t-> new token: 704\n",
      "[vocab: 450 / 2048] Merging\t(b'h', b'im')\t(count: 763)\t-> new token: 705\n",
      "[vocab: 451 / 2048] Merging\t(b'the', b'm')\t(count: 758)\t-> new token: 706\n",
      "[vocab: 452 / 2048] Merging\t(b'c', b'ould')\t(count: 758)\t-> new token: 707\n",
      "[vocab: 453 / 2048] Merging\t(b'play', b'ed')\t(count: 753)\t-> new token: 708\n",
      "[vocab: 454 / 2048] Merging\t(b'sa', b'd')\t(count: 745)\t-> new token: 709\n",
      "[vocab: 455 / 2048] Merging\t(b'S', b'ue')\t(count: 737)\t-> new token: 710\n",
      "[vocab: 456 / 2048] Merging\t(b'f', b'u')\t(count: 725)\t-> new token: 711\n",
      "[vocab: 457 / 2048] Merging\t(b'bo', b'y')\t(count: 724)\t-> new token: 712\n",
      "[vocab: 458 / 2048] Merging\t(b'c', b'o')\t(count: 719)\t-> new token: 713\n",
      "[vocab: 459 / 2048] Merging\t(b'to', b'o')\t(count: 716)\t-> new token: 714\n",
      "[vocab: 460 / 2048] Merging\t(b'u', b'm')\t(count: 711)\t-> new token: 715\n",
      "[vocab: 461 / 2048] Merging\t(b'he', b'n')\t(count: 706)\t-> new token: 716\n",
      "[vocab: 462 / 2048] Merging\t(b'st', b'ar')\t(count: 696)\t-> new token: 717\n",
      "[vocab: 463 / 2048] Merging\t(b'tre', b'e')\t(count: 696)\t-> new token: 718\n",
      "[vocab: 464 / 2048] Merging\t(b'g', b'ir')\t(count: 691)\t-> new token: 719\n",
      "[vocab: 465 / 2048] Merging\t(b'ha', b've')\t(count: 691)\t-> new token: 720\n",
      "[vocab: 466 / 2048] Merging\t(b'r', b'om')\t(count: 689)\t-> new token: 721\n",
      "[vocab: 467 / 2048] Merging\t(b'lo', b'ved')\t(count: 680)\t-> new token: 722\n",
      "[vocab: 468 / 2048] Merging\t(b'gir', b'l')\t(count: 671)\t-> new token: 723\n",
      "[vocab: 469 / 2048] Merging\t(b'p', b'ot')\t(count: 669)\t-> new token: 724\n",
      "[vocab: 470 / 2048] Merging\t(b'o', b'ked')\t(count: 667)\t-> new token: 725\n",
      "[vocab: 471 / 2048] Merging\t(b'b', b'ack')\t(count: 666)\t-> new token: 726\n",
      "[vocab: 472 / 2048] Merging\t(b'he', b'd')\t(count: 661)\t-> new token: 727\n",
      "[vocab: 473 / 2048] Merging\t(b'f', b'o')\t(count: 660)\t-> new token: 728\n",
      "[vocab: 474 / 2048] Merging\t(b'e', b't')\t(count: 657)\t-> new token: 729\n",
      "[vocab: 475 / 2048] Merging\t(b'f', b'ound')\t(count: 651)\t-> new token: 730\n",
      "[vocab: 476 / 2048] Merging\t(b'li', b'ke')\t(count: 645)\t-> new token: 731\n",
      "[vocab: 477 / 2048] Merging\t(b'l', b'a')\t(count: 645)\t-> new token: 732\n",
      "[vocab: 478 / 2048] Merging\t(b'lo', b'oked')\t(count: 636)\t-> new token: 733\n",
      "[vocab: 479 / 2048] Merging\t(b'a', b'in')\t(count: 631)\t-> new token: 734\n",
      "[vocab: 480 / 2048] Merging\t(b's', b'ide')\t(count: 624)\t-> new token: 735\n",
      "[vocab: 481 / 2048] Merging\t(b's', b'to')\t(count: 621)\t-> new token: 736\n",
      "[vocab: 482 / 2048] Merging\t(b'par', b'k')\t(count: 621)\t-> new token: 737\n",
      "[vocab: 483 / 2048] Merging\t(b'ou', b'g')\t(count: 619)\t-> new token: 738\n",
      "[vocab: 484 / 2048] Merging\t(b'S', b'am')\t(count: 618)\t-> new token: 739\n",
      "[vocab: 485 / 2048] Merging\t(b'o', b'p')\t(count: 609)\t-> new token: 740\n",
      "[vocab: 486 / 2048] Merging\t(b'f', b'a')\t(count: 602)\t-> new token: 741\n",
      "[vocab: 487 / 2048] Merging\t(b'w', b'n')\t(count: 600)\t-> new token: 742\n",
      "[vocab: 488 / 2048] Merging\t(b'd', b'e')\t(count: 599)\t-> new token: 743\n",
      "[vocab: 489 / 2048] Merging\t(b'on', b'g')\t(count: 599)\t-> new token: 744\n",
      "[vocab: 490 / 2048] Merging\t(b'a', b'b')\t(count: 595)\t-> new token: 745\n",
      "[vocab: 491 / 2048] Merging\t(b'n', b'ow')\t(count: 592)\t-> new token: 746\n",
      "[vocab: 492 / 2048] Merging\t(b'l', b't')\t(count: 592)\t-> new token: 747\n",
      "[vocab: 493 / 2048] Merging\t(b'w', b'ould')\t(count: 582)\t-> new token: 748\n",
      "[vocab: 494 / 2048] Merging\t(b'S', b'pot')\t(count: 573)\t-> new token: 749\n",
      "[vocab: 495 / 2048] Merging\t(b'star', b'ted')\t(count: 571)\t-> new token: 750\n",
      "[vocab: 496 / 2048] Merging\t(b'c', b'a')\t(count: 571)\t-> new token: 751\n",
      "[vocab: 497 / 2048] Merging\t(b'r', b'an')\t(count: 567)\t-> new token: 752\n",
      "[vocab: 498 / 2048] Merging\t(b'fu', b'l')\t(count: 564)\t-> new token: 753\n",
      "[vocab: 499 / 2048] Merging\t(b'se', b'e')\t(count: 560)\t-> new token: 754\n",
      "[vocab: 500 / 2048] Merging\t(b'fe', b'lt')\t(count: 556)\t-> new token: 755\n",
      "[vocab: 501 / 2048] Merging\t(b' ', b'\\n')\t(count: 555)\t-> new token: 756\n",
      "[vocab: 502 / 2048] Merging\t(b'li', b'ked')\t(count: 554)\t-> new token: 757\n",
      "[vocab: 503 / 2048] Merging\t(b's', b'ay')\t(count: 545)\t-> new token: 758\n",
      "[vocab: 504 / 2048] Merging\t(b'o', b'ther')\t(count: 544)\t-> new token: 759\n",
      "[vocab: 505 / 2048] Merging\t(b'p', b'r')\t(count: 538)\t-> new token: 760\n",
      "[vocab: 506 / 2048] Merging\t(b'ou', b'se')\t(count: 537)\t-> new token: 761\n",
      "[vocab: 507 / 2048] Merging\t(b'm', b'ake')\t(count: 537)\t-> new token: 762\n",
      "[vocab: 508 / 2048] Merging\t(b'ig', b'ht')\t(count: 535)\t-> new token: 763\n",
      "[vocab: 509 / 2048] Merging\t(b'w', b'or')\t(count: 524)\t-> new token: 764\n",
      "[vocab: 510 / 2048] Merging\t(b'sm', b'all')\t(count: 518)\t-> new token: 765\n",
      "[vocab: 511 / 2048] Merging\t(b'B', b'en')\t(count: 514)\t-> new token: 766\n",
      "[vocab: 512 / 2048] Merging\t(b'as', b'ked')\t(count: 513)\t-> new token: 767\n",
      "[vocab: 513 / 2048] Merging\t(b'Y', b'ou')\t(count: 511)\t-> new token: 768\n",
      "[vocab: 514 / 2048] Merging\t(b'ar', b'd')\t(count: 510)\t-> new token: 769\n",
      "[vocab: 515 / 2048] Merging\t(b'il', b'ed')\t(count: 508)\t-> new token: 770\n",
      "[vocab: 516 / 2048] Merging\t(b'mo', b're')\t(count: 508)\t-> new token: 771\n",
      "[vocab: 517 / 2048] Merging\t(b'm', b'ad')\t(count: 505)\t-> new token: 772\n",
      "[vocab: 518 / 2048] Merging\t(b'i', b'a')\t(count: 499)\t-> new token: 773\n",
      "[vocab: 519 / 2048] Merging\t(b'go', b'od')\t(count: 494)\t-> new token: 774\n",
      "[vocab: 520 / 2048] Merging\t(b'p', b'ut')\t(count: 494)\t-> new token: 775\n",
      "[vocab: 521 / 2048] Merging\t(b'ri', b'ed')\t(count: 489)\t-> new token: 776\n",
      "[vocab: 522 / 2048] Merging\t(b'g', b'r')\t(count: 485)\t-> new token: 777\n",
      "[vocab: 523 / 2048] Merging\t(b'sm', b'iled')\t(count: 482)\t-> new token: 778\n",
      "[vocab: 524 / 2048] Merging\t(b'oug', b'ht')\t(count: 479)\t-> new token: 779\n",
      "[vocab: 525 / 2048] Merging\t(b'i', b'ce')\t(count: 470)\t-> new token: 780\n",
      "[vocab: 526 / 2048] Merging\t(b'a', b'way')\t(count: 470)\t-> new token: 781\n",
      "[vocab: 527 / 2048] Merging\t(b'mad', b'e')\t(count: 469)\t-> new token: 782\n",
      "[vocab: 528 / 2048] Merging\t(b'some', b'thing')\t(count: 467)\t-> new token: 783\n",
      "[vocab: 529 / 2048] Merging\t(b'M', b'om')\t(count: 467)\t-> new token: 784\n",
      "[vocab: 530 / 2048] Merging\t(b's', b'ha')\t(count: 462)\t-> new token: 785\n",
      "[vocab: 531 / 2048] Merging\t(b'M', b'ia')\t(count: 457)\t-> new token: 786\n",
      "[vocab: 532 / 2048] Merging\t(b'h', b'ome')\t(count: 454)\t-> new token: 787\n",
      "[vocab: 533 / 2048] Merging\t(b'r', b'ed')\t(count: 454)\t-> new token: 788\n",
      "[vocab: 534 / 2048] Merging\t(b's', b'car')\t(count: 449)\t-> new token: 789\n",
      "[vocab: 535 / 2048] Merging\t(b'w', b'hat')\t(count: 449)\t-> new token: 790\n",
      "[vocab: 536 / 2048] Merging\t(b'ar', b'n')\t(count: 448)\t-> new token: 791\n",
      "[vocab: 537 / 2048] Merging\t(b'n', b'o')\t(count: 446)\t-> new token: 792\n",
      "[vocab: 538 / 2048] Merging\t(b'en', b'ed')\t(count: 444)\t-> new token: 793\n",
      "[vocab: 539 / 2048] Merging\t(b'do', b'wn')\t(count: 443)\t-> new token: 794\n",
      "[vocab: 540 / 2048] Merging\t(b'u', b'c')\t(count: 439)\t-> new token: 795\n",
      "[vocab: 541 / 2048] Merging\t(b'f', b'rom')\t(count: 438)\t-> new token: 796\n",
      "[vocab: 542 / 2048] Merging\t(b'ag', b'ain')\t(count: 437)\t-> new token: 797\n",
      "[vocab: 543 / 2048] Merging\t(b'is', b'h')\t(count: 436)\t-> new token: 798\n",
      "[vocab: 544 / 2048] Merging\t(b'm', b'u')\t(count: 435)\t-> new token: 799\n",
      "[vocab: 545 / 2048] Merging\t(b'play', b'ing')\t(count: 433)\t-> new token: 800\n",
      "[vocab: 546 / 2048] Merging\t(b'h', b'ouse')\t(count: 431)\t-> new token: 801\n",
      "[vocab: 547 / 2048] Merging\t(b'e', b'l')\t(count: 427)\t-> new token: 802\n",
      "[vocab: 548 / 2048] Merging\t(b'f', b'ind')\t(count: 424)\t-> new token: 803\n",
      "[vocab: 549 / 2048] Merging\t(b'wa', b'l')\t(count: 423)\t-> new token: 804\n",
      "[vocab: 550 / 2048] Merging\t(b't', b'y')\t(count: 422)\t-> new token: 805\n",
      "[vocab: 551 / 2048] Merging\t(b'bo', b'x')\t(count: 417)\t-> new token: 806\n",
      "[vocab: 552 / 2048] Merging\t(b'la', b'ug')\t(count: 416)\t-> new token: 807\n",
      "[vocab: 553 / 2048] Merging\t(b'th', b'ought')\t(count: 414)\t-> new token: 808\n",
      "[vocab: 554 / 2048] Merging\t(b'ar', b'ound')\t(count: 412)\t-> new token: 809\n",
      "[vocab: 555 / 2048] Merging\t(b'i', b'le')\t(count: 412)\t-> new token: 810\n",
      "[vocab: 556 / 2048] Merging\t(b'u', b'se')\t(count: 410)\t-> new token: 811\n",
      "[vocab: 557 / 2048] Merging\t(b'e', b'very')\t(count: 406)\t-> new token: 812\n",
      "[vocab: 558 / 2048] Merging\t(b'o', b'b')\t(count: 405)\t-> new token: 813\n",
      "[vocab: 559 / 2048] Merging\t(b'toy', b's')\t(count: 404)\t-> new token: 814\n",
      "[vocab: 560 / 2048] Merging\t(b'say', b's')\t(count: 401)\t-> new token: 815\n",
      "[vocab: 561 / 2048] Merging\t(b're', b't')\t(count: 399)\t-> new token: 816\n",
      "[vocab: 562 / 2048] Merging\t(b'w', b'ill')\t(count: 398)\t-> new token: 817\n",
      "[vocab: 563 / 2048] Merging\t(b'g', b'ot')\t(count: 396)\t-> new token: 818\n",
      "[vocab: 564 / 2048] Merging\t(b'to', b'ok')\t(count: 393)\t-> new token: 819\n",
      "[vocab: 565 / 2048] Merging\t(b'le', b'arn')\t(count: 385)\t-> new token: 820\n",
      "[vocab: 566 / 2048] Merging\t(b's', b'un')\t(count: 385)\t-> new token: 821\n",
      "[vocab: 567 / 2048] Merging\t(b'S', b'o')\t(count: 384)\t-> new token: 822\n",
      "[vocab: 568 / 2048] Merging\t(b'l', b'ot')\t(count: 382)\t-> new token: 823\n",
      "[vocab: 569 / 2048] Merging\t(b'k', b'now')\t(count: 382)\t-> new token: 824\n",
      "[vocab: 570 / 2048] Merging\t(b'i', b'ck')\t(count: 382)\t-> new token: 825\n",
      "[vocab: 571 / 2048] Merging\t(b'b', b'ot')\t(count: 381)\t-> new token: 826\n",
      "[vocab: 572 / 2048] Merging\t(b'd', b'er')\t(count: 378)\t-> new token: 827\n",
      "[vocab: 573 / 2048] Merging\t(b'lo', b'ok')\t(count: 377)\t-> new token: 828\n",
      "[vocab: 574 / 2048] Merging\t(b'scar', b'ed')\t(count: 376)\t-> new token: 829\n",
      "[vocab: 575 / 2048] Merging\t(b'the', b'n')\t(count: 376)\t-> new token: 830\n",
      "[vocab: 576 / 2048] Merging\t(b'u', b'd')\t(count: 376)\t-> new token: 831\n",
      "[vocab: 577 / 2048] Merging\t(b'w', b'hen')\t(count: 375)\t-> new token: 832\n",
      "[vocab: 578 / 2048] Merging\t(b'li', b'ved')\t(count: 374)\t-> new token: 833\n",
      "[vocab: 579 / 2048] Merging\t(b'n', b'y')\t(count: 372)\t-> new token: 834\n",
      "[vocab: 580 / 2048] Merging\t(b'you', b'r')\t(count: 368)\t-> new token: 835\n",
      "[vocab: 581 / 2048] Merging\t(b'u', b're')\t(count: 368)\t-> new token: 836\n",
      "[vocab: 582 / 2048] Merging\t(b'a', b'ch')\t(count: 367)\t-> new token: 837\n",
      "[vocab: 583 / 2048] Merging\t(b'ge', b't')\t(count: 362)\t-> new token: 838\n",
      "[vocab: 584 / 2048] Merging\t(b'ro', b'om')\t(count: 360)\t-> new token: 839\n",
      "[vocab: 585 / 2048] Merging\t(b'pe', b'c')\t(count: 356)\t-> new token: 840\n",
      "[vocab: 586 / 2048] Merging\t(b'thing', b's')\t(count: 354)\t-> new token: 841\n",
      "[vocab: 587 / 2048] Merging\t(b'pp', b'ed')\t(count: 354)\t-> new token: 842\n",
      "[vocab: 588 / 2048] Merging\t(b's', b's')\t(count: 351)\t-> new token: 843\n",
      "[vocab: 589 / 2048] Merging\t(b'L', b'uc')\t(count: 351)\t-> new token: 844\n",
      "[vocab: 590 / 2048] Merging\t(b'Luc', b'y')\t(count: 351)\t-> new token: 845\n",
      "[vocab: 591 / 2048] Merging\t(b'i', b'e')\t(count: 349)\t-> new token: 846\n",
      "[vocab: 592 / 2048] Merging\t(b'it', b'ed')\t(count: 346)\t-> new token: 847\n",
      "[vocab: 593 / 2048] Merging\t(b'le', b'a')\t(count: 346)\t-> new token: 848\n",
      "[vocab: 594 / 2048] Merging\t(b'e', b'p')\t(count: 344)\t-> new token: 849\n",
      "[vocab: 595 / 2048] Merging\t(b'k', b'ing')\t(count: 342)\t-> new token: 850\n",
      "[vocab: 596 / 2048] Merging\t(b'um', b'p')\t(count: 340)\t-> new token: 851\n",
      "[vocab: 597 / 2048] Merging\t(b't', b'ried')\t(count: 340)\t-> new token: 852\n",
      "[vocab: 598 / 2048] Merging\t(b'an', b'y')\t(count: 339)\t-> new token: 853\n",
      "[vocab: 599 / 2048] Merging\t(b'u', b'st')\t(count: 336)\t-> new token: 854\n",
      "[vocab: 600 / 2048] Merging\t(b'b', b'y')\t(count: 335)\t-> new token: 855\n",
      "[vocab: 601 / 2048] Merging\t(b'u', b'ck')\t(count: 334)\t-> new token: 856\n",
      "[vocab: 602 / 2048] Merging\t(b'e', b'll')\t(count: 334)\t-> new token: 857\n",
      "[vocab: 603 / 2048] Merging\t(b'ou', b'd')\t(count: 333)\t-> new token: 858\n",
      "[vocab: 604 / 2048] Merging\t(b'g', b'i')\t(count: 333)\t-> new token: 859\n",
      "[vocab: 605 / 2048] Merging\t(b'w', b'ho')\t(count: 332)\t-> new token: 860\n",
      "[vocab: 606 / 2048] Merging\t(b'u', b's')\t(count: 331)\t-> new token: 861\n",
      "[vocab: 607 / 2048] Merging\t(b'ft', b'er')\t(count: 329)\t-> new token: 862\n",
      "[vocab: 608 / 2048] Merging\t(b'de', b'c')\t(count: 327)\t-> new token: 863\n",
      "[vocab: 609 / 2048] Merging\t(b'p', b'ic')\t(count: 324)\t-> new token: 864\n",
      "[vocab: 610 / 2048] Merging\t(b'm', b'a')\t(count: 322)\t-> new token: 865\n",
      "[vocab: 611 / 2048] Merging\t(b'f', b'ish')\t(count: 321)\t-> new token: 866\n",
      "[vocab: 612 / 2048] Merging\t(b'at', b'e')\t(count: 320)\t-> new token: 867\n",
      "[vocab: 613 / 2048] Merging\t(b'w', b'er')\t(count: 318)\t-> new token: 868\n",
      "[vocab: 614 / 2048] Merging\t(b'ud', b'd')\t(count: 317)\t-> new token: 869\n",
      "[vocab: 615 / 2048] Merging\t(b'all', b'y')\t(count: 314)\t-> new token: 870\n",
      "[vocab: 616 / 2048] Merging\t(b'ab', b'out')\t(count: 310)\t-> new token: 871\n",
      "[vocab: 617 / 2048] Merging\t(b'it', b'e')\t(count: 309)\t-> new token: 872\n",
      "[vocab: 618 / 2048] Merging\t(b'wa', b'ter')\t(count: 308)\t-> new token: 873\n",
      "[vocab: 619 / 2048] Merging\t(b'c', b'are')\t(count: 307)\t-> new token: 874\n",
      "[vocab: 620 / 2048] Merging\t(b'q', b'u')\t(count: 307)\t-> new token: 875\n",
      "[vocab: 621 / 2048] Merging\t(b'man', b'y')\t(count: 306)\t-> new token: 876\n",
      "[vocab: 622 / 2048] Merging\t(b'p', b'o')\t(count: 306)\t-> new token: 877\n",
      "[vocab: 623 / 2048] Merging\t(b'i', b'f')\t(count: 305)\t-> new token: 878\n",
      "[vocab: 624 / 2048] Merging\t(b'ar', b'a')\t(count: 305)\t-> new token: 879\n",
      "[vocab: 625 / 2048] Merging\t(b'p', b'u')\t(count: 305)\t-> new token: 880\n",
      "[vocab: 626 / 2048] Merging\t(b'f', b'lo')\t(count: 304)\t-> new token: 881\n",
      "[vocab: 627 / 2048] Merging\t(b'p', b'ret')\t(count: 301)\t-> new token: 882\n",
      "[vocab: 628 / 2048] Merging\t(b'l', b'ong')\t(count: 301)\t-> new token: 883\n",
      "[vocab: 629 / 2048] Merging\t(b'L', b'et')\t(count: 300)\t-> new token: 884\n",
      "[vocab: 630 / 2048] Merging\t(b'r', b'un')\t(count: 299)\t-> new token: 885\n",
      "[vocab: 631 / 2048] Merging\t(b'd', b'ad')\t(count: 298)\t-> new token: 886\n",
      "[vocab: 632 / 2048] Merging\t(b'ex', b'c')\t(count: 297)\t-> new token: 887\n",
      "[vocab: 633 / 2048] Merging\t(b'c', b'l')\t(count: 297)\t-> new token: 888\n",
      "[vocab: 634 / 2048] Merging\t(b'in', b'k')\t(count: 296)\t-> new token: 889\n",
      "[vocab: 635 / 2048] Merging\t(b's', b'or')\t(count: 295)\t-> new token: 890\n",
      "[vocab: 636 / 2048] Merging\t(b'c', b'le')\t(count: 295)\t-> new token: 891\n",
      "[vocab: 637 / 2048] Merging\t(b'ne', b'x')\t(count: 294)\t-> new token: 892\n",
      "[vocab: 638 / 2048] Merging\t(b'B', b'ob')\t(count: 294)\t-> new token: 893\n",
      "[vocab: 639 / 2048] Merging\t(b'k', b'new')\t(count: 294)\t-> new token: 894\n",
      "[vocab: 640 / 2048] Merging\t(b'ca', b'use')\t(count: 292)\t-> new token: 895\n",
      "[vocab: 641 / 2048] Merging\t(b'laug', b'hed')\t(count: 291)\t-> new token: 896\n",
      "[vocab: 642 / 2048] Merging\t(b'is', b't')\t(count: 291)\t-> new token: 897\n",
      "[vocab: 643 / 2048] Merging\t(b'g', b'a')\t(count: 290)\t-> new token: 898\n",
      "[vocab: 644 / 2048] Merging\t(b'learn', b'ed')\t(count: 290)\t-> new token: 899\n",
      "[vocab: 645 / 2048] Merging\t(b'w', b'h')\t(count: 290)\t-> new token: 900\n",
      "[vocab: 646 / 2048] Merging\t(b'th', b'an')\t(count: 288)\t-> new token: 901\n",
      "[vocab: 647 / 2048] Merging\t(b'c', b'ome')\t(count: 287)\t-> new token: 902\n",
      "[vocab: 648 / 2048] Merging\t(b'e', b'at')\t(count: 286)\t-> new token: 903\n",
      "[vocab: 649 / 2048] Merging\t(b'bo', b'ok')\t(count: 286)\t-> new token: 904\n",
      "[vocab: 650 / 2048] Merging\t(b'W', b'e')\t(count: 284)\t-> new token: 905\n",
      "[vocab: 651 / 2048] Merging\t(b'be', b'cause')\t(count: 284)\t-> new token: 906\n",
      "[vocab: 652 / 2048] Merging\t(b'id', b'ed')\t(count: 283)\t-> new token: 907\n",
      "[vocab: 653 / 2048] Merging\t(b'he', b're')\t(count: 283)\t-> new token: 908\n",
      "[vocab: 654 / 2048] Merging\t(b'S', b'ara')\t(count: 282)\t-> new token: 909\n",
      "[vocab: 655 / 2048] Merging\t(b'to', b'ld')\t(count: 281)\t-> new token: 910\n",
      "[vocab: 656 / 2048] Merging\t(b'fe', b'el')\t(count: 281)\t-> new token: 911\n",
      "[vocab: 657 / 2048] Merging\t(b'dec', b'ided')\t(count: 280)\t-> new token: 912\n",
      "[vocab: 658 / 2048] Merging\t(b't', b'his')\t(count: 279)\t-> new token: 913\n",
      "[vocab: 659 / 2048] Merging\t(b'h', b'ug')\t(count: 279)\t-> new token: 914\n",
      "[vocab: 660 / 2048] Merging\t(b'j', b'ump')\t(count: 279)\t-> new token: 915\n",
      "[vocab: 661 / 2048] Merging\t(b'an', b'g')\t(count: 279)\t-> new token: 916\n",
      "[vocab: 662 / 2048] Merging\t(b'A', b'nd')\t(count: 278)\t-> new token: 917\n",
      "[vocab: 663 / 2048] Merging\t(b'be', b'came')\t(count: 278)\t-> new token: 918\n",
      "[vocab: 664 / 2048] Merging\t(b'g', b're')\t(count: 277)\t-> new token: 919\n",
      "[vocab: 665 / 2048] Merging\t(b'in', b'to')\t(count: 276)\t-> new token: 920\n",
      "[vocab: 666 / 2048] Merging\t(b'w', b'o')\t(count: 274)\t-> new token: 921\n",
      "[vocab: 667 / 2048] Merging\t(b'n', b'a')\t(count: 274)\t-> new token: 922\n",
      "[vocab: 668 / 2048] Merging\t(b'The', b'n')\t(count: 273)\t-> new token: 923\n",
      "[vocab: 669 / 2048] Merging\t(b'c', b'lo')\t(count: 273)\t-> new token: 924\n",
      "[vocab: 670 / 2048] Merging\t(b'out', b'side')\t(count: 269)\t-> new token: 925\n",
      "[vocab: 671 / 2048] Merging\t(b'way', b's')\t(count: 267)\t-> new token: 926\n",
      "[vocab: 672 / 2048] Merging\t(b'be', b'st')\t(count: 267)\t-> new token: 927\n",
      "[vocab: 673 / 2048] Merging\t(b'sh', b'ow')\t(count: 265)\t-> new token: 928\n",
      "[vocab: 674 / 2048] Merging\t(b'exc', b'ited')\t(count: 265)\t-> new token: 929\n",
      "[vocab: 675 / 2048] Merging\t(b'bot', b'h')\t(count: 263)\t-> new token: 930\n",
      "[vocab: 676 / 2048] Merging\t(b'ou', b's')\t(count: 262)\t-> new token: 931\n",
      "[vocab: 677 / 2048] Merging\t(b'Y', b'es')\t(count: 262)\t-> new token: 932\n",
      "[vocab: 678 / 2048] Merging\t(b'is', b'e')\t(count: 261)\t-> new token: 933\n",
      "[vocab: 679 / 2048] Merging\t(b'in', b'side')\t(count: 259)\t-> new token: 934\n",
      "[vocab: 680 / 2048] Merging\t(b'fa', b'st')\t(count: 258)\t-> new token: 935\n",
      "[vocab: 681 / 2048] Merging\t(b'in', b'y')\t(count: 257)\t-> new token: 936\n",
      "[vocab: 682 / 2048] Merging\t(b'al', b'ways')\t(count: 256)\t-> new token: 937\n",
      "[vocab: 683 / 2048] Merging\t(b'fo', b're')\t(count: 255)\t-> new token: 938\n",
      "[vocab: 684 / 2048] Merging\t(b't', b'a')\t(count: 255)\t-> new token: 939\n",
      "[vocab: 685 / 2048] Merging\t(b'e', b'ach')\t(count: 254)\t-> new token: 940\n",
      "[vocab: 686 / 2048] Merging\t(b's', b'ur')\t(count: 250)\t-> new token: 941\n",
      "[vocab: 687 / 2048] Merging\t(b'sor', b'ry')\t(count: 250)\t-> new token: 942\n",
      "[vocab: 688 / 2048] Merging\t(b'f', b'ly')\t(count: 248)\t-> new token: 943\n",
      "[vocab: 689 / 2048] Merging\t(b'n', b'ice')\t(count: 247)\t-> new token: 944\n",
      "[vocab: 690 / 2048] Merging\t(b'W', b'hen')\t(count: 245)\t-> new token: 945\n",
      "[vocab: 691 / 2048] Merging\t(b'mu', b'ch')\t(count: 245)\t-> new token: 946\n",
      "[vocab: 692 / 2048] Merging\t(b'o', b'ld')\t(count: 242)\t-> new token: 947\n",
      "[vocab: 693 / 2048] Merging\t(b'p', b'a')\t(count: 241)\t-> new token: 948\n",
      "[vocab: 694 / 2048] Merging\t(b'un', b'der')\t(count: 239)\t-> new token: 949\n",
      "[vocab: 695 / 2048] Merging\t(b'sur', b'pr')\t(count: 238)\t-> new token: 950\n",
      "[vocab: 696 / 2048] Merging\t(b'is', b'ed')\t(count: 238)\t-> new token: 951\n",
      "[vocab: 697 / 2048] Merging\t(b'b', b'r')\t(count: 237)\t-> new token: 952\n",
      "[vocab: 698 / 2048] Merging\t(b'b', b'l')\t(count: 237)\t-> new token: 953\n",
      "[vocab: 699 / 2048] Merging\t(b'b', b'u')\t(count: 236)\t-> new token: 954\n",
      "[vocab: 700 / 2048] Merging\t(b'ou', b'r')\t(count: 236)\t-> new token: 955\n",
      "[vocab: 701 / 2048] Merging\t(b't', b'ake')\t(count: 234)\t-> new token: 956\n",
      "[vocab: 702 / 2048] Merging\t(b't', b'ur')\t(count: 234)\t-> new token: 957\n",
      "[vocab: 703 / 2048] Merging\t(b'b', b'le')\t(count: 234)\t-> new token: 958\n",
      "[vocab: 704 / 2048] Merging\t(b's', b'w')\t(count: 233)\t-> new token: 959\n",
      "[vocab: 705 / 2048] Merging\t(b'b', b'ed')\t(count: 233)\t-> new token: 960\n",
      "[vocab: 706 / 2048] Merging\t(b's', b'k')\t(count: 233)\t-> new token: 961\n",
      "[vocab: 707 / 2048] Merging\t(b'v', b'en')\t(count: 232)\t-> new token: 962\n",
      "[vocab: 708 / 2048] Merging\t(b'ro', b'ck')\t(count: 232)\t-> new token: 963\n",
      "[vocab: 709 / 2048] Merging\t(b'H', b'er')\t(count: 229)\t-> new token: 964\n",
      "[vocab: 710 / 2048] Merging\t(b'j', b'o')\t(count: 228)\t-> new token: 965\n",
      "[vocab: 711 / 2048] Merging\t(b'ga', b've')\t(count: 227)\t-> new token: 966\n",
      "[vocab: 712 / 2048] Merging\t(b'did', b'n')\t(count: 227)\t-> new token: 967\n",
      "[vocab: 713 / 2048] Merging\t(b'le', b't')\t(count: 226)\t-> new token: 968\n",
      "[vocab: 714 / 2048] Merging\t(b'h', b'ow')\t(count: 225)\t-> new token: 969\n",
      "[vocab: 715 / 2048] Merging\t(b'pret', b'ty')\t(count: 225)\t-> new token: 970\n",
      "[vocab: 716 / 2048] Merging\t(b'b', b'ro')\t(count: 225)\t-> new token: 971\n",
      "[vocab: 717 / 2048] Merging\t(b'ra', b'in')\t(count: 225)\t-> new token: 972\n",
      "[vocab: 718 / 2048] Merging\t(b'in', b'e')\t(count: 224)\t-> new token: 973\n",
      "[vocab: 719 / 2048] Merging\t(b'g', b'ed')\t(count: 223)\t-> new token: 974\n",
      "[vocab: 720 / 2048] Merging\t(b'l', b'ist')\t(count: 223)\t-> new token: 975\n",
      "[vocab: 721 / 2048] Merging\t(b't', b'r')\t(count: 222)\t-> new token: 976\n",
      "[vocab: 722 / 2048] Merging\t(b'it', b's')\t(count: 221)\t-> new token: 977\n",
      "[vocab: 723 / 2048] Merging\t(b're', b'ad')\t(count: 220)\t-> new token: 978\n",
      "[vocab: 724 / 2048] Merging\t(b'f', b'le')\t(count: 220)\t-> new token: 979\n",
      "[vocab: 725 / 2048] Merging\t(b'h', b'and')\t(count: 219)\t-> new token: 980\n",
      "[vocab: 726 / 2048] Merging\t(b'k', b'ind')\t(count: 217)\t-> new token: 981\n",
      "[vocab: 727 / 2048] Merging\t(b'an', b'im')\t(count: 217)\t-> new token: 982\n",
      "[vocab: 728 / 2048] Merging\t(b'anim', b'al')\t(count: 217)\t-> new token: 983\n",
      "[vocab: 729 / 2048] Merging\t(b'H', b'is')\t(count: 216)\t-> new token: 984\n",
      "[vocab: 730 / 2048] Merging\t(b'co', b'l')\t(count: 214)\t-> new token: 985\n",
      "[vocab: 731 / 2048] Merging\t(b'f', b'i')\t(count: 214)\t-> new token: 986\n",
      "[vocab: 732 / 2048] Merging\t(b'wal', b'ked')\t(count: 214)\t-> new token: 987\n",
      "[vocab: 733 / 2048] Merging\t(b'happ', b'ened')\t(count: 213)\t-> new token: 988\n",
      "[vocab: 734 / 2048] Merging\t(b'i', b'on')\t(count: 213)\t-> new token: 989\n",
      "[vocab: 735 / 2048] Merging\t(b'A', b's')\t(count: 213)\t-> new token: 990\n",
      "[vocab: 736 / 2048] Merging\t(b'ne', b'ed')\t(count: 211)\t-> new token: 991\n",
      "[vocab: 737 / 2048] Merging\t(b'j', b'ust')\t(count: 211)\t-> new token: 992\n",
      "[vocab: 738 / 2048] Merging\t(b'c', b'ake')\t(count: 210)\t-> new token: 993\n",
      "[vocab: 739 / 2048] Merging\t(b'ha', b'r')\t(count: 209)\t-> new token: 994\n",
      "[vocab: 740 / 2048] Merging\t(b'fo', b'od')\t(count: 207)\t-> new token: 995\n",
      "[vocab: 741 / 2048] Merging\t(b's', b'pec')\t(count: 205)\t-> new token: 996\n",
      "[vocab: 742 / 2048] Merging\t(b'flo', b'wer')\t(count: 205)\t-> new token: 997\n",
      "[vocab: 743 / 2048] Merging\t(b'lo', b've')\t(count: 205)\t-> new token: 998\n",
      "[vocab: 744 / 2048] Merging\t(b'as', b's')\t(count: 205)\t-> new token: 999\n",
      "[vocab: 745 / 2048] Merging\t(b'v', b'ing')\t(count: 203)\t-> new token: 1000\n",
      "[vocab: 746 / 2048] Merging\t(b'I', b'n')\t(count: 203)\t-> new token: 1001\n",
      "[vocab: 747 / 2048] Merging\t(b'T', b'h')\t(count: 202)\t-> new token: 1002\n",
      "[vocab: 748 / 2048] Merging\t(b'an', b'k')\t(count: 200)\t-> new token: 1003\n",
      "[vocab: 749 / 2048] Merging\t(b'c', b're')\t(count: 200)\t-> new token: 1004\n",
      "[vocab: 750 / 2048] Merging\t(b'be', b't')\t(count: 199)\t-> new token: 1005\n",
      "[vocab: 751 / 2048] Merging\t(b'wa', b't')\t(count: 199)\t-> new token: 1006\n",
      "[vocab: 752 / 2048] Merging\t(b'ne', b'ar')\t(count: 199)\t-> new token: 1007\n",
      "[vocab: 753 / 2048] Merging\t(b'f', b'f')\t(count: 199)\t-> new token: 1008\n",
      "[vocab: 754 / 2048] Merging\t(b'ab', b'le')\t(count: 198)\t-> new token: 1009\n",
      "[vocab: 755 / 2048] Merging\t(b'ne', b'ver')\t(count: 198)\t-> new token: 1010\n",
      "[vocab: 756 / 2048] Merging\t(b'c', b'hed')\t(count: 198)\t-> new token: 1011\n",
      "[vocab: 757 / 2048] Merging\t(b'Th', b'ank')\t(count: 197)\t-> new token: 1012\n",
      "[vocab: 758 / 2048] Merging\t(b'E', b'very')\t(count: 197)\t-> new token: 1013\n",
      "[vocab: 759 / 2048] Merging\t(b'm', b'ag')\t(count: 197)\t-> new token: 1014\n",
      "[vocab: 760 / 2048] Merging\t(b'b', b'ug')\t(count: 197)\t-> new token: 1015\n",
      "[vocab: 761 / 2048] Merging\t(b'p', b'er')\t(count: 195)\t-> new token: 1016\n",
      "[vocab: 762 / 2048] Merging\t(b'c', b'he')\t(count: 194)\t-> new token: 1017\n",
      "[vocab: 763 / 2048] Merging\t(b'A', b'n')\t(count: 193)\t-> new token: 1018\n",
      "[vocab: 764 / 2048] Merging\t(b'op', b'le')\t(count: 192)\t-> new token: 1019\n",
      "[vocab: 765 / 2048] Merging\t(b'r', b'u')\t(count: 191)\t-> new token: 1020\n",
      "[vocab: 766 / 2048] Merging\t(b't', b'ry')\t(count: 191)\t-> new token: 1021\n",
      "[vocab: 767 / 2048] Merging\t(b'cle', b'an')\t(count: 191)\t-> new token: 1022\n",
      "[vocab: 768 / 2048] Merging\t(b'ide', b'a')\t(count: 190)\t-> new token: 1023\n",
      "[vocab: 769 / 2048] Merging\t(b'animal', b's')\t(count: 190)\t-> new token: 1024\n",
      "[vocab: 770 / 2048] Merging\t(b'r', b'ong')\t(count: 189)\t-> new token: 1025\n",
      "[vocab: 771 / 2048] Merging\t(b'pe', b'ople')\t(count: 189)\t-> new token: 1026\n",
      "[vocab: 772 / 2048] Merging\t(b'f', b'ar')\t(count: 189)\t-> new token: 1027\n",
      "[vocab: 773 / 2048] Merging\t(b'bet', b'ter')\t(count: 188)\t-> new token: 1028\n",
      "[vocab: 774 / 2048] Merging\t(b'ig', b'h')\t(count: 188)\t-> new token: 1029\n",
      "[vocab: 775 / 2048] Merging\t(b'spec', b'i')\t(count: 187)\t-> new token: 1030\n",
      "[vocab: 776 / 2048] Merging\t(b'speci', b'al')\t(count: 186)\t-> new token: 1031\n",
      "[vocab: 777 / 2048] Merging\t(b'F', b'rom')\t(count: 186)\t-> new token: 1032\n",
      "[vocab: 778 / 2048] Merging\t(b'gi', b've')\t(count: 186)\t-> new token: 1033\n",
      "[vocab: 779 / 2048] Merging\t(b'T', b'hat')\t(count: 185)\t-> new token: 1034\n",
      "[vocab: 780 / 2048] Merging\t(b'sk', b'y')\t(count: 185)\t-> new token: 1035\n",
      "[vocab: 781 / 2048] Merging\t(b're', b'a')\t(count: 184)\t-> new token: 1036\n",
      "[vocab: 782 / 2048] Merging\t(b'any', b'more')\t(count: 183)\t-> new token: 1037\n",
      "[vocab: 783 / 2048] Merging\t(b'lot', b's')\t(count: 182)\t-> new token: 1038\n",
      "[vocab: 784 / 2048] Merging\t(b'col', b'or')\t(count: 182)\t-> new token: 1039\n",
      "[vocab: 785 / 2048] Merging\t(b'a', b'ce')\t(count: 182)\t-> new token: 1040\n",
      "[vocab: 786 / 2048] Merging\t(b'udd', b'en')\t(count: 181)\t-> new token: 1041\n",
      "[vocab: 787 / 2048] Merging\t(b'w', b'here')\t(count: 181)\t-> new token: 1042\n",
      "[vocab: 788 / 2048] Merging\t(b'll', b'y')\t(count: 180)\t-> new token: 1043\n",
      "[vocab: 789 / 2048] Merging\t(b'do', b'or')\t(count: 180)\t-> new token: 1044\n",
      "[vocab: 790 / 2048] Merging\t(b'n', b't')\t(count: 180)\t-> new token: 1045\n",
      "[vocab: 791 / 2048] Merging\t(b's', b'l')\t(count: 180)\t-> new token: 1046\n",
      "[vocab: 792 / 2048] Merging\t(b's', b'p')\t(count: 179)\t-> new token: 1047\n",
      "[vocab: 793 / 2048] Merging\t(b'fle', b'w')\t(count: 179)\t-> new token: 1048\n",
      "[vocab: 794 / 2048] Merging\t(b'sha', b're')\t(count: 179)\t-> new token: 1049\n",
      "[vocab: 795 / 2048] Merging\t(b'do', b'll')\t(count: 179)\t-> new token: 1050\n",
      "[vocab: 796 / 2048] Merging\t(b'tur', b'n')\t(count: 178)\t-> new token: 1051\n",
      "[vocab: 797 / 2048] Merging\t(b'surpr', b'ised')\t(count: 178)\t-> new token: 1052\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m\n\u001b[0;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mbyte_pair_encoding_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytePairEncodingWordTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_input_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregex_split_pattern_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregex_pattern_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/gpt_from_scratch/gpt_from_scratch/byte_pair_encoding_tokenizer.py:317\u001b[0m, in \u001b[0;36mBytePairEncodingWordTokenizer.from_input_text\u001b[0;34m(cls, input_text, regex_split_pattern_string, vocab_size)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# ex: word = [b'h', b'e', b'l', b'l', b'o']\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m    315\u001b[0m \n\u001b[1;32m    316\u001b[0m     \u001b[38;5;66;03m# ex: pair = (b'h', b'e')\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pair \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    319\u001b[0m         pair_counts[pair] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# ex: top_pair = (b't', b'h')\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vocab_size = 2048\n",
    "\n",
    "tokenizer = byte_pair_encoding_tokenizer.BytePairEncodingWordTokenizer.from_input_text(\n",
    "    input_text=input_text,\n",
    "    regex_split_pattern_string=regex_pattern_str,\n",
    "    vocab_size=vocab_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d849f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jack and Jill went up the hill\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode('Jack and Jill went up the hill')\n",
    "print(tokenizer.decode(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b4edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74, 691, 32, 517, 32, 74, 667, 32, 650, 32, 590, 32, 514, 32, 104, 667]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Jack and Jill went up the hill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a54cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(b'say', 758),\n",
       " (b'other', 759),\n",
       " (b'pr', 760),\n",
       " (b'ouse', 761),\n",
       " (b'make', 762),\n",
       " (b'ight', 763),\n",
       " (b'wor', 764),\n",
       " (b'small', 765),\n",
       " (b'Ben', 766),\n",
       " (b'asked', 767)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some examples from the vocabulary\n",
    "list(tokenizer.merges.items())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4454d912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\t\tOnce upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "Tokenized:\t\u001b[44m\u001b[97mOnce\u001b[0m\u001b[45m\u001b[97m \u001b[0m\u001b[42m\u001b[97mupon\u001b[0m\u001b[41m\u001b[97m \u001b[0m\u001b[43m\u001b[97ma\u001b[0m\u001b[46m\u001b[97m \u001b[0m\u001b[44m\u001b[97mtime\u001b[0m\u001b[45m\u001b[97m \u001b[0m\u001b[42m\u001b[97mthere\u001b[0m\u001b[41m\u001b[97m \u001b[0m\u001b[43m\u001b[97mwas\u001b[0m\u001b[46m\u001b[97m \u001b[0m\u001b[44m\u001b[97ma\u001b[0m\u001b[45m\u001b[97m \u001b[0m\u001b[42m\u001b[97mlittle\u001b[0m\u001b[41m\u001b[97m \u001b[0m\u001b[43m\u001b[97mboy\u001b[0m\u001b[46m\u001b[97m \u001b[0m\u001b[44m\u001b[97mnamed\u001b[0m\u001b[45m\u001b[97m \u001b[0m\u001b[42m\u001b[97mBen\u001b[0m\u001b[41m\u001b[97m.\u001b[0m\u001b[43m\u001b[97m \u001b[0m\u001b[46m\u001b[97mBen\u001b[0m\u001b[44m\u001b[97m \u001b[0m\u001b[45m\u001b[97mloved\u001b[0m\u001b[42m\u001b[97m \u001b[0m\u001b[41m\u001b[97mto\u001b[0m\u001b[43m\u001b[97m \u001b[0m\u001b[46m\u001b[97mex\u001b[0m\u001b[44m\u001b[97mpl\u001b[0m\u001b[45m\u001b[97mo\u001b[0m\u001b[42m\u001b[97mre\u001b[0m\u001b[41m\u001b[97m \u001b[0m\u001b[43m\u001b[97mthe\u001b[0m\u001b[46m\u001b[97m \u001b[0m\u001b[44m\u001b[97mwor\u001b[0m\u001b[45m\u001b[97mld\u001b[0m\u001b[42m\u001b[97m \u001b[0m\u001b[41m\u001b[97mar\u001b[0m\u001b[43m\u001b[97mound\u001b[0m\u001b[46m\u001b[97m \u001b[0m\u001b[44m\u001b[97mhim\u001b[0m\u001b[45m\u001b[97m.\u001b[0m\u001b[42m\u001b[97m \u001b[0m\u001b[41m\u001b[97mHe\u001b[0m\u001b[43m\u001b[97m \u001b[0m\u001b[46m\u001b[97msaw\u001b[0m\n",
      "Token ID | Token Bytes | Token String\n",
      "---------+-------------+--------------\n",
      "     660 | \u001b[38;5;2m4F\u001b[0m \u001b[38;5;2m6E\u001b[0m \u001b[38;5;2m63\u001b[0m \u001b[38;5;2m65\u001b[0m | 'Once'\n",
      "          \u001b[48;5;1m\u001b[38;5;15mOnce\u001b[0m upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+004F LATIN CAPITAL LETTER O (1 bytes: \u001b[38;5;2m4F\u001b[0m)\n",
      "          U+006E LATIN SMALL LETTER N (1 bytes: \u001b[38;5;2m6E\u001b[0m)\n",
      "          U+0063 LATIN SMALL LETTER C (1 bytes: \u001b[38;5;2m63\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once\u001b[48;5;1m\u001b[38;5;15m \u001b[0mupon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     666 | \u001b[38;5;2m75\u001b[0m \u001b[38;5;2m70\u001b[0m \u001b[38;5;2m6F\u001b[0m \u001b[38;5;2m6E\u001b[0m | 'upon'\n",
      "          Once \u001b[48;5;1m\u001b[38;5;15mupon\u001b[0m a time there was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0075 LATIN SMALL LETTER U (1 bytes: \u001b[38;5;2m75\u001b[0m)\n",
      "          U+0070 LATIN SMALL LETTER P (1 bytes: \u001b[38;5;2m70\u001b[0m)\n",
      "          U+006F LATIN SMALL LETTER O (1 bytes: \u001b[38;5;2m6F\u001b[0m)\n",
      "          U+006E LATIN SMALL LETTER N (1 bytes: \u001b[38;5;2m6E\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon\u001b[48;5;1m\u001b[38;5;15m \u001b[0ma time there was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "      97 | \u001b[38;5;2m61\u001b[0m | 'a'\n",
      "          Once upon \u001b[48;5;1m\u001b[38;5;15ma\u001b[0m time there was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a\u001b[48;5;1m\u001b[38;5;15m \u001b[0mtime there was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     637 | \u001b[38;5;2m74\u001b[0m \u001b[38;5;2m69\u001b[0m \u001b[38;5;2m6D\u001b[0m \u001b[38;5;2m65\u001b[0m | 'time'\n",
      "          Once upon a \u001b[48;5;1m\u001b[38;5;15mtime\u001b[0m there was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0074 LATIN SMALL LETTER T (1 bytes: \u001b[38;5;2m74\u001b[0m)\n",
      "          U+0069 LATIN SMALL LETTER I (1 bytes: \u001b[38;5;2m69\u001b[0m)\n",
      "          U+006D LATIN SMALL LETTER M (1 bytes: \u001b[38;5;2m6D\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time\u001b[48;5;1m\u001b[38;5;15m \u001b[0mthere was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     641 | \u001b[38;5;2m74\u001b[0m \u001b[38;5;2m68\u001b[0m \u001b[38;5;2m65\u001b[0m \u001b[38;5;2m72\u001b[0m \u001b[38;5;2m65\u001b[0m | 'there'\n",
      "          Once upon a time \u001b[48;5;1m\u001b[38;5;15mthere\u001b[0m was a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0074 LATIN SMALL LETTER T (1 bytes: \u001b[38;5;2m74\u001b[0m)\n",
      "          U+0068 LATIN SMALL LETTER H (1 bytes: \u001b[38;5;2m68\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "          U+0072 LATIN SMALL LETTER R (1 bytes: \u001b[38;5;2m72\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there\u001b[48;5;1m\u001b[38;5;15m \u001b[0mwas a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     528 | \u001b[38;5;2m77\u001b[0m \u001b[38;5;2m61\u001b[0m \u001b[38;5;2m73\u001b[0m | 'was'\n",
      "          Once upon a time there \u001b[48;5;1m\u001b[38;5;15mwas\u001b[0m a little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0077 LATIN SMALL LETTER W (1 bytes: \u001b[38;5;2m77\u001b[0m)\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "          U+0073 LATIN SMALL LETTER S (1 bytes: \u001b[38;5;2m73\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was\u001b[48;5;1m\u001b[38;5;15m \u001b[0ma little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "      97 | \u001b[38;5;2m61\u001b[0m | 'a'\n",
      "          Once upon a time there was \u001b[48;5;1m\u001b[38;5;15ma\u001b[0m little boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a\u001b[48;5;1m\u001b[38;5;15m \u001b[0mlittle boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     634 | \u001b[38;5;2m6C\u001b[0m \u001b[38;5;2m69\u001b[0m \u001b[38;5;2m74\u001b[0m \u001b[38;5;2m74\u001b[0m \u001b[38;5;2m6C\u001b[0m \u001b[38;5;2m65\u001b[0m | 'little'\n",
      "          Once upon a time there was a \u001b[48;5;1m\u001b[38;5;15mlittle\u001b[0m boy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+006C LATIN SMALL LETTER L (1 bytes: \u001b[38;5;2m6C\u001b[0m)\n",
      "          U+0069 LATIN SMALL LETTER I (1 bytes: \u001b[38;5;2m69\u001b[0m)\n",
      "          U+0074 LATIN SMALL LETTER T (1 bytes: \u001b[38;5;2m74\u001b[0m)\n",
      "          U+0074 LATIN SMALL LETTER T (1 bytes: \u001b[38;5;2m74\u001b[0m)\n",
      "          U+006C LATIN SMALL LETTER L (1 bytes: \u001b[38;5;2m6C\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little\u001b[48;5;1m\u001b[38;5;15m \u001b[0mboy named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     712 | \u001b[38;5;2m62\u001b[0m \u001b[38;5;2m6F\u001b[0m \u001b[38;5;2m79\u001b[0m | 'boy'\n",
      "          Once upon a time there was a little \u001b[48;5;1m\u001b[38;5;15mboy\u001b[0m named Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0062 LATIN SMALL LETTER B (1 bytes: \u001b[38;5;2m62\u001b[0m)\n",
      "          U+006F LATIN SMALL LETTER O (1 bytes: \u001b[38;5;2m6F\u001b[0m)\n",
      "          U+0079 LATIN SMALL LETTER Y (1 bytes: \u001b[38;5;2m79\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy\u001b[48;5;1m\u001b[38;5;15m \u001b[0mnamed Ben. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     639 | \u001b[38;5;2m6E\u001b[0m \u001b[38;5;2m61\u001b[0m \u001b[38;5;2m6D\u001b[0m \u001b[38;5;2m65\u001b[0m \u001b[38;5;2m64\u001b[0m | 'named'\n",
      "          Once upon a time there was a little boy \u001b[48;5;1m\u001b[38;5;15mnamed\u001b[0m Ben. Ben loved to explore the world around him. He saw\n",
      "          U+006E LATIN SMALL LETTER N (1 bytes: \u001b[38;5;2m6E\u001b[0m)\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "          U+006D LATIN SMALL LETTER M (1 bytes: \u001b[38;5;2m6D\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named\u001b[48;5;1m\u001b[38;5;15m \u001b[0mBen. Ben loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     766 | \u001b[38;5;2m42\u001b[0m \u001b[38;5;2m65\u001b[0m \u001b[38;5;2m6E\u001b[0m | 'Ben'\n",
      "          Once upon a time there was a little boy named \u001b[48;5;1m\u001b[38;5;15mBen\u001b[0m. Ben loved to explore the world around him. He saw\n",
      "          U+0042 LATIN CAPITAL LETTER B (1 bytes: \u001b[38;5;2m42\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "          U+006E LATIN SMALL LETTER N (1 bytes: \u001b[38;5;2m6E\u001b[0m)\n",
      "      46 | \u001b[38;5;2m2E\u001b[0m | '.'\n",
      "          Once upon a time there was a little boy named Ben\u001b[48;5;1m\u001b[38;5;15m.\u001b[0m Ben loved to explore the world around him. He saw\n",
      "          U+002E FULL STOP (1 bytes: \u001b[38;5;2m2E\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben.\u001b[48;5;1m\u001b[38;5;15m \u001b[0mBen loved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     766 | \u001b[38;5;2m42\u001b[0m \u001b[38;5;2m65\u001b[0m \u001b[38;5;2m6E\u001b[0m | 'Ben'\n",
      "          Once upon a time there was a little boy named Ben. \u001b[48;5;1m\u001b[38;5;15mBen\u001b[0m loved to explore the world around him. He saw\n",
      "          U+0042 LATIN CAPITAL LETTER B (1 bytes: \u001b[38;5;2m42\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "          U+006E LATIN SMALL LETTER N (1 bytes: \u001b[38;5;2m6E\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben\u001b[48;5;1m\u001b[38;5;15m \u001b[0mloved to explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     722 | \u001b[38;5;2m6C\u001b[0m \u001b[38;5;2m6F\u001b[0m \u001b[38;5;2m76\u001b[0m \u001b[38;5;2m65\u001b[0m \u001b[38;5;2m64\u001b[0m | 'loved'\n",
      "          Once upon a time there was a little boy named Ben. Ben \u001b[48;5;1m\u001b[38;5;15mloved\u001b[0m to explore the world around him. He saw\n",
      "          U+006C LATIN SMALL LETTER L (1 bytes: \u001b[38;5;2m6C\u001b[0m)\n",
      "          U+006F LATIN SMALL LETTER O (1 bytes: \u001b[38;5;2m6F\u001b[0m)\n",
      "          U+0076 LATIN SMALL LETTER V (1 bytes: \u001b[38;5;2m76\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben loved\u001b[48;5;1m\u001b[38;5;15m \u001b[0mto explore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     516 | \u001b[38;5;2m74\u001b[0m \u001b[38;5;2m6F\u001b[0m | 'to'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved \u001b[48;5;1m\u001b[38;5;15mto\u001b[0m explore the world around him. He saw\n",
      "          U+0074 LATIN SMALL LETTER T (1 bytes: \u001b[38;5;2m74\u001b[0m)\n",
      "          U+006F LATIN SMALL LETTER O (1 bytes: \u001b[38;5;2m6F\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to\u001b[48;5;1m\u001b[38;5;15m \u001b[0mexplore the world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     579 | \u001b[38;5;2m65\u001b[0m \u001b[38;5;2m78\u001b[0m | 'ex'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to \u001b[48;5;1m\u001b[38;5;15mex\u001b[0mplore the world around him. He saw\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "          U+0078 LATIN SMALL LETTER X (1 bytes: \u001b[38;5;2m78\u001b[0m)\n",
      "     548 | \u001b[38;5;2m70\u001b[0m \u001b[38;5;2m6C\u001b[0m | 'pl'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to ex\u001b[48;5;1m\u001b[38;5;15mpl\u001b[0more the world around him. He saw\n",
      "          U+0070 LATIN SMALL LETTER P (1 bytes: \u001b[38;5;2m70\u001b[0m)\n",
      "          U+006C LATIN SMALL LETTER L (1 bytes: \u001b[38;5;2m6C\u001b[0m)\n",
      "     111 | \u001b[38;5;2m6F\u001b[0m | 'o'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to expl\u001b[48;5;1m\u001b[38;5;15mo\u001b[0mre the world around him. He saw\n",
      "          U+006F LATIN SMALL LETTER O (1 bytes: \u001b[38;5;2m6F\u001b[0m)\n",
      "     520 | \u001b[38;5;2m72\u001b[0m \u001b[38;5;2m65\u001b[0m | 're'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explo\u001b[48;5;1m\u001b[38;5;15mre\u001b[0m the world around him. He saw\n",
      "          U+0072 LATIN SMALL LETTER R (1 bytes: \u001b[38;5;2m72\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore\u001b[48;5;1m\u001b[38;5;15m \u001b[0mthe world around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     514 | \u001b[38;5;2m74\u001b[0m \u001b[38;5;2m68\u001b[0m \u001b[38;5;2m65\u001b[0m | 'the'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore \u001b[48;5;1m\u001b[38;5;15mthe\u001b[0m world around him. He saw\n",
      "          U+0074 LATIN SMALL LETTER T (1 bytes: \u001b[38;5;2m74\u001b[0m)\n",
      "          U+0068 LATIN SMALL LETTER H (1 bytes: \u001b[38;5;2m68\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the\u001b[48;5;1m\u001b[38;5;15m \u001b[0mworld around him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     764 | \u001b[38;5;2m77\u001b[0m \u001b[38;5;2m6F\u001b[0m \u001b[38;5;2m72\u001b[0m | 'wor'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the \u001b[48;5;1m\u001b[38;5;15mwor\u001b[0mld around him. He saw\n",
      "          U+0077 LATIN SMALL LETTER W (1 bytes: \u001b[38;5;2m77\u001b[0m)\n",
      "          U+006F LATIN SMALL LETTER O (1 bytes: \u001b[38;5;2m6F\u001b[0m)\n",
      "          U+0072 LATIN SMALL LETTER R (1 bytes: \u001b[38;5;2m72\u001b[0m)\n",
      "     574 | \u001b[38;5;2m6C\u001b[0m \u001b[38;5;2m64\u001b[0m | 'ld'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the wor\u001b[48;5;1m\u001b[38;5;15mld\u001b[0m around him. He saw\n",
      "          U+006C LATIN SMALL LETTER L (1 bytes: \u001b[38;5;2m6C\u001b[0m)\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world\u001b[48;5;1m\u001b[38;5;15m \u001b[0maround him. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     532 | \u001b[38;5;2m61\u001b[0m \u001b[38;5;2m72\u001b[0m | 'ar'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world \u001b[48;5;1m\u001b[38;5;15mar\u001b[0mound him. He saw\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "          U+0072 LATIN SMALL LETTER R (1 bytes: \u001b[38;5;2m72\u001b[0m)\n",
      "     636 | \u001b[38;5;2m6F\u001b[0m \u001b[38;5;2m75\u001b[0m \u001b[38;5;2m6E\u001b[0m \u001b[38;5;2m64\u001b[0m | 'ound'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world ar\u001b[48;5;1m\u001b[38;5;15mound\u001b[0m him. He saw\n",
      "          U+006F LATIN SMALL LETTER O (1 bytes: \u001b[38;5;2m6F\u001b[0m)\n",
      "          U+0075 LATIN SMALL LETTER U (1 bytes: \u001b[38;5;2m75\u001b[0m)\n",
      "          U+006E LATIN SMALL LETTER N (1 bytes: \u001b[38;5;2m6E\u001b[0m)\n",
      "          U+0064 LATIN SMALL LETTER D (1 bytes: \u001b[38;5;2m64\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world around\u001b[48;5;1m\u001b[38;5;15m \u001b[0mhim. He saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     705 | \u001b[38;5;2m68\u001b[0m \u001b[38;5;2m69\u001b[0m \u001b[38;5;2m6D\u001b[0m | 'him'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world around \u001b[48;5;1m\u001b[38;5;15mhim\u001b[0m. He saw\n",
      "          U+0068 LATIN SMALL LETTER H (1 bytes: \u001b[38;5;2m68\u001b[0m)\n",
      "          U+0069 LATIN SMALL LETTER I (1 bytes: \u001b[38;5;2m69\u001b[0m)\n",
      "          U+006D LATIN SMALL LETTER M (1 bytes: \u001b[38;5;2m6D\u001b[0m)\n",
      "      46 | \u001b[38;5;2m2E\u001b[0m | '.'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world around him\u001b[48;5;1m\u001b[38;5;15m.\u001b[0m He saw\n",
      "          U+002E FULL STOP (1 bytes: \u001b[38;5;2m2E\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world around him.\u001b[48;5;1m\u001b[38;5;15m \u001b[0mHe saw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     549 | \u001b[38;5;2m48\u001b[0m \u001b[38;5;2m65\u001b[0m | 'He'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. \u001b[48;5;1m\u001b[38;5;15mHe\u001b[0m saw\n",
      "          U+0048 LATIN CAPITAL LETTER H (1 bytes: \u001b[38;5;2m48\u001b[0m)\n",
      "          U+0065 LATIN SMALL LETTER E (1 bytes: \u001b[38;5;2m65\u001b[0m)\n",
      "      32 | \u001b[38;5;2m20\u001b[0m | ' '\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He\u001b[48;5;1m\u001b[38;5;15m \u001b[0msaw\n",
      "          U+0020 SPACE (1 bytes: \u001b[38;5;2m20\u001b[0m)\n",
      "     620 | \u001b[38;5;2m73\u001b[0m \u001b[38;5;2m61\u001b[0m \u001b[38;5;2m77\u001b[0m | 'saw'\n",
      "          Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He \u001b[48;5;1m\u001b[38;5;15msaw\u001b[0m\n",
      "          U+0073 LATIN SMALL LETTER S (1 bytes: \u001b[38;5;2m73\u001b[0m)\n",
      "          U+0061 LATIN SMALL LETTER A (1 bytes: \u001b[38;5;2m61\u001b[0m)\n",
      "          U+0077 LATIN SMALL LETTER W (1 bytes: \u001b[38;5;2m77\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "# show how it looks for the first N characters to sanity check\n",
    "example_text = input_text[:100]\n",
    "\n",
    "# note: this includes a call to `get_colored_tokenization`\n",
    "tokenizer_utils.show_token_mapping(tokenizer=tokenizer, input_string=example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0dbc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JackandJillwentupthehill\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizer.encode('Jack and Jill went up the hill')\n",
    "print(tokenizer.decode(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635efdb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_utils.BytePairEncodingTokenizer.from_input_bytes(\n",
    "    input_bytes=input_text.encode('utf-8'),\n",
    "    vocab_size=1000,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
