{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5674fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoreload when imports change\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d131b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import Unpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4978c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_from_scratch import (\n",
    "    file_utils,\n",
    "    vocab_utils,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "155f247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# imported for typechecking\n",
    "#\n",
    "# note: can't easily alias via jaxtyping annotations, as it's a string literal and\n",
    "#       likely plays weirdly with typing.Annotation to forward a payload\n",
    "# note: torchtyping is deprecated in favor of jaxtyping, as torchtyping doesn't have mypy integration\n",
    "#\n",
    "# note: jaxtyping does support prepending\n",
    "#\n",
    "#   Image = Float[Array, \"channels height width\"]\n",
    "#   BatchImage = Float[Image, \"batch\"]\n",
    "#\n",
    "#    -->\n",
    "#\n",
    "#   BatchImage = Float[Array, \"batch channels height width\"]\n",
    "#\n",
    "# so we can compose aliases\n",
    "#\n",
    "from torch import Tensor\n",
    "import jaxtyping\n",
    "from jaxtyping import jaxtyped, Float32, Int64\n",
    "from typeguard import typechecked as typechecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2076e5",
   "metadata": {},
   "source": [
    "# The mathematical trick of self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e34a63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# important enough for Karpathy to call out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fc46612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem:\n",
    "# - we want it to be able to communicate previous token up to current token\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8e6d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - the simplest possible way, if I'm the 5th token, I just want\n",
    "# -   [\n",
    "#       <avg-0th-position>\n",
    "#       <avg-1st-position>\n",
    "#       <avg-2nd-position>\n",
    "#       ...\n",
    "#     ]\n",
    "#   along the vocab dimension\n",
    "#\n",
    "# - this is \"bag of words\"\n",
    "#\n",
    "# this is our \"version 1\"\n",
    "\n",
    "# We want x[b,t] = mean_{i<=t} x[b,i]\n",
    "x_bow = torch.zeros((B,T,C))\n",
    "\n",
    "# for each batch\n",
    "for b in range(B):\n",
    "    \n",
    "    # for each token in the sequence\n",
    "    for t in range(T):\n",
    "        \n",
    "        # slice up to (and including) the current token\n",
    "        x_prev = x[b, :t+1] # (t,C)\n",
    "        \n",
    "        # average them (along the vocab dimension)\n",
    "        x_bow[b, t] = torch.mean(x_prev, 0)\n",
    "\n",
    "# now `x_bow` is average \"up to \"\n",
    "x_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c3bbf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First element:\n",
      " - tensor([ 0.1808, -0.0700])\n",
      " -> tensor([ 0.1808, -0.0700])\n"
     ]
    }
   ],
   "source": [
    "print(f'First element:')\n",
    "print(f' - {x[0][0]}')\n",
    "print(f' -> {x_bow[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f1428ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second element: (average of first two)\n",
      " - tensor([ 0.1808, -0.0700])\n",
      " - tensor([-0.3596, -0.9152])\n",
      " -> tensor([-0.0894, -0.4926])\n"
     ]
    }
   ],
   "source": [
    "print(f'Second element: (average of first two)')\n",
    "print(f' - {x[0][0]}')\n",
    "print(f' - {x[0][1]}')\n",
    "print(f' -> {x_bow[0][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74a6360b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "--\n",
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "# this is good, but very inefficient\n",
    "# the trick is that we can be very very good about doing this with matrix multiplication\n",
    "\n",
    "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# a = torch.ones(3, 3)\n",
    "\n",
    "# OHHHH the triangular starts to look like the running total used in bag of words\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "\n",
    "# we can normalize them so they sum to 1 (now rows sum to 1)\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "\n",
    "c = a @ b\n",
    "\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)\n",
    "\n",
    "# that was literally it lmao?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "253df363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"version 2\": using matrix multiply for a weighted aggregation\n",
    "#\n",
    "# - this essentially lets:\n",
    "#   - `a = weights`\n",
    "#   - `b = x`\n",
    "#\n",
    "# - the weights are an intermediate computation tool\n",
    "#\n",
    "# - is self attention about letting them go in different directions?\n",
    "#\n",
    "weights = torch.tril(torch.ones(T, T))\n",
    "weights = weights / weights.sum(1, keepdim=True)\n",
    "\n",
    "x_bow2 = weights @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "\n",
    "# can see that same normalized running average pattern\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "053acc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we can show that this gives us the same thing our for loop was doing\n",
    "torch.allclose(x_bow, x_bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68cd6cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Softmax:\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "After Softmax:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n"
     ]
    }
   ],
   "source": [
    "# version 3: use softmax\n",
    "#\n",
    "# - so why do we care? this is the same thing\n",
    "# - this allows the weights to start at 0\n",
    "# - and we can essentially treat them as \"interaction strength\"\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "\n",
    "# affinities aren't going to be constant at 0, we want to let them vary depending on the data\n",
    "weights = torch.zeros((T,T))\n",
    "\n",
    "# for all the weights that are 0, make them -inf\n",
    "weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "print('Before Softmax:')\n",
    "print(weights)\n",
    "\n",
    "weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "print('After Softmax:')\n",
    "print(weights)\n",
    "\n",
    "x_bow3 = weights @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f2ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.allclose(x_bow, x_bow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c71add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tldr: this is:\n",
    "#  - weighted aggregation of information from previous tokens\n",
    "#  - allows it to change"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
